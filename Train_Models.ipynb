{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train Models.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SZ70ierx3pq2",
        "mTOwqhvR3xL3",
        "XA8ARleo3h53",
        "pKP_mFuB5giz",
        "dBQ-bRaW9oq5",
        "vK6rAXyO9rL8",
        "quStVkT996lA",
        "o1rIVfBKCPT5",
        "oHjYDaTNBYjQ"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yr2387/E4511-2021-Rong/blob/main/Train_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ70ierx3pq2"
      },
      "source": [
        "### Install AMPL packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYPEij6rwDmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900cdcdc-5da9-498d-d5c7-3b66ab8254f0"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNuv4Q5KFABw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6482217-376d-48c3-cedc-84c485857df5"
      },
      "source": [
        "! wget -c https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh\n",
        "! chmod +x Anaconda3-2019.10-Linux-x86_64.sh\n",
        "! bash ./Anaconda3-2019.10-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "# ! wget -c https://repo.anaconda.com/miniconda/Miniconda3-py37_4.9.2-Linux-x86_64.sh \n",
        "# ! chmod +x Miniconda3-py37_4.9.2-Linux-x86_64.sh\n",
        "# ! time bash Miniconda3-py37_4.9.2-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "! time conda install -y -c deepchem -c rdkit -c conda-forge -c omnia deepchem-gpu=2.3.0\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-13 16:32:44--  https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 530308481 (506M) [application/x-sh]\n",
            "Saving to: ‘Anaconda3-2019.10-Linux-x86_64.sh’\n",
            "\n",
            "Anaconda3-2019.10-L 100%[===================>] 505.74M   164MB/s    in 3.1s    \n",
            "\n",
            "2021-04-13 16:32:48 (164 MB/s) - ‘Anaconda3-2019.10-Linux-x86_64.sh’ saved [530308481/530308481]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _ipyw_jlab_nb_ext_conf==0.1.0=py37_0\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - alabaster==0.7.12=py37_0\n",
            "    - anaconda-client==1.7.2=py37_0\n",
            "    - anaconda-navigator==1.9.7=py37_0\n",
            "    - anaconda-project==0.8.3=py_0\n",
            "    - anaconda==2019.10=py37_0\n",
            "    - asn1crypto==1.0.1=py37_0\n",
            "    - astroid==2.3.1=py37_0\n",
            "    - astropy==3.2.2=py37h7b6447c_0\n",
            "    - atomicwrites==1.3.0=py37_1\n",
            "    - attrs==19.2.0=py_0\n",
            "    - babel==2.7.0=py_0\n",
            "    - backcall==0.1.0=py37_0\n",
            "    - backports.functools_lru_cache==1.5=py_2\n",
            "    - backports.os==0.1.1=py37_0\n",
            "    - backports.shutil_get_terminal_size==1.0.0=py37_2\n",
            "    - backports.tempfile==1.0=py_1\n",
            "    - backports.weakref==1.0.post1=py_1\n",
            "    - backports==1.0=py_2\n",
            "    - beautifulsoup4==4.8.0=py37_0\n",
            "    - bitarray==1.0.1=py37h7b6447c_0\n",
            "    - bkcharts==0.2=py37_0\n",
            "    - blas==1.0=mkl\n",
            "    - bleach==3.1.0=py37_0\n",
            "    - blosc==1.16.3=hd408876_0\n",
            "    - bokeh==1.3.4=py37_0\n",
            "    - boto==2.49.0=py37_0\n",
            "    - bottleneck==1.2.1=py37h035aef0_1\n",
            "    - bzip2==1.0.8=h7b6447c_0\n",
            "    - ca-certificates==2019.8.28=0\n",
            "    - cairo==1.14.12=h8948797_3\n",
            "    - certifi==2019.9.11=py37_0\n",
            "    - cffi==1.12.3=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - click==7.0=py37_0\n",
            "    - cloudpickle==1.2.2=py_0\n",
            "    - clyent==1.2.2=py37_1\n",
            "    - colorama==0.4.1=py37_0\n",
            "    - conda-build==3.18.9=py37_3\n",
            "    - conda-env==2.6.0=1\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda-verify==3.4.2=py_1\n",
            "    - conda==4.7.12=py37_0\n",
            "    - contextlib2==0.6.0=py_0\n",
            "    - cryptography==2.7=py37h1ba5d50_0\n",
            "    - curl==7.65.3=hbc83047_0\n",
            "    - cycler==0.10.0=py37_0\n",
            "    - cython==0.29.13=py37he6710b0_0\n",
            "    - cytoolz==0.10.0=py37h7b6447c_0\n",
            "    - dask-core==2.5.2=py_0\n",
            "    - dask==2.5.2=py_0\n",
            "    - dbus==1.13.6=h746ee38_0\n",
            "    - decorator==4.4.0=py37_1\n",
            "    - defusedxml==0.6.0=py_0\n",
            "    - distributed==2.5.2=py_0\n",
            "    - docutils==0.15.2=py37_0\n",
            "    - entrypoints==0.3=py37_0\n",
            "    - et_xmlfile==1.0.1=py37_0\n",
            "    - expat==2.2.6=he6710b0_0\n",
            "    - fastcache==1.1.0=py37h7b6447c_0\n",
            "    - filelock==3.0.12=py_0\n",
            "    - flask==1.1.1=py_0\n",
            "    - fontconfig==2.13.0=h9420a91_0\n",
            "    - freetype==2.9.1=h8a8886c_1\n",
            "    - fribidi==1.0.5=h7b6447c_0\n",
            "    - fsspec==0.5.2=py_0\n",
            "    - future==0.17.1=py37_0\n",
            "    - get_terminal_size==1.0.0=haa9412d_0\n",
            "    - gevent==1.4.0=py37h7b6447c_0\n",
            "    - glib==2.56.2=hd408876_0\n",
            "    - glob2==0.7=py_0\n",
            "    - gmp==6.1.2=h6c8ec71_1\n",
            "    - gmpy2==2.0.8=py37h10f8cd9_2\n",
            "    - graphite2==1.3.13=h23475e2_0\n",
            "    - greenlet==0.4.15=py37h7b6447c_0\n",
            "    - gst-plugins-base==1.14.0=hbbd80ab_1\n",
            "    - gstreamer==1.14.0=hb453b48_1\n",
            "    - h5py==2.9.0=py37h7918eee_0\n",
            "    - harfbuzz==1.8.8=hffaf4a1_0\n",
            "    - hdf5==1.10.4=hb1b8bf9_0\n",
            "    - heapdict==1.0.1=py_0\n",
            "    - html5lib==1.0.1=py37_0\n",
            "    - icu==58.2=h9c2bf20_1\n",
            "    - idna==2.8=py37_0\n",
            "    - imageio==2.6.0=py37_0\n",
            "    - imagesize==1.1.0=py37_0\n",
            "    - importlib_metadata==0.23=py37_0\n",
            "    - intel-openmp==2019.4=243\n",
            "    - ipykernel==5.1.2=py37h39e3cac_0\n",
            "    - ipython==7.8.0=py37h39e3cac_0\n",
            "    - ipython_genutils==0.2.0=py37_0\n",
            "    - ipywidgets==7.5.1=py_0\n",
            "    - isort==4.3.21=py37_0\n",
            "    - itsdangerous==1.1.0=py37_0\n",
            "    - jbig==2.1=hdba287a_0\n",
            "    - jdcal==1.4.1=py_0\n",
            "    - jedi==0.15.1=py37_0\n",
            "    - jeepney==0.4.1=py_0\n",
            "    - jinja2==2.10.3=py_0\n",
            "    - joblib==0.13.2=py37_0\n",
            "    - jpeg==9b=h024ee3a_2\n",
            "    - json5==0.8.5=py_0\n",
            "    - jsonschema==3.0.2=py37_0\n",
            "    - jupyter==1.0.0=py37_7\n",
            "    - jupyter_client==5.3.3=py37_1\n",
            "    - jupyter_console==6.0.0=py37_0\n",
            "    - jupyter_core==4.5.0=py_0\n",
            "    - jupyterlab==1.1.4=pyhf63ae98_0\n",
            "    - jupyterlab_server==1.0.6=py_0\n",
            "    - keyring==18.0.0=py37_0\n",
            "    - kiwisolver==1.1.0=py37he6710b0_0\n",
            "    - krb5==1.16.1=h173b8e3_7\n",
            "    - lazy-object-proxy==1.4.2=py37h7b6447c_0\n",
            "    - libarchive==3.3.3=h5d8350f_5\n",
            "    - libcurl==7.65.3=h20c2e04_0\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libgfortran-ng==7.3.0=hdf63c60_0\n",
            "    - liblief==0.9.0=h7725739_2\n",
            "    - libpng==1.6.37=hbc83047_0\n",
            "    - libsodium==1.0.16=h1bed415_0\n",
            "    - libssh2==1.8.2=h1ba5d50_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - libtiff==4.0.10=h2733197_2\n",
            "    - libtool==2.4.6=h7b6447c_5\n",
            "    - libuuid==1.0.3=h1bed415_2\n",
            "    - libxcb==1.13=h1bed415_1\n",
            "    - libxml2==2.9.9=hea5a465_1\n",
            "    - libxslt==1.1.33=h7d1a2b0_0\n",
            "    - llvmlite==0.29.0=py37hd408876_0\n",
            "    - locket==0.2.0=py37_1\n",
            "    - lxml==4.4.1=py37hefd8a0e_0\n",
            "    - lz4-c==1.8.1.2=h14c3975_0\n",
            "    - lzo==2.10=h49e0be7_2\n",
            "    - markupsafe==1.1.1=py37h7b6447c_0\n",
            "    - matplotlib==3.1.1=py37h5429711_0\n",
            "    - mccabe==0.6.1=py37_1\n",
            "    - mistune==0.8.4=py37h7b6447c_0\n",
            "    - mkl-service==2.3.0=py37he904b0f_0\n",
            "    - mkl==2019.4=243\n",
            "    - mkl_fft==1.0.14=py37ha843d7b_0\n",
            "    - mkl_random==1.1.0=py37hd6b4f25_0\n",
            "    - mock==3.0.5=py37_0\n",
            "    - more-itertools==7.2.0=py37_0\n",
            "    - mpc==1.1.0=h10f8cd9_1\n",
            "    - mpfr==4.0.1=hdf1c602_3\n",
            "    - mpmath==1.1.0=py37_0\n",
            "    - msgpack-python==0.6.1=py37hfd86e86_1\n",
            "    - multipledispatch==0.6.0=py37_0\n",
            "    - navigator-updater==0.2.1=py37_0\n",
            "    - nbconvert==5.6.0=py37_1\n",
            "    - nbformat==4.4.0=py37_0\n",
            "    - ncurses==6.1=he6710b0_1\n",
            "    - networkx==2.3=py_0\n",
            "    - nltk==3.4.5=py37_0\n",
            "    - nose==1.3.7=py37_2\n",
            "    - notebook==6.0.1=py37_0\n",
            "    - numba==0.45.1=py37h962f231_0\n",
            "    - numexpr==2.7.0=py37h9e4a6bb_0\n",
            "    - numpy-base==1.17.2=py37hde5b4d6_0\n",
            "    - numpy==1.17.2=py37haad9e8e_0\n",
            "    - numpydoc==0.9.1=py_0\n",
            "    - olefile==0.46=py37_0\n",
            "    - openpyxl==3.0.0=py_0\n",
            "    - openssl==1.1.1d=h7b6447c_2\n",
            "    - packaging==19.2=py_0\n",
            "    - pandas==0.25.1=py37he6710b0_0\n",
            "    - pandoc==2.2.3.2=0\n",
            "    - pandocfilters==1.4.2=py37_1\n",
            "    - pango==1.42.4=h049681c_0\n",
            "    - parso==0.5.1=py_0\n",
            "    - partd==1.0.0=py_0\n",
            "    - patchelf==0.9=he6710b0_3\n",
            "    - path.py==12.0.1=py_0\n",
            "    - pathlib2==2.3.5=py37_0\n",
            "    - patsy==0.5.1=py37_0\n",
            "    - pcre==8.43=he6710b0_0\n",
            "    - pep8==1.7.1=py37_0\n",
            "    - pexpect==4.7.0=py37_0\n",
            "    - pickleshare==0.7.5=py37_0\n",
            "    - pillow==6.2.0=py37h34e0f95_0\n",
            "    - pip==19.2.3=py37_0\n",
            "    - pixman==0.38.0=h7b6447c_0\n",
            "    - pkginfo==1.5.0.1=py37_0\n",
            "    - pluggy==0.13.0=py37_0\n",
            "    - ply==3.11=py37_0\n",
            "    - prometheus_client==0.7.1=py_0\n",
            "    - prompt_toolkit==2.0.10=py_0\n",
            "    - psutil==5.6.3=py37h7b6447c_0\n",
            "    - ptyprocess==0.6.0=py37_0\n",
            "    - py-lief==0.9.0=py37h7725739_2\n",
            "    - py==1.8.0=py37_0\n",
            "    - pycodestyle==2.5.0=py37_0\n",
            "    - pycosat==0.6.3=py37h14c3975_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pycrypto==2.6.1=py37h14c3975_9\n",
            "    - pycurl==7.43.0.3=py37h1ba5d50_0\n",
            "    - pyflakes==2.1.1=py37_0\n",
            "    - pygments==2.4.2=py_0\n",
            "    - pylint==2.4.2=py37_0\n",
            "    - pyodbc==4.0.27=py37he6710b0_0\n",
            "    - pyopenssl==19.0.0=py37_0\n",
            "    - pyparsing==2.4.2=py_0\n",
            "    - pyqt==5.9.2=py37h05f1152_2\n",
            "    - pyrsistent==0.15.4=py37h7b6447c_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - pytables==3.5.2=py37h71ec239_1\n",
            "    - pytest-arraydiff==0.3=py37h39e3cac_0\n",
            "    - pytest-astropy==0.5.0=py37_0\n",
            "    - pytest-doctestplus==0.4.0=py_0\n",
            "    - pytest-openfiles==0.4.0=py_0\n",
            "    - pytest-remotedata==0.3.2=py37_0\n",
            "    - pytest==5.2.1=py37_0\n",
            "    - python-dateutil==2.8.0=py37_0\n",
            "    - python-libarchive-c==2.8=py37_13\n",
            "    - python==3.7.4=h265db76_1\n",
            "    - pytz==2019.3=py_0\n",
            "    - pywavelets==1.0.3=py37hdd07704_1\n",
            "    - pyyaml==5.1.2=py37h7b6447c_0\n",
            "    - pyzmq==18.1.0=py37he6710b0_0\n",
            "    - qt==5.9.7=h5867ecd_1\n",
            "    - qtawesome==0.6.0=py_0\n",
            "    - qtconsole==4.5.5=py_0\n",
            "    - qtpy==1.9.0=py_0\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_0\n",
            "    - ripgrep==0.10.0=hc07d326_0\n",
            "    - rope==0.14.0=py_0\n",
            "    - ruamel_yaml==0.15.46=py37h14c3975_0\n",
            "    - scikit-image==0.15.0=py37he6710b0_0\n",
            "    - scikit-learn==0.21.3=py37hd81dba3_0\n",
            "    - scipy==1.3.1=py37h7c811a0_0\n",
            "    - seaborn==0.9.0=py37_0\n",
            "    - secretstorage==3.1.1=py37_0\n",
            "    - send2trash==1.5.0=py37_0\n",
            "    - setuptools==41.4.0=py37_0\n",
            "    - simplegeneric==0.8.1=py37_2\n",
            "    - singledispatch==3.4.0.3=py37_0\n",
            "    - sip==4.19.8=py37hf484d3e_0\n",
            "    - six==1.12.0=py37_0\n",
            "    - snappy==1.1.7=hbae5bb6_3\n",
            "    - snowballstemmer==2.0.0=py_0\n",
            "    - sortedcollections==1.1.2=py37_0\n",
            "    - sortedcontainers==2.1.0=py37_0\n",
            "    - soupsieve==1.9.3=py37_0\n",
            "    - sphinx==2.2.0=py_0\n",
            "    - sphinxcontrib-applehelp==1.0.1=py_0\n",
            "    - sphinxcontrib-devhelp==1.0.1=py_0\n",
            "    - sphinxcontrib-htmlhelp==1.0.2=py_0\n",
            "    - sphinxcontrib-jsmath==1.0.1=py_0\n",
            "    - sphinxcontrib-qthelp==1.0.2=py_0\n",
            "    - sphinxcontrib-serializinghtml==1.1.3=py_0\n",
            "    - sphinxcontrib-websupport==1.1.2=py_0\n",
            "    - sphinxcontrib==1.0=py37_1\n",
            "    - spyder-kernels==0.5.2=py37_0\n",
            "    - spyder==3.3.6=py37_0\n",
            "    - sqlalchemy==1.3.9=py37h7b6447c_0\n",
            "    - sqlite==3.30.0=h7b6447c_0\n",
            "    - statsmodels==0.10.1=py37hdd07704_0\n",
            "    - sympy==1.4=py37_0\n",
            "    - tbb==2019.4=hfd86e86_0\n",
            "    - tblib==1.4.0=py_0\n",
            "    - terminado==0.8.2=py37_0\n",
            "    - testpath==0.4.2=py37_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - toolz==0.10.0=py_0\n",
            "    - tornado==6.0.3=py37h7b6447c_0\n",
            "    - tqdm==4.36.1=py_0\n",
            "    - traitlets==4.3.3=py37_0\n",
            "    - unicodecsv==0.14.1=py37_0\n",
            "    - unixodbc==2.3.7=h14c3975_0\n",
            "    - urllib3==1.24.2=py37_0\n",
            "    - wcwidth==0.1.7=py37_0\n",
            "    - webencodings==0.5.1=py37_1\n",
            "    - werkzeug==0.16.0=py_0\n",
            "    - wheel==0.33.6=py37_0\n",
            "    - widgetsnbextension==3.5.1=py37_0\n",
            "    - wrapt==1.11.2=py37h7b6447c_0\n",
            "    - wurlitzer==1.0.3=py37_0\n",
            "    - xlrd==1.2.0=py37_0\n",
            "    - xlsxwriter==1.2.1=py_0\n",
            "    - xlwt==1.3.0=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zeromq==4.3.1=he6710b0_3\n",
            "    - zict==1.0.0=py_0\n",
            "    - zipp==0.6.0=py_0\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "    - zstd==1.3.7=h0b5b093_0\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _ipyw_jlab_nb_ext~ pkgs/main/linux-64::_ipyw_jlab_nb_ext_conf-0.1.0-py37_0\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  alabaster          pkgs/main/linux-64::alabaster-0.7.12-py37_0\n",
            "  anaconda           pkgs/main/linux-64::anaconda-2019.10-py37_0\n",
            "  anaconda-client    pkgs/main/linux-64::anaconda-client-1.7.2-py37_0\n",
            "  anaconda-navigator pkgs/main/linux-64::anaconda-navigator-1.9.7-py37_0\n",
            "  anaconda-project   pkgs/main/noarch::anaconda-project-0.8.3-py_0\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.0.1-py37_0\n",
            "  astroid            pkgs/main/linux-64::astroid-2.3.1-py37_0\n",
            "  astropy            pkgs/main/linux-64::astropy-3.2.2-py37h7b6447c_0\n",
            "  atomicwrites       pkgs/main/linux-64::atomicwrites-1.3.0-py37_1\n",
            "  attrs              pkgs/main/noarch::attrs-19.2.0-py_0\n",
            "  babel              pkgs/main/noarch::babel-2.7.0-py_0\n",
            "  backcall           pkgs/main/linux-64::backcall-0.1.0-py37_0\n",
            "  backports          pkgs/main/noarch::backports-1.0-py_2\n",
            "  backports.functoo~ pkgs/main/noarch::backports.functools_lru_cache-1.5-py_2\n",
            "  backports.os       pkgs/main/linux-64::backports.os-0.1.1-py37_0\n",
            "  backports.shutil_~ pkgs/main/linux-64::backports.shutil_get_terminal_size-1.0.0-py37_2\n",
            "  backports.tempfile pkgs/main/noarch::backports.tempfile-1.0-py_1\n",
            "  backports.weakref  pkgs/main/noarch::backports.weakref-1.0.post1-py_1\n",
            "  beautifulsoup4     pkgs/main/linux-64::beautifulsoup4-4.8.0-py37_0\n",
            "  bitarray           pkgs/main/linux-64::bitarray-1.0.1-py37h7b6447c_0\n",
            "  bkcharts           pkgs/main/linux-64::bkcharts-0.2-py37_0\n",
            "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
            "  bleach             pkgs/main/linux-64::bleach-3.1.0-py37_0\n",
            "  blosc              pkgs/main/linux-64::blosc-1.16.3-hd408876_0\n",
            "  bokeh              pkgs/main/linux-64::bokeh-1.3.4-py37_0\n",
            "  boto               pkgs/main/linux-64::boto-2.49.0-py37_0\n",
            "  bottleneck         pkgs/main/linux-64::bottleneck-1.2.1-py37h035aef0_1\n",
            "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2019.8.28-0\n",
            "  cairo              pkgs/main/linux-64::cairo-1.14.12-h8948797_3\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.9.11-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.12.3-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  click              pkgs/main/linux-64::click-7.0-py37_0\n",
            "  cloudpickle        pkgs/main/noarch::cloudpickle-1.2.2-py_0\n",
            "  clyent             pkgs/main/linux-64::clyent-1.2.2-py37_1\n",
            "  colorama           pkgs/main/linux-64::colorama-0.4.1-py37_0\n",
            "  conda              pkgs/main/linux-64::conda-4.7.12-py37_0\n",
            "  conda-build        pkgs/main/linux-64::conda-build-3.18.9-py37_3\n",
            "  conda-env          pkgs/main/linux-64::conda-env-2.6.0-1\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  conda-verify       pkgs/main/noarch::conda-verify-3.4.2-py_1\n",
            "  contextlib2        pkgs/main/noarch::contextlib2-0.6.0-py_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.7-py37h1ba5d50_0\n",
            "  curl               pkgs/main/linux-64::curl-7.65.3-hbc83047_0\n",
            "  cycler             pkgs/main/linux-64::cycler-0.10.0-py37_0\n",
            "  cython             pkgs/main/linux-64::cython-0.29.13-py37he6710b0_0\n",
            "  cytoolz            pkgs/main/linux-64::cytoolz-0.10.0-py37h7b6447c_0\n",
            "  dask               pkgs/main/noarch::dask-2.5.2-py_0\n",
            "  dask-core          pkgs/main/noarch::dask-core-2.5.2-py_0\n",
            "  dbus               pkgs/main/linux-64::dbus-1.13.6-h746ee38_0\n",
            "  decorator          pkgs/main/linux-64::decorator-4.4.0-py37_1\n",
            "  defusedxml         pkgs/main/noarch::defusedxml-0.6.0-py_0\n",
            "  distributed        pkgs/main/noarch::distributed-2.5.2-py_0\n",
            "  docutils           pkgs/main/linux-64::docutils-0.15.2-py37_0\n",
            "  entrypoints        pkgs/main/linux-64::entrypoints-0.3-py37_0\n",
            "  et_xmlfile         pkgs/main/linux-64::et_xmlfile-1.0.1-py37_0\n",
            "  expat              pkgs/main/linux-64::expat-2.2.6-he6710b0_0\n",
            "  fastcache          pkgs/main/linux-64::fastcache-1.1.0-py37h7b6447c_0\n",
            "  filelock           pkgs/main/noarch::filelock-3.0.12-py_0\n",
            "  flask              pkgs/main/noarch::flask-1.1.1-py_0\n",
            "  fontconfig         pkgs/main/linux-64::fontconfig-2.13.0-h9420a91_0\n",
            "  freetype           pkgs/main/linux-64::freetype-2.9.1-h8a8886c_1\n",
            "  fribidi            pkgs/main/linux-64::fribidi-1.0.5-h7b6447c_0\n",
            "  fsspec             pkgs/main/noarch::fsspec-0.5.2-py_0\n",
            "  future             pkgs/main/linux-64::future-0.17.1-py37_0\n",
            "  get_terminal_size  pkgs/main/linux-64::get_terminal_size-1.0.0-haa9412d_0\n",
            "  gevent             pkgs/main/linux-64::gevent-1.4.0-py37h7b6447c_0\n",
            "  glib               pkgs/main/linux-64::glib-2.56.2-hd408876_0\n",
            "  glob2              pkgs/main/noarch::glob2-0.7-py_0\n",
            "  gmp                pkgs/main/linux-64::gmp-6.1.2-h6c8ec71_1\n",
            "  gmpy2              pkgs/main/linux-64::gmpy2-2.0.8-py37h10f8cd9_2\n",
            "  graphite2          pkgs/main/linux-64::graphite2-1.3.13-h23475e2_0\n",
            "  greenlet           pkgs/main/linux-64::greenlet-0.4.15-py37h7b6447c_0\n",
            "  gst-plugins-base   pkgs/main/linux-64::gst-plugins-base-1.14.0-hbbd80ab_1\n",
            "  gstreamer          pkgs/main/linux-64::gstreamer-1.14.0-hb453b48_1\n",
            "  h5py               pkgs/main/linux-64::h5py-2.9.0-py37h7918eee_0\n",
            "  harfbuzz           pkgs/main/linux-64::harfbuzz-1.8.8-hffaf4a1_0\n",
            "  hdf5               pkgs/main/linux-64::hdf5-1.10.4-hb1b8bf9_0\n",
            "  heapdict           pkgs/main/noarch::heapdict-1.0.1-py_0\n",
            "  html5lib           pkgs/main/linux-64::html5lib-1.0.1-py37_0\n",
            "  icu                pkgs/main/linux-64::icu-58.2-h9c2bf20_1\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  imageio            pkgs/main/linux-64::imageio-2.6.0-py37_0\n",
            "  imagesize          pkgs/main/linux-64::imagesize-1.1.0-py37_0\n",
            "  importlib_metadata pkgs/main/linux-64::importlib_metadata-0.23-py37_0\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2019.4-243\n",
            "  ipykernel          pkgs/main/linux-64::ipykernel-5.1.2-py37h39e3cac_0\n",
            "  ipython            pkgs/main/linux-64::ipython-7.8.0-py37h39e3cac_0\n",
            "  ipython_genutils   pkgs/main/linux-64::ipython_genutils-0.2.0-py37_0\n",
            "  ipywidgets         pkgs/main/noarch::ipywidgets-7.5.1-py_0\n",
            "  isort              pkgs/main/linux-64::isort-4.3.21-py37_0\n",
            "  itsdangerous       pkgs/main/linux-64::itsdangerous-1.1.0-py37_0\n",
            "  jbig               pkgs/main/linux-64::jbig-2.1-hdba287a_0\n",
            "  jdcal              pkgs/main/noarch::jdcal-1.4.1-py_0\n",
            "  jedi               pkgs/main/linux-64::jedi-0.15.1-py37_0\n",
            "  jeepney            pkgs/main/noarch::jeepney-0.4.1-py_0\n",
            "  jinja2             pkgs/main/noarch::jinja2-2.10.3-py_0\n",
            "  joblib             pkgs/main/linux-64::joblib-0.13.2-py37_0\n",
            "  jpeg               pkgs/main/linux-64::jpeg-9b-h024ee3a_2\n",
            "  json5              pkgs/main/noarch::json5-0.8.5-py_0\n",
            "  jsonschema         pkgs/main/linux-64::jsonschema-3.0.2-py37_0\n",
            "  jupyter            pkgs/main/linux-64::jupyter-1.0.0-py37_7\n",
            "  jupyter_client     pkgs/main/linux-64::jupyter_client-5.3.3-py37_1\n",
            "  jupyter_console    pkgs/main/linux-64::jupyter_console-6.0.0-py37_0\n",
            "  jupyter_core       pkgs/main/noarch::jupyter_core-4.5.0-py_0\n",
            "  jupyterlab         pkgs/main/noarch::jupyterlab-1.1.4-pyhf63ae98_0\n",
            "  jupyterlab_server  pkgs/main/noarch::jupyterlab_server-1.0.6-py_0\n",
            "  keyring            pkgs/main/linux-64::keyring-18.0.0-py37_0\n",
            "  kiwisolver         pkgs/main/linux-64::kiwisolver-1.1.0-py37he6710b0_0\n",
            "  krb5               pkgs/main/linux-64::krb5-1.16.1-h173b8e3_7\n",
            "  lazy-object-proxy  pkgs/main/linux-64::lazy-object-proxy-1.4.2-py37h7b6447c_0\n",
            "  libarchive         pkgs/main/linux-64::libarchive-3.3.3-h5d8350f_5\n",
            "  libcurl            pkgs/main/linux-64::libcurl-7.65.3-h20c2e04_0\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libgfortran-ng     pkgs/main/linux-64::libgfortran-ng-7.3.0-hdf63c60_0\n",
            "  liblief            pkgs/main/linux-64::liblief-0.9.0-h7725739_2\n",
            "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0\n",
            "  libsodium          pkgs/main/linux-64::libsodium-1.0.16-h1bed415_0\n",
            "  libssh2            pkgs/main/linux-64::libssh2-1.8.2-h1ba5d50_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  libtiff            pkgs/main/linux-64::libtiff-4.0.10-h2733197_2\n",
            "  libtool            pkgs/main/linux-64::libtool-2.4.6-h7b6447c_5\n",
            "  libuuid            pkgs/main/linux-64::libuuid-1.0.3-h1bed415_2\n",
            "  libxcb             pkgs/main/linux-64::libxcb-1.13-h1bed415_1\n",
            "  libxml2            pkgs/main/linux-64::libxml2-2.9.9-hea5a465_1\n",
            "  libxslt            pkgs/main/linux-64::libxslt-1.1.33-h7d1a2b0_0\n",
            "  llvmlite           pkgs/main/linux-64::llvmlite-0.29.0-py37hd408876_0\n",
            "  locket             pkgs/main/linux-64::locket-0.2.0-py37_1\n",
            "  lxml               pkgs/main/linux-64::lxml-4.4.1-py37hefd8a0e_0\n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.8.1.2-h14c3975_0\n",
            "  lzo                pkgs/main/linux-64::lzo-2.10-h49e0be7_2\n",
            "  markupsafe         pkgs/main/linux-64::markupsafe-1.1.1-py37h7b6447c_0\n",
            "  matplotlib         pkgs/main/linux-64::matplotlib-3.1.1-py37h5429711_0\n",
            "  mccabe             pkgs/main/linux-64::mccabe-0.6.1-py37_1\n",
            "  mistune            pkgs/main/linux-64::mistune-0.8.4-py37h7b6447c_0\n",
            "  mkl                pkgs/main/linux-64::mkl-2019.4-243\n",
            "  mkl-service        pkgs/main/linux-64::mkl-service-2.3.0-py37he904b0f_0\n",
            "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.0.14-py37ha843d7b_0\n",
            "  mkl_random         pkgs/main/linux-64::mkl_random-1.1.0-py37hd6b4f25_0\n",
            "  mock               pkgs/main/linux-64::mock-3.0.5-py37_0\n",
            "  more-itertools     pkgs/main/linux-64::more-itertools-7.2.0-py37_0\n",
            "  mpc                pkgs/main/linux-64::mpc-1.1.0-h10f8cd9_1\n",
            "  mpfr               pkgs/main/linux-64::mpfr-4.0.1-hdf1c602_3\n",
            "  mpmath             pkgs/main/linux-64::mpmath-1.1.0-py37_0\n",
            "  msgpack-python     pkgs/main/linux-64::msgpack-python-0.6.1-py37hfd86e86_1\n",
            "  multipledispatch   pkgs/main/linux-64::multipledispatch-0.6.0-py37_0\n",
            "  navigator-updater  pkgs/main/linux-64::navigator-updater-0.2.1-py37_0\n",
            "  nbconvert          pkgs/main/linux-64::nbconvert-5.6.0-py37_1\n",
            "  nbformat           pkgs/main/linux-64::nbformat-4.4.0-py37_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.1-he6710b0_1\n",
            "  networkx           pkgs/main/noarch::networkx-2.3-py_0\n",
            "  nltk               pkgs/main/linux-64::nltk-3.4.5-py37_0\n",
            "  nose               pkgs/main/linux-64::nose-1.3.7-py37_2\n",
            "  notebook           pkgs/main/linux-64::notebook-6.0.1-py37_0\n",
            "  numba              pkgs/main/linux-64::numba-0.45.1-py37h962f231_0\n",
            "  numexpr            pkgs/main/linux-64::numexpr-2.7.0-py37h9e4a6bb_0\n",
            "  numpy              pkgs/main/linux-64::numpy-1.17.2-py37haad9e8e_0\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.17.2-py37hde5b4d6_0\n",
            "  numpydoc           pkgs/main/noarch::numpydoc-0.9.1-py_0\n",
            "  olefile            pkgs/main/linux-64::olefile-0.46-py37_0\n",
            "  openpyxl           pkgs/main/noarch::openpyxl-3.0.0-py_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_2\n",
            "  packaging          pkgs/main/noarch::packaging-19.2-py_0\n",
            "  pandas             pkgs/main/linux-64::pandas-0.25.1-py37he6710b0_0\n",
            "  pandoc             pkgs/main/linux-64::pandoc-2.2.3.2-0\n",
            "  pandocfilters      pkgs/main/linux-64::pandocfilters-1.4.2-py37_1\n",
            "  pango              pkgs/main/linux-64::pango-1.42.4-h049681c_0\n",
            "  parso              pkgs/main/noarch::parso-0.5.1-py_0\n",
            "  partd              pkgs/main/noarch::partd-1.0.0-py_0\n",
            "  patchelf           pkgs/main/linux-64::patchelf-0.9-he6710b0_3\n",
            "  path.py            pkgs/main/noarch::path.py-12.0.1-py_0\n",
            "  pathlib2           pkgs/main/linux-64::pathlib2-2.3.5-py37_0\n",
            "  patsy              pkgs/main/linux-64::patsy-0.5.1-py37_0\n",
            "  pcre               pkgs/main/linux-64::pcre-8.43-he6710b0_0\n",
            "  pep8               pkgs/main/linux-64::pep8-1.7.1-py37_0\n",
            "  pexpect            pkgs/main/linux-64::pexpect-4.7.0-py37_0\n",
            "  pickleshare        pkgs/main/linux-64::pickleshare-0.7.5-py37_0\n",
            "  pillow             pkgs/main/linux-64::pillow-6.2.0-py37h34e0f95_0\n",
            "  pip                pkgs/main/linux-64::pip-19.2.3-py37_0\n",
            "  pixman             pkgs/main/linux-64::pixman-0.38.0-h7b6447c_0\n",
            "  pkginfo            pkgs/main/linux-64::pkginfo-1.5.0.1-py37_0\n",
            "  pluggy             pkgs/main/linux-64::pluggy-0.13.0-py37_0\n",
            "  ply                pkgs/main/linux-64::ply-3.11-py37_0\n",
            "  prometheus_client  pkgs/main/noarch::prometheus_client-0.7.1-py_0\n",
            "  prompt_toolkit     pkgs/main/noarch::prompt_toolkit-2.0.10-py_0\n",
            "  psutil             pkgs/main/linux-64::psutil-5.6.3-py37h7b6447c_0\n",
            "  ptyprocess         pkgs/main/linux-64::ptyprocess-0.6.0-py37_0\n",
            "  py                 pkgs/main/linux-64::py-1.8.0-py37_0\n",
            "  py-lief            pkgs/main/linux-64::py-lief-0.9.0-py37h7725739_2\n",
            "  pycodestyle        pkgs/main/linux-64::pycodestyle-2.5.0-py37_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h14c3975_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pycrypto           pkgs/main/linux-64::pycrypto-2.6.1-py37h14c3975_9\n",
            "  pycurl             pkgs/main/linux-64::pycurl-7.43.0.3-py37h1ba5d50_0\n",
            "  pyflakes           pkgs/main/linux-64::pyflakes-2.1.1-py37_0\n",
            "  pygments           pkgs/main/noarch::pygments-2.4.2-py_0\n",
            "  pylint             pkgs/main/linux-64::pylint-2.4.2-py37_0\n",
            "  pyodbc             pkgs/main/linux-64::pyodbc-4.0.27-py37he6710b0_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.0.0-py37_0\n",
            "  pyparsing          pkgs/main/noarch::pyparsing-2.4.2-py_0\n",
            "  pyqt               pkgs/main/linux-64::pyqt-5.9.2-py37h05f1152_2\n",
            "  pyrsistent         pkgs/main/linux-64::pyrsistent-0.15.4-py37h7b6447c_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  pytables           pkgs/main/linux-64::pytables-3.5.2-py37h71ec239_1\n",
            "  pytest             pkgs/main/linux-64::pytest-5.2.1-py37_0\n",
            "  pytest-arraydiff   pkgs/main/linux-64::pytest-arraydiff-0.3-py37h39e3cac_0\n",
            "  pytest-astropy     pkgs/main/linux-64::pytest-astropy-0.5.0-py37_0\n",
            "  pytest-doctestplus pkgs/main/noarch::pytest-doctestplus-0.4.0-py_0\n",
            "  pytest-openfiles   pkgs/main/noarch::pytest-openfiles-0.4.0-py_0\n",
            "  pytest-remotedata  pkgs/main/linux-64::pytest-remotedata-0.3.2-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.4-h265db76_1\n",
            "  python-dateutil    pkgs/main/linux-64::python-dateutil-2.8.0-py37_0\n",
            "  python-libarchive~ pkgs/main/linux-64::python-libarchive-c-2.8-py37_13\n",
            "  pytz               pkgs/main/noarch::pytz-2019.3-py_0\n",
            "  pywavelets         pkgs/main/linux-64::pywavelets-1.0.3-py37hdd07704_1\n",
            "  pyyaml             pkgs/main/linux-64::pyyaml-5.1.2-py37h7b6447c_0\n",
            "  pyzmq              pkgs/main/linux-64::pyzmq-18.1.0-py37he6710b0_0\n",
            "  qt                 pkgs/main/linux-64::qt-5.9.7-h5867ecd_1\n",
            "  qtawesome          pkgs/main/noarch::qtawesome-0.6.0-py_0\n",
            "  qtconsole          pkgs/main/noarch::qtconsole-4.5.5-py_0\n",
            "  qtpy               pkgs/main/noarch::qtpy-1.9.0-py_0\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_0\n",
            "  ripgrep            pkgs/main/linux-64::ripgrep-0.10.0-hc07d326_0\n",
            "  rope               pkgs/main/noarch::rope-0.14.0-py_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.46-py37h14c3975_0\n",
            "  scikit-image       pkgs/main/linux-64::scikit-image-0.15.0-py37he6710b0_0\n",
            "  scikit-learn       pkgs/main/linux-64::scikit-learn-0.21.3-py37hd81dba3_0\n",
            "  scipy              pkgs/main/linux-64::scipy-1.3.1-py37h7c811a0_0\n",
            "  seaborn            pkgs/main/linux-64::seaborn-0.9.0-py37_0\n",
            "  secretstorage      pkgs/main/linux-64::secretstorage-3.1.1-py37_0\n",
            "  send2trash         pkgs/main/linux-64::send2trash-1.5.0-py37_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-41.4.0-py37_0\n",
            "  simplegeneric      pkgs/main/linux-64::simplegeneric-0.8.1-py37_2\n",
            "  singledispatch     pkgs/main/linux-64::singledispatch-3.4.0.3-py37_0\n",
            "  sip                pkgs/main/linux-64::sip-4.19.8-py37hf484d3e_0\n",
            "  six                pkgs/main/linux-64::six-1.12.0-py37_0\n",
            "  snappy             pkgs/main/linux-64::snappy-1.1.7-hbae5bb6_3\n",
            "  snowballstemmer    pkgs/main/noarch::snowballstemmer-2.0.0-py_0\n",
            "  sortedcollections  pkgs/main/linux-64::sortedcollections-1.1.2-py37_0\n",
            "  sortedcontainers   pkgs/main/linux-64::sortedcontainers-2.1.0-py37_0\n",
            "  soupsieve          pkgs/main/linux-64::soupsieve-1.9.3-py37_0\n",
            "  sphinx             pkgs/main/noarch::sphinx-2.2.0-py_0\n",
            "  sphinxcontrib      pkgs/main/linux-64::sphinxcontrib-1.0-py37_1\n",
            "  sphinxcontrib-app~ pkgs/main/noarch::sphinxcontrib-applehelp-1.0.1-py_0\n",
            "  sphinxcontrib-dev~ pkgs/main/noarch::sphinxcontrib-devhelp-1.0.1-py_0\n",
            "  sphinxcontrib-htm~ pkgs/main/noarch::sphinxcontrib-htmlhelp-1.0.2-py_0\n",
            "  sphinxcontrib-jsm~ pkgs/main/noarch::sphinxcontrib-jsmath-1.0.1-py_0\n",
            "  sphinxcontrib-qth~ pkgs/main/noarch::sphinxcontrib-qthelp-1.0.2-py_0\n",
            "  sphinxcontrib-ser~ pkgs/main/noarch::sphinxcontrib-serializinghtml-1.1.3-py_0\n",
            "  sphinxcontrib-web~ pkgs/main/noarch::sphinxcontrib-websupport-1.1.2-py_0\n",
            "  spyder             pkgs/main/linux-64::spyder-3.3.6-py37_0\n",
            "  spyder-kernels     pkgs/main/linux-64::spyder-kernels-0.5.2-py37_0\n",
            "  sqlalchemy         pkgs/main/linux-64::sqlalchemy-1.3.9-py37h7b6447c_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.30.0-h7b6447c_0\n",
            "  statsmodels        pkgs/main/linux-64::statsmodels-0.10.1-py37hdd07704_0\n",
            "  sympy              pkgs/main/linux-64::sympy-1.4-py37_0\n",
            "  tbb                pkgs/main/linux-64::tbb-2019.4-hfd86e86_0\n",
            "  tblib              pkgs/main/noarch::tblib-1.4.0-py_0\n",
            "  terminado          pkgs/main/linux-64::terminado-0.8.2-py37_0\n",
            "  testpath           pkgs/main/linux-64::testpath-0.4.2-py37_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  toolz              pkgs/main/noarch::toolz-0.10.0-py_0\n",
            "  tornado            pkgs/main/linux-64::tornado-6.0.3-py37h7b6447c_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.36.1-py_0\n",
            "  traitlets          pkgs/main/linux-64::traitlets-4.3.3-py37_0\n",
            "  unicodecsv         pkgs/main/linux-64::unicodecsv-0.14.1-py37_0\n",
            "  unixodbc           pkgs/main/linux-64::unixodbc-2.3.7-h14c3975_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.24.2-py37_0\n",
            "  wcwidth            pkgs/main/linux-64::wcwidth-0.1.7-py37_0\n",
            "  webencodings       pkgs/main/linux-64::webencodings-0.5.1-py37_1\n",
            "  werkzeug           pkgs/main/noarch::werkzeug-0.16.0-py_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.33.6-py37_0\n",
            "  widgetsnbextension pkgs/main/linux-64::widgetsnbextension-3.5.1-py37_0\n",
            "  wrapt              pkgs/main/linux-64::wrapt-1.11.2-py37h7b6447c_0\n",
            "  wurlitzer          pkgs/main/linux-64::wurlitzer-1.0.3-py37_0\n",
            "  xlrd               pkgs/main/linux-64::xlrd-1.2.0-py37_0\n",
            "  xlsxwriter         pkgs/main/noarch::xlsxwriter-1.2.1-py_0\n",
            "  xlwt               pkgs/main/linux-64::xlwt-1.3.0-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zeromq             pkgs/main/linux-64::zeromq-4.3.1-he6710b0_3\n",
            "  zict               pkgs/main/noarch::zict-1.0.0-py_0\n",
            "  zipp               pkgs/main/noarch::zipp-0.6.0-py_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "  zstd               pkgs/main/linux-64::zstd-1.3.7-h0b5b093_0\n",
            "\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Anaconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Anaconda3: /usr/local\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.7.12\n",
            "  latest version: 4.10.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - deepchem-gpu=2.3.0\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB  conda-forge\n",
            "    _tflow_select-2.1.0        |              gpu           2 KB\n",
            "    absl-py-0.12.0             |     pyhd8ed1ab_0          96 KB  conda-forge\n",
            "    astor-0.8.1                |     pyh9f0ad1d_0          25 KB  conda-forge\n",
            "    astunparse-1.6.3           |     pyhd8ed1ab_0          15 KB  conda-forge\n",
            "    c-ares-1.17.1              |       h36c2ea0_0         111 KB  conda-forge\n",
            "    certifi-2019.9.11          |           py37_0         147 KB  conda-forge\n",
            "    conda-4.10.0               |   py37h89c1867_1         3.1 MB  conda-forge\n",
            "    cudatoolkit-10.1.243       |       h6bb024c_0       347.4 MB\n",
            "    cudnn-7.6.5.32             |       hc0a50b0_1       250.7 MB  conda-forge\n",
            "    cupti-10.1.168             |                0         1.4 MB\n",
            "    deepchem-gpu-2.3.0         |           py37_0         2.1 MB  deepchem\n",
            "    fftw3f-3.3.4               |                2         1.2 MB  omnia\n",
            "    gast-0.4.0                 |     pyh9f0ad1d_0          12 KB  conda-forge\n",
            "    google-pasta-0.2.0         |     pyh8c360ce_0          42 KB  conda-forge\n",
            "    grpcio-1.23.0              |   py37hb0870dc_1         1.1 MB  conda-forge\n",
            "    importlib-metadata-3.10.1  |   py37h89c1867_0          27 KB  conda-forge\n",
            "    keras-applications-1.0.8   |             py_1          30 KB  conda-forge\n",
            "    keras-preprocessing-1.1.2  |     pyhd8ed1ab_0          34 KB  conda-forge\n",
            "    libboost-1.67.0            |       h46d08c1_4        13.0 MB\n",
            "    libprotobuf-3.13.0.1       |       h8b12597_0         2.3 MB  conda-forge\n",
            "    libxgboost-1.2.0           |       he1b5a44_0         3.1 MB  conda-forge\n",
            "    markdown-3.3.4             |     pyhd8ed1ab_0          67 KB  conda-forge\n",
            "    mdtraj-1.9.5               |   py37h113d463_0         1.7 MB  conda-forge\n",
            "    openmm-7.4.2               |py37_cuda101_rc_1        11.9 MB  omnia\n",
            "    pdbfixer-1.6               |             py_1         167 KB  omnia\n",
            "    protobuf-3.13.0.1          |   py37h745909e_1         704 KB  conda-forge\n",
            "    py-boost-1.67.0            |   py37h04863e7_4         278 KB\n",
            "    py-xgboost-1.2.0           |   py37hc8dfbb8_0         1.7 MB  conda-forge\n",
            "    python_abi-3.7             |          1_cp37m           4 KB  conda-forge\n",
            "    rdkit-2020.03.3.0          |   py37hc20afe1_1        24.8 MB  rdkit\n",
            "    simdna-0.4.2               |             py_0         627 KB  deepchem\n",
            "    tensorboard-1.14.0         |           py37_0         3.2 MB  conda-forge\n",
            "    tensorflow-1.14.0          |gpu_py37h74c33d7_0           4 KB\n",
            "    tensorflow-base-1.14.0     |gpu_py37he45bfe2_0       146.3 MB\n",
            "    tensorflow-estimator-1.14.0|   py37h5ca1d4c_0         645 KB  conda-forge\n",
            "    tensorflow-gpu-1.14.0      |       h0d30ee6_0           3 KB\n",
            "    termcolor-1.1.0            |             py_2           6 KB  conda-forge\n",
            "    typing_extensions-3.7.4.3  |             py_0          25 KB  conda-forge\n",
            "    xgboost-1.2.0              |   py37h3340039_0          11 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       817.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _py-xgboost-mutex  conda-forge/linux-64::_py-xgboost-mutex-2.0-cpu_0\n",
            "  _tflow_select      pkgs/main/linux-64::_tflow_select-2.1.0-gpu\n",
            "  absl-py            conda-forge/noarch::absl-py-0.12.0-pyhd8ed1ab_0\n",
            "  astor              conda-forge/noarch::astor-0.8.1-pyh9f0ad1d_0\n",
            "  astunparse         conda-forge/noarch::astunparse-1.6.3-pyhd8ed1ab_0\n",
            "  c-ares             conda-forge/linux-64::c-ares-1.17.1-h36c2ea0_0\n",
            "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.1.243-h6bb024c_0\n",
            "  cudnn              conda-forge/linux-64::cudnn-7.6.5.32-hc0a50b0_1\n",
            "  cupti              pkgs/main/linux-64::cupti-10.1.168-0\n",
            "  deepchem-gpu       deepchem/linux-64::deepchem-gpu-2.3.0-py37_0\n",
            "  fftw3f             omnia/linux-64::fftw3f-3.3.4-2\n",
            "  gast               conda-forge/noarch::gast-0.4.0-pyh9f0ad1d_0\n",
            "  google-pasta       conda-forge/noarch::google-pasta-0.2.0-pyh8c360ce_0\n",
            "  grpcio             conda-forge/linux-64::grpcio-1.23.0-py37hb0870dc_1\n",
            "  importlib-metadata conda-forge/linux-64::importlib-metadata-3.10.1-py37h89c1867_0\n",
            "  keras-applications conda-forge/noarch::keras-applications-1.0.8-py_1\n",
            "  keras-preprocessi~ conda-forge/noarch::keras-preprocessing-1.1.2-pyhd8ed1ab_0\n",
            "  libboost           pkgs/main/linux-64::libboost-1.67.0-h46d08c1_4\n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-3.13.0.1-h8b12597_0\n",
            "  libxgboost         conda-forge/linux-64::libxgboost-1.2.0-he1b5a44_0\n",
            "  markdown           conda-forge/noarch::markdown-3.3.4-pyhd8ed1ab_0\n",
            "  mdtraj             conda-forge/linux-64::mdtraj-1.9.5-py37h113d463_0\n",
            "  openmm             omnia/linux-64::openmm-7.4.2-py37_cuda101_rc_1\n",
            "  pdbfixer           omnia/noarch::pdbfixer-1.6-py_1\n",
            "  protobuf           conda-forge/linux-64::protobuf-3.13.0.1-py37h745909e_1\n",
            "  py-boost           pkgs/main/linux-64::py-boost-1.67.0-py37h04863e7_4\n",
            "  py-xgboost         conda-forge/linux-64::py-xgboost-1.2.0-py37hc8dfbb8_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.7-1_cp37m\n",
            "  rdkit              rdkit/linux-64::rdkit-2020.03.3.0-py37hc20afe1_1\n",
            "  simdna             deepchem/noarch::simdna-0.4.2-py_0\n",
            "  tensorboard        conda-forge/linux-64::tensorboard-1.14.0-py37_0\n",
            "  tensorflow         pkgs/main/linux-64::tensorflow-1.14.0-gpu_py37h74c33d7_0\n",
            "  tensorflow-base    pkgs/main/linux-64::tensorflow-base-1.14.0-gpu_py37he45bfe2_0\n",
            "  tensorflow-estima~ conda-forge/linux-64::tensorflow-estimator-1.14.0-py37h5ca1d4c_0\n",
            "  tensorflow-gpu     pkgs/main/linux-64::tensorflow-gpu-1.14.0-h0d30ee6_0\n",
            "  termcolor          conda-forge/noarch::termcolor-1.1.0-py_2\n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-3.7.4.3-py_0\n",
            "  xgboost            conda-forge/linux-64::xgboost-1.2.0-py37h3340039_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  conda                      pkgs/main::conda-4.7.12-py37_0 --> conda-forge::conda-4.10.0-py37h89c1867_1\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  certifi                                         pkgs/main --> conda-forge\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "c-ares-1.17.1        | 111 KB    | : 100% 1.0/1 [00:00<00:00,  7.72it/s]               \n",
            "cupti-10.1.168       | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  5.83it/s]\n",
            "typing_extensions-3. | 25 KB     | : 100% 1.0/1 [00:00<00:00, 23.21it/s]\n",
            "google-pasta-0.2.0   | 42 KB     | : 100% 1.0/1 [00:00<00:00, 22.49it/s]\n",
            "protobuf-3.13.0.1    | 704 KB    | : 100% 1.0/1 [00:00<00:00,  4.58it/s]\n",
            "python_abi-3.7       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 32.97it/s]\n",
            "termcolor-1.1.0      | 6 KB      | : 100% 1.0/1 [00:00<00:00, 21.13it/s]\n",
            "conda-4.10.0         | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.87it/s]\n",
            "deepchem-gpu-2.3.0   | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.23it/s]\n",
            "astunparse-1.6.3     | 15 KB     | : 100% 1.0/1 [00:00<00:00, 23.19it/s]\n",
            "tensorflow-1.14.0    | 4 KB      | : 100% 1.0/1 [00:00<00:00,  9.52it/s]\n",
            "tensorboard-1.14.0   | 3.2 MB    | : 100% 1.0/1 [00:00<00:00,  2.27it/s]              \n",
            "xgboost-1.2.0        | 11 KB     | : 100% 1.0/1 [00:00<00:00, 22.10it/s]\n",
            "mdtraj-1.9.5         | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.25it/s]\n",
            "certifi-2019.9.11    | 147 KB    | : 100% 1.0/1 [00:00<00:00, 10.94it/s]\n",
            "py-xgboost-1.2.0     | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.28it/s]\n",
            "markdown-3.3.4       | 67 KB     | : 100% 1.0/1 [00:00<00:00, 18.64it/s]\n",
            "grpcio-1.23.0        | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  5.03it/s]\n",
            "importlib-metadata-3 | 27 KB     | : 100% 1.0/1 [00:00<00:00, 18.99it/s]\n",
            "fftw3f-3.3.4         | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.52it/s]\n",
            "py-boost-1.67.0      | 278 KB    | : 100% 1.0/1 [00:00<00:00,  8.23it/s]\n",
            "tensorflow-gpu-1.14. | 3 KB      | : 100% 1.0/1 [00:00<00:00, 10.13it/s]\n",
            "gast-0.4.0           | 12 KB     | : 100% 1.0/1 [00:00<00:00, 23.40it/s]\n",
            "absl-py-0.12.0       | 96 KB     | : 100% 1.0/1 [00:00<00:00, 18.72it/s]\n",
            "keras-applications-1 | 30 KB     | : 100% 1.0/1 [00:00<00:00, 20.50it/s]\n",
            "tensorflow-base-1.14 | 146.3 MB  | : 100% 1.0/1 [00:09<00:00,  9.44s/it]               \n",
            "keras-preprocessing- | 34 KB     | : 100% 1.0/1 [00:00<00:00, 20.05it/s]\n",
            "libboost-1.67.0      | 13.0 MB   | : 100% 1.0/1 [00:01<00:00,  1.31s/it]               \n",
            "libprotobuf-3.13.0.1 | 2.3 MB    | : 100% 1.0/1 [00:00<00:00,  2.41it/s]\n",
            "cudnn-7.6.5.32       | 250.7 MB  | : 100% 1.0/1 [00:29<00:00, 29.60s/it]               \n",
            "astor-0.8.1          | 25 KB     | : 100% 1.0/1 [00:00<00:00, 13.03it/s]\n",
            "rdkit-2020.03.3.0    | 24.8 MB   | : 100% 1.0/1 [00:04<00:00,  4.40s/it]\n",
            "openmm-7.4.2         | 11.9 MB   | : 100% 1.0/1 [00:02<00:00,  2.44s/it]\n",
            "libxgboost-1.2.0     | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  2.15it/s]\n",
            "_tflow_select-2.1.0  | 2 KB      | : 100% 1.0/1 [00:00<00:00, 11.21it/s]\n",
            "_py-xgboost-mutex-2. | 8 KB      | : 100% 1.0/1 [00:00<00:00,  8.99it/s]\n",
            "cudatoolkit-10.1.243 | 347.4 MB  | : 100% 1.0/1 [00:10<00:00, 10.61s/it]               \n",
            "tensorflow-estimator | 645 KB    | : 100% 1.0/1 [00:00<00:00,  4.90it/s]\n",
            "pdbfixer-1.6         | 167 KB    | : 100% 1.0/1 [00:00<00:00,  1.82it/s]\n",
            "simdna-0.4.2         | 627 KB    | : 100% 1.0/1 [00:00<00:00,  1.91it/s]\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ b'By downloading and using the cuDNN conda packages, you accept the terms and conditions of the NVIDIA cuDNN EULA -\\n  https://docs.nvidia.com/deeplearning/cudnn/sla/index.html\\n'\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "real\t4m11.530s\n",
            "user\t3m43.515s\n",
            "sys\t0m12.999s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AB0U-9gyJNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32996cc7-cff4-4de3-d471-8cbd1b864aaf"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ravichas/AMPL-Tutorial/master/config/install_AMPL_GPU_test.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-13 16:38:22--  https://raw.githubusercontent.com/ravichas/AMPL-Tutorial/master/config/install_AMPL_GPU_test.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1100 (1.1K) [text/plain]\n",
            "Saving to: ‘install_AMPL_GPU_test.sh’\n",
            "\n",
            "install_AMPL_GPU_te 100%[===================>]   1.07K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-13 16:38:22 (96.4 MB/s) - ‘install_AMPL_GPU_test.sh’ saved [1100/1100]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aadk1g7ZzPdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76be4b3e-bfa0-44b0-801f-20cda3b3824f"
      },
      "source": [
        "! chmod u+x install_AMPL_GPU_test.sh\n",
        "! time ./install_AMPL_GPU_test.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AMPL'...\n",
            "remote: Enumerating objects: 388, done.\u001b[K\n",
            "remote: Counting objects: 100% (388/388), done.\u001b[K\n",
            "remote: Compressing objects: 100% (217/217), done.\u001b[K\n",
            "remote: Total 1896 (delta 278), reused 242 (delta 171), pack-reused 1508\u001b[K\n",
            "Receiving objects: 100% (1896/1896), 9.71 MiB | 2.15 MiB/s, done.\n",
            "Resolving deltas: 100% (1090/1090), done.\n",
            "Branch 'pkg_upgrade' set up to track remote branch 'pkg_upgrade' from 'origin'.\n",
            "Switched to a new branch 'pkg_upgrade'\n",
            "patching file /content/github/AMPL/atomsci/ddm/pipeline/transformations.py\n",
            "patching file /content/github/AMPL/atomsci/ddm/__init__.py\n",
            "running build\n",
            "running build_py\n",
            "creating /content/github/AMPL.build/ampl/lib\n",
            "creating /content/github/AMPL.build/ampl/lib/atomsci\n",
            "copying atomsci/__init__.py -> /content/github/AMPL.build/ampl/lib/atomsci\n",
            "creating /content/github/AMPL.build/ampl/lib/atomsci/ddm\n",
            "copying atomsci/ddm/__init__.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm\n",
            "creating /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/perf_data.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/chem_diversity.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/predict_from_model.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/parameter_parser.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/model_tracker.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/featurization.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/transformations.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/model_pipeline.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/__init__.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/model_wrapper.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/temporal_splitter.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/dist_metrics.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/perf_plots.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/splitting.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/compare_models.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/model_datasets.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/hyper_perf_plots.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/ave_splitter.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/diversity_plots.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/pipeline\n",
            "creating /content/github/AMPL.build/ampl/lib/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/struct_utils.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/pubchem_utils.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/hyperparam_search_wrapper.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/genTestset.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/__init__.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/datastore_functions.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/llnl_utils.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/rdkit_easy.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/open-docs.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/curate_data.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/data_curation_functions.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/process_slurm.py -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/utils\n",
            "running egg_info\n",
            "creating /content/github/AMPL.build/ampl/atomsci_ampl.egg-info\n",
            "writing /content/github/AMPL.build/ampl/atomsci_ampl.egg-info/PKG-INFO\n",
            "writing dependency_links to /content/github/AMPL.build/ampl/atomsci_ampl.egg-info/dependency_links.txt\n",
            "writing namespace_packages to /content/github/AMPL.build/ampl/atomsci_ampl.egg-info/namespace_packages.txt\n",
            "writing top-level names to /content/github/AMPL.build/ampl/atomsci_ampl.egg-info/top_level.txt\n",
            "writing manifest file '/content/github/AMPL.build/ampl/atomsci_ampl.egg-info/SOURCES.txt'\n",
            "reading manifest file '/content/github/AMPL.build/ampl/atomsci_ampl.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "warning: no files found matching 'atomsci/*/*.yaml'\n",
            "writing manifest file '/content/github/AMPL.build/ampl/atomsci_ampl.egg-info/SOURCES.txt'\n",
            "creating /content/github/AMPL.build/ampl/lib/atomsci/ddm/data\n",
            "copying atomsci/ddm/data/descriptor_sets_sources_by_descr_type.csv -> /content/github/AMPL.build/ampl/lib/atomsci/ddm/data\n",
            "running bdist_wheel\n",
            "installing to /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel\n",
            "running install\n",
            "running install_lib\n",
            "Skipping installation of /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/__init__.py (namespace package)\n",
            "copying atomsci/ddm/__init__.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm\n",
            "copying atomsci/ddm/data/descriptor_sets_sources_by_descr_type.csv -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/data\n",
            "copying atomsci/ddm/pipeline/perf_data.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/chem_diversity.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/predict_from_model.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/parameter_parser.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/model_tracker.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/featurization.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/transformations.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/model_pipeline.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/__init__.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/model_wrapper.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/temporal_splitter.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/dist_metrics.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/perf_plots.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/splitting.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/compare_models.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/model_datasets.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/hyper_perf_plots.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/ave_splitter.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/pipeline/diversity_plots.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/pipeline\n",
            "copying atomsci/ddm/utils/struct_utils.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/pubchem_utils.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/hyperparam_search_wrapper.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/genTestset.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/__init__.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/datastore_functions.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/llnl_utils.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/rdkit_easy.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/open-docs.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/curate_data.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/data_curation_functions.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/utils\n",
            "copying atomsci/ddm/utils/process_slurm.py -> /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci/ddm/utils\n",
            "running install_egg_info\n",
            "Copying /content/github/AMPL.build/ampl/atomsci_ampl.egg-info to /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci_ampl-1.0.0.dev1-py3.7.egg-info\n",
            "Installing /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci_ampl-1.0.0.dev1-py3.7-nspkg.pth\n",
            "running install_scripts\n",
            "adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "adding license file \"NOTICE\" (matched pattern \"NOTICE*\")\n",
            "creating /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel/atomsci_ampl-1.0.0.dev1.dist-info/WHEEL\n",
            "creating '/content/github/AMPL.dist/atomsci_ampl-1.0.0.dev1-py3-none-any.whl' and adding '/content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel' to it\n",
            "adding 'atomsci_ampl-1.0.0.dev1-py3.7-nspkg.pth'\n",
            "adding 'atomsci/ddm/__init__.py'\n",
            "adding 'atomsci/ddm/data/descriptor_sets_sources_by_descr_type.csv'\n",
            "adding 'atomsci/ddm/pipeline/__init__.py'\n",
            "adding 'atomsci/ddm/pipeline/ave_splitter.py'\n",
            "adding 'atomsci/ddm/pipeline/chem_diversity.py'\n",
            "adding 'atomsci/ddm/pipeline/compare_models.py'\n",
            "adding 'atomsci/ddm/pipeline/dist_metrics.py'\n",
            "adding 'atomsci/ddm/pipeline/diversity_plots.py'\n",
            "adding 'atomsci/ddm/pipeline/featurization.py'\n",
            "adding 'atomsci/ddm/pipeline/hyper_perf_plots.py'\n",
            "adding 'atomsci/ddm/pipeline/model_datasets.py'\n",
            "adding 'atomsci/ddm/pipeline/model_pipeline.py'\n",
            "adding 'atomsci/ddm/pipeline/model_tracker.py'\n",
            "adding 'atomsci/ddm/pipeline/model_wrapper.py'\n",
            "adding 'atomsci/ddm/pipeline/parameter_parser.py'\n",
            "adding 'atomsci/ddm/pipeline/perf_data.py'\n",
            "adding 'atomsci/ddm/pipeline/perf_plots.py'\n",
            "adding 'atomsci/ddm/pipeline/predict_from_model.py'\n",
            "adding 'atomsci/ddm/pipeline/splitting.py'\n",
            "adding 'atomsci/ddm/pipeline/temporal_splitter.py'\n",
            "adding 'atomsci/ddm/pipeline/transformations.py'\n",
            "adding 'atomsci/ddm/utils/__init__.py'\n",
            "adding 'atomsci/ddm/utils/curate_data.py'\n",
            "adding 'atomsci/ddm/utils/data_curation_functions.py'\n",
            "adding 'atomsci/ddm/utils/datastore_functions.py'\n",
            "adding 'atomsci/ddm/utils/genTestset.py'\n",
            "adding 'atomsci/ddm/utils/hyperparam_search_wrapper.py'\n",
            "adding 'atomsci/ddm/utils/llnl_utils.py'\n",
            "adding 'atomsci/ddm/utils/open-docs.py'\n",
            "adding 'atomsci/ddm/utils/process_slurm.py'\n",
            "adding 'atomsci/ddm/utils/pubchem_utils.py'\n",
            "adding 'atomsci/ddm/utils/rdkit_easy.py'\n",
            "adding 'atomsci/ddm/utils/struct_utils.py'\n",
            "adding 'atomsci_ampl-1.0.0.dev1.dist-info/LICENSE'\n",
            "adding 'atomsci_ampl-1.0.0.dev1.dist-info/METADATA'\n",
            "adding 'atomsci_ampl-1.0.0.dev1.dist-info/NOTICE'\n",
            "adding 'atomsci_ampl-1.0.0.dev1.dist-info/WHEEL'\n",
            "adding 'atomsci_ampl-1.0.0.dev1.dist-info/namespace_packages.txt'\n",
            "adding 'atomsci_ampl-1.0.0.dev1.dist-info/top_level.txt'\n",
            "adding 'atomsci_ampl-1.0.0.dev1.dist-info/RECORD'\n",
            "removing /content/github/AMPL.build/ampl/bdist.linux-x86_64/wheel\n",
            "DIR: /content/github/AMPL\n",
            "Ignoring indexes: https://pypi.org/simple\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-ldfnvsfm\n",
            "Created temporary directory: /tmp/pip-req-tracker-nvet48bk\n",
            "Created requirements tracker '/tmp/pip-req-tracker-nvet48bk'\n",
            "Created temporary directory: /tmp/pip-install-pjkzu8lf\n",
            "Looking in links: /content/github/AMPL.dist\n",
            "Collecting atomsci_ampl\n",
            "  0 location(s) to search for versions of atomsci-ampl:\n",
            "  Skipping link: unsupported archive format: .dist: /content/github/AMPL.dist (from -f)\n",
            "  Found link file:///content/github/AMPL.dist/atomsci_ampl-1.0.0.dev1-py3-none-any.whl, version: 1.0.0.dev1\n",
            "  Local files found: /content/github/AMPL.dist/atomsci_ampl-1.0.0.dev1-py3-none-any.whl\n",
            "  Given no hashes to check 1 links for project 'atomsci-ampl': discarding no candidates\n",
            "  Using version 1.0.0.dev1 (newest of versions: 1.0.0.dev1)\n",
            "  Added atomsci_ampl from file:///content/github/AMPL.dist/atomsci_ampl-1.0.0.dev1-py3-none-any.whl to build tracker '/tmp/pip-req-tracker-nvet48bk'\n",
            "  Removed atomsci_ampl from file:///content/github/AMPL.dist/atomsci_ampl-1.0.0.dev1-py3-none-any.whl from build tracker '/tmp/pip-req-tracker-nvet48bk'\n",
            "Installing collected packages: atomsci-ampl\n",
            "\n",
            "Successfully installed atomsci-ampl-1.0.0.dev1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-nvet48bk'\n",
            "\n",
            "real\t0m6.958s\n",
            "user\t0m1.645s\n",
            "sys\t0m0.407s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvmh_JjmFYbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "218a93df-444e-482b-d094-f10dbdeaea96"
      },
      "source": [
        "! time pip install mordred bravado molvs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mordred\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/3d/26c908ece761adafcea06320bf8fe73f4de69979273fb164226dc6038c39/mordred-1.2.0.tar.gz (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 13.8MB/s \n",
            "\u001b[?25hCollecting bravado\n",
            "  Downloading https://files.pythonhosted.org/packages/21/ed/03b0c36b5bcafbe2938ed222f9a164a6c0367ce99a9d2d502e462853571d/bravado-11.0.3-py2.py3-none-any.whl\n",
            "Collecting molvs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/dc/d948e83b97f2c420cb6c7e2143ae349560d3b5b061945f1b2a4eefb0231c/MolVS-0.1.1.tar.gz (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 26.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.* in /usr/local/lib/python3.7/site-packages (from mordred) (1.12.0)\n",
            "Requirement already satisfied: numpy==1.* in /usr/local/lib/python3.7/site-packages (from mordred) (1.17.2)\n",
            "Requirement already satisfied: networkx==2.* in /usr/local/lib/python3.7/site-packages (from mordred) (2.3)\n",
            "Requirement already satisfied: requests>=2.17 in /usr/local/lib/python3.7/site-packages (from bravado) (2.22.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/site-packages (from bravado) (5.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/site-packages (from bravado) (2.8.0)\n",
            "Collecting bravado-core>=5.16.1 (from bravado)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/11/18e9d28a156c33f2d5f15a5e155dc7130250acb0a569255a2b6b307b596d/bravado_core-5.17.0-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 22.5MB/s \n",
            "\u001b[?25hCollecting simplejson (from bravado)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/04/377418ac1e530ce2a196b54c6552c018fdf1fe776718053efb1f216bffcd/simplejson-3.17.2-cp37-cp37m-manylinux2010_x86_64.whl (128kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 20.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/site-packages (from bravado) (0.6.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from bravado) (3.7.4.3)\n",
            "Collecting monotonic (from bravado)\n",
            "  Downloading https://files.pythonhosted.org/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/site-packages (from networkx==2.*->mordred) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests>=2.17->bravado) (2019.9.11)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests>=2.17->bravado) (1.24.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests>=2.17->bravado) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests>=2.17->bravado) (3.0.4)\n",
            "Requirement already satisfied: jsonschema[format]>=2.5.1 in /usr/local/lib/python3.7/site-packages (from bravado-core>=5.16.1->bravado) (3.0.2)\n",
            "Collecting swagger-spec-validator>=2.0.1 (from bravado-core>=5.16.1->bravado)\n",
            "  Downloading https://files.pythonhosted.org/packages/09/de/e78cefbf5838b434b63a789264b79821cb2267f1498fbed23ef8590133e4/swagger_spec_validator-2.7.3-py2.py3-none-any.whl\n",
            "Collecting jsonref (from bravado-core>=5.16.1->bravado)\n",
            "  Downloading https://files.pythonhosted.org/packages/07/92/f8e4ac824b14af77e613984e480fa818397c72d4141fc466decb26752749/jsonref-0.2-py3-none-any.whl\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/site-packages (from bravado-core>=5.16.1->bravado) (2019.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/site-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado) (19.2.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/site-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado) (0.15.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado) (41.4.0)\n",
            "Collecting rfc3987; extra == \"format\" (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado)\n",
            "  Downloading https://files.pythonhosted.org/packages/65/d4/f7407c3d15d5ac779c3dd34fbbc6ea2090f77bd7dd12f207ccf881551208/rfc3987-1.3.8-py2.py3-none-any.whl\n",
            "Collecting webcolors; extra == \"format\" (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado)\n",
            "  Downloading https://files.pythonhosted.org/packages/12/05/3350559de9714b202e443a9e6312937341bd5f79f4e4f625744295e7dd17/webcolors-1.11.1-py3-none-any.whl\n",
            "Collecting jsonpointer>1.13; extra == \"format\" (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado)\n",
            "  Downloading https://files.pythonhosted.org/packages/23/52/05f67532aa922e494c351344e0d9624a01f74f5dd8402fe0d1b563a6e6fc/jsonpointer-2.1-py2.py3-none-any.whl\n",
            "Collecting strict-rfc3339; extra == \"format\" (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado)\n",
            "  Downloading https://files.pythonhosted.org/packages/56/e4/879ef1dbd6ddea1c77c0078cd59b503368b0456bcca7d063a870ca2119d3/strict-rfc3339-0.7.tar.gz\n",
            "Building wheels for collected packages: mordred, molvs, strict-rfc3339\n",
            "  Building wheel for mordred (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mordred: filename=mordred-1.2.0-cp37-none-any.whl size=176721 sha256=196fee67cbe9457e0313c8efad008ca7c43c05b4432b330792a4614d5b3f7660\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/74/3f/2fd81b1187013f2eadb15620434813f1824c4c03b7bd1f94f6\n",
            "  Building wheel for molvs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for molvs: filename=MolVS-0.1.1-cp37-none-any.whl size=32376 sha256=d83b8843ece4fc49d3ae42d4491eb2ea1994fddc74fed685b9273630985e76e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/37/a8/8ac8147605c9de6b45ffd66d1cc19761d41467db12b34a0de8\n",
            "  Building wheel for strict-rfc3339 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for strict-rfc3339: filename=strict_rfc3339-0.7-cp37-none-any.whl size=18120 sha256=7dd93a1d15eea3faf680216c5061035adfa0618924982543b2b310db33c28aea\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/af/c9/b6e9fb5f9b2470e4ed2a7241c9ab3a8cdd3bc8555ae02ca2e6\n",
            "Successfully built mordred molvs strict-rfc3339\n",
            "Installing collected packages: mordred, swagger-spec-validator, jsonref, simplejson, bravado-core, monotonic, bravado, molvs, rfc3987, webcolors, jsonpointer, strict-rfc3339\n",
            "Successfully installed bravado-11.0.3 bravado-core-5.17.0 jsonpointer-2.1 jsonref-0.2 molvs-0.1.1 monotonic-1.6 mordred-1.2.0 rfc3987-1.3.8 simplejson-3.17.2 strict-rfc3339-0.7 swagger-spec-validator-2.7.3 webcolors-1.11.1\n",
            "\n",
            "real\t0m5.104s\n",
            "user\t0m4.269s\n",
            "sys\t0m0.669s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InUQE4II1noi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1d03a9-a69b-4f89-87f3-e4de5e27f98a"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ravichas/AMPL-Tutorial/master/datasets/H1_std.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-13 16:38:34--  https://raw.githubusercontent.com/ravichas/AMPL-Tutorial/master/datasets/H1_std.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 136759 (134K) [text/plain]\n",
            "Saving to: ‘H1_std.csv’\n",
            "\n",
            "H1_std.csv          100%[===================>] 133.55K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2021-04-13 16:38:35 (15.4 MB/s) - ‘H1_std.csv’ saved [136759/136759]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PO0-2HKvVpn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b470599-2dac-480a-ba92-173a3b795443"
      },
      "source": [
        "!pip install hyperopt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hyperopt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/07/bd524635d218adae139be320eeac87fb4fbbd45c63b0bd58930c9e91f1fc/hyperopt-0.2.5-py2.py3-none-any.whl (965kB)\n",
            "\r\u001b[K     |▍                               | 10kB 21.4MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 28.9MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 22.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40kB 17.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51kB 15.6MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 13.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71kB 15.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81kB 15.7MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 15.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 102kB 16.1MB/s eta 0:00:01\r\u001b[K     |███▊                            | 112kB 16.1MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 16.1MB/s eta 0:00:01\r\u001b[K     |████▍                           | 133kB 16.1MB/s eta 0:00:01\r\u001b[K     |████▊                           | 143kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 163kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 174kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 194kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 204kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 215kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 225kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 235kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 245kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 256kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 266kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 276kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 286kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 296kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 307kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 317kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 327kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 337kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 348kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 358kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 368kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 378kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 389kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 399kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 409kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 419kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 430kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 440kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 450kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 460kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 471kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 481kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 491kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 501kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 512kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 522kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 532kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 542kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 552kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 563kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 573kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 583kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 593kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 604kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 614kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 624kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 634kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 645kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 655kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 665kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 675kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 686kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 696kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 706kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 716kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 727kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 737kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 747kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 757kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 768kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 778kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 788kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 798kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 808kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 819kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 829kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 839kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 849kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 860kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 870kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 880kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 890kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 901kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 911kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 921kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 931kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 942kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 952kB 16.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 962kB 16.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 972kB 16.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from hyperopt) (1.17.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/site-packages (from hyperopt) (2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from hyperopt) (4.36.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/site-packages (from hyperopt) (1.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/site-packages (from hyperopt) (0.17.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from hyperopt) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/site-packages (from hyperopt) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/site-packages (from networkx>=2.2->hyperopt) (4.4.0)\n",
            "Installing collected packages: hyperopt\n",
            "Successfully installed hyperopt-0.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTOwqhvR3xL3"
      },
      "source": [
        "### Load packages and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeN9kEMO2R9Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654e49f1-71c1-42b6-8fe7-26c560acc5bd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "sns.set_context(\"poster\")\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_palette(\"Set2\")\n",
        "\n",
        "import pandas as pd\n",
        "import os, json, sys, glob, pickle\n",
        "\n",
        "from atomsci.ddm.pipeline import model_pipeline as mp\n",
        "from atomsci.ddm.pipeline import parameter_parser as parse\n",
        "from atomsci.ddm.pipeline import perf_data\n",
        "from atomsci.ddm.pipeline import compare_models as cmp\n",
        "\n",
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0zYnjPsU1TZ",
        "outputId": "af8c7036-401c-4973-dd98-8585691434b1"
      },
      "source": [
        "# clean up unnecessary files\n",
        "! conda clean -a -y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cache location: /usr/local/pkgs\n",
            "Will remove the following tarballs:\n",
            "\n",
            "/usr/local/pkgs\n",
            "---------------\n",
            "json5-0.8.5-py_0.tar.bz2                      25 KB\n",
            "grpcio-1.23.0-py37hb0870dc_1.tar.bz2         1.1 MB\n",
            "bleach-3.1.0-py37_0.conda                    220 KB\n",
            "freetype-2.9.1-h8a8886c_1.conda              550 KB\n",
            "prompt_toolkit-2.0.10-py_0.tar.bz2           227 KB\n",
            "mistune-0.8.4-py37h7b6447c_0.conda            55 KB\n",
            "mpfr-4.0.1-hdf1c602_3.conda                  429 KB\n",
            "zict-1.0.0-py_0.tar.bz2                       12 KB\n",
            "future-0.17.1-py37_0.conda                   616 KB\n",
            "cudnn-7.6.5.32-hc0a50b0_1.tar.bz2          250.7 MB\n",
            "numpy-1.17.2-py37haad9e8e_0.conda              4 KB\n",
            "tk-8.6.8-hbc83047_0.conda                    2.8 MB\n",
            "setuptools-41.4.0-py37_0.tar.bz2             651 KB\n",
            "libxcb-1.13-h1bed415_1.conda                 421 KB\n",
            "sphinxcontrib-1.0-py37_1.conda                 4 KB\n",
            "gst-plugins-base-1.14.0-hbbd80ab_1.conda     4.8 MB\n",
            "pyyaml-5.1.2-py37h7b6447c_0.conda            179 KB\n",
            "qtconsole-4.5.5-py_0.tar.bz2                  94 KB\n",
            "keras-applications-1.0.8-py_1.tar.bz2         30 KB\n",
            "protobuf-3.13.0.1-py37h745909e_1.tar.bz2     704 KB\n",
            "joblib-0.13.2-py37_0.conda                   343 KB\n",
            "pyflakes-2.1.1-py37_0.conda                  106 KB\n",
            "jsonschema-3.0.2-py37_0.conda                 92 KB\n",
            "jupyter-1.0.0-py37_7.conda                     6 KB\n",
            "fastcache-1.1.0-py37h7b6447c_0.conda          30 KB\n",
            "ipython_genutils-0.2.0-py37_0.conda           39 KB\n",
            "anaconda-navigator-1.9.7-py37_0.tar.bz2      4.8 MB\n",
            "clyent-1.2.2-py37_1.conda                     19 KB\n",
            "keyring-18.0.0-py37_0.conda                   59 KB\n",
            "bzip2-1.0.8-h7b6447c_0.conda                  78 KB\n",
            "babel-2.7.0-py_0.tar.bz2                     5.8 MB\n",
            "numpy-base-1.17.2-py37hde5b4d6_0.conda       4.2 MB\n",
            "simdna-0.4.2-py_0.tar.bz2                    627 KB\n",
            "tbb-2019.4-hfd86e86_0.conda                  1.1 MB\n",
            "blas-1.0-mkl.conda                             6 KB\n",
            "dbus-1.13.6-h746ee38_0.conda                 499 KB\n",
            "pytables-3.5.2-py37h71ec239_1.conda          1.2 MB\n",
            "tensorflow-gpu-1.14.0-h0d30ee6_0.conda         3 KB\n",
            "anaconda-project-0.8.3-py_0.tar.bz2          212 KB\n",
            "backports.tempfile-1.0-py_1.tar.bz2           12 KB\n",
            "prometheus_client-0.7.1-py_0.tar.bz2          42 KB\n",
            "libxgboost-1.2.0-he1b5a44_0.tar.bz2          3.1 MB\n",
            "intel-openmp-2019.4-243.conda                729 KB\n",
            "navigator-updater-0.2.1-py37_0.conda         691 KB\n",
            "zipp-0.6.0-py_0.tar.bz2                        9 KB\n",
            "libstdcxx-ng-9.1.0-hdf63c60_0.conda          3.1 MB\n",
            "sphinx-2.2.0-py_0.tar.bz2                    1.5 MB\n",
            "gmp-6.1.2-h6c8ec71_1.conda                   514 KB\n",
            "tensorflow-estimator-1.14.0-py37h5ca1d4c_0.tar.bz2     645 KB\n",
            "fftw3f-3.3.4-2.tar.bz2                       1.2 MB\n",
            "sphinxcontrib-devhelp-1.0.1-py_0.tar.bz2      23 KB\n",
            "hdf5-1.10.4-hb1b8bf9_0.conda                 3.9 MB\n",
            "cycler-0.10.0-py37_0.conda                    13 KB\n",
            "sphinxcontrib-jsmath-1.0.1-py_0.tar.bz2        8 KB\n",
            "certifi-2019.9.11-py37_0.tar.bz2             147 KB\n",
            "ptyprocess-0.6.0-py37_0.conda                 23 KB\n",
            "jbig-2.1-hdba287a_0.conda                     40 KB\n",
            "krb5-1.16.1-h173b8e3_7.conda                 1.2 MB\n",
            "astor-0.8.1-pyh9f0ad1d_0.tar.bz2              25 KB\n",
            "deepchem-gpu-2.3.0-py37_0.tar.bz2            2.1 MB\n",
            "conda-env-2.6.0-1.conda                        3 KB\n",
            "backports.shutil_get_terminal_size-1.0.0-py37_2.conda       8 KB\n",
            "h5py-2.9.0-py37h7918eee_0.conda              991 KB\n",
            "sortedcollections-1.1.2-py37_0.conda          18 KB\n",
            "msgpack-python-0.6.1-py37hfd86e86_1.conda      87 KB\n",
            "tensorflow-base-1.14.0-gpu_py37he45bfe2_0.conda   146.3 MB\n",
            "pep8-1.7.1-py37_0.conda                       53 KB\n",
            "scikit-image-0.15.0-py37he6710b0_0.conda    24.8 MB\n",
            "unixodbc-2.3.7-h14c3975_0.conda              285 KB\n",
            "py-boost-1.67.0-py37h04863e7_4.conda         278 KB\n",
            "pycrypto-2.6.1-py37h14c3975_9.conda          362 KB\n",
            "numpydoc-0.9.1-py_0.tar.bz2                   31 KB\n",
            "scipy-1.3.1-py37h7c811a0_0.conda            14.0 MB\n",
            "ply-3.11-py37_0.conda                         82 KB\n",
            "python-libarchive-c-2.8-py37_13.conda         24 KB\n",
            "pytest-remotedata-0.3.2-py37_0.conda          15 KB\n",
            "asn1crypto-1.0.1-py37_0.tar.bz2              161 KB\n",
            "pycosat-0.6.3-py37h14c3975_0.conda            79 KB\n",
            "mpc-1.1.0-h10f8cd9_1.conda                    90 KB\n",
            "snappy-1.1.7-hbae5bb6_3.conda                 35 KB\n",
            "markupsafe-1.1.1-py37h7b6447c_0.conda         29 KB\n",
            "yaml-0.1.7-had09818_2.conda                   73 KB\n",
            "libsodium-1.0.16-h1bed415_0.conda            214 KB\n",
            "jeepney-0.4.1-py_0.tar.bz2                    21 KB\n",
            "decorator-4.4.0-py37_1.conda                  19 KB\n",
            "pycodestyle-2.5.0-py37_0.conda                61 KB\n",
            "mock-3.0.5-py37_0.conda                       49 KB\n",
            "tblib-1.4.0-py_0.tar.bz2                      14 KB\n",
            "filelock-3.0.12-py_0.tar.bz2                  12 KB\n",
            "colorama-0.4.1-py37_0.conda                   25 KB\n",
            "qt-5.9.7-h5867ecd_1.conda                   68.5 MB\n",
            "cupti-10.1.168-0.conda                       1.4 MB\n",
            "libedit-3.1.20181209-hc058e9b_0.conda        163 KB\n",
            "dask-2.5.2-py_0.tar.bz2                       12 KB\n",
            "boto-2.49.0-py37_0.conda                     1.2 MB\n",
            "absl-py-0.12.0-pyhd8ed1ab_0.tar.bz2           96 KB\n",
            "pickleshare-0.7.5-py37_0.conda                13 KB\n",
            "pyzmq-18.1.0-py37he6710b0_0.conda            455 KB\n",
            "pluggy-0.13.0-py37_0.tar.bz2                  31 KB\n",
            "pycparser-2.19-py37_0.conda                  171 KB\n",
            "libxslt-1.1.33-h7d1a2b0_0.conda              426 KB\n",
            "pytest-doctestplus-0.4.0-py_0.tar.bz2         18 KB\n",
            "libarchive-3.3.3-h5d8350f_5.conda            725 KB\n",
            "packaging-19.2-py_0.tar.bz2                   30 KB\n",
            "cairo-1.14.12-h8948797_3.conda               906 KB\n",
            "jupyter_core-4.5.0-py_0.tar.bz2               48 KB\n",
            "contextlib2-0.6.0-py_0.tar.bz2                16 KB\n",
            "astropy-3.2.2-py37h7b6447c_0.tar.bz2         7.1 MB\n",
            "libtiff-4.0.10-h2733197_2.conda              435 KB\n",
            "libxml2-2.9.9-hea5a465_1.conda               1.6 MB\n",
            "jedi-0.15.1-py37_0.conda                     704 KB\n",
            "werkzeug-0.16.0-py_0.tar.bz2                 255 KB\n",
            "lazy-object-proxy-1.4.2-py37h7b6447c_0.conda      29 KB\n",
            "c-ares-1.17.1-h36c2ea0_0.tar.bz2             111 KB\n",
            "qtawesome-0.6.0-py_0.tar.bz2                 671 KB\n",
            "wurlitzer-1.0.3-py37_0.conda                  14 KB\n",
            "libpng-1.6.37-hbc83047_0.conda               278 KB\n",
            "testpath-0.4.2-py37_0.conda                   86 KB\n",
            "sip-4.19.8-py37hf484d3e_0.conda              274 KB\n",
            "libtool-2.4.6-h7b6447c_5.conda               389 KB\n",
            "secretstorage-3.1.1-py37_0.conda              24 KB\n",
            "conda-4.7.12-py37_0.tar.bz2                  3.0 MB\n",
            "bkcharts-0.2-py37_0.conda                    133 KB\n",
            "_py-xgboost-mutex-2.0-cpu_0.tar.bz2            8 KB\n",
            "libffi-3.2.1-hd88cf55_4.conda                 40 KB\n",
            "isort-4.3.21-py37_0.conda                     69 KB\n",
            "pdbfixer-1.6-py_1.tar.bz2                    167 KB\n",
            "urllib3-1.24.2-py37_0.conda                  159 KB\n",
            "bitarray-1.0.1-py37h7b6447c_0.conda           60 KB\n",
            "sympy-1.4-py37_0.conda                       7.9 MB\n",
            "backcall-0.1.0-py37_0.conda                   20 KB\n",
            "graphite2-1.3.13-h23475e2_0.conda             98 KB\n",
            "sqlalchemy-1.3.9-py37h7b6447c_0.tar.bz2      1.8 MB\n",
            "mccabe-0.6.1-py37_1.conda                     14 KB\n",
            "locket-0.2.0-py37_1.conda                      9 KB\n",
            "multipledispatch-0.6.0-py37_0.conda           22 KB\n",
            "networkx-2.3-py_0.tar.bz2                    1.1 MB\n",
            "conda-build-3.18.9-py37_3.conda              506 KB\n",
            "sphinxcontrib-websupport-1.1.2-py_0.tar.bz2      35 KB\n",
            "heapdict-1.0.1-py_0.conda                      9 KB\n",
            "zlib-1.2.11-h7b6447c_3.conda                 103 KB\n",
            "toolz-0.10.0-py_0.tar.bz2                     50 KB\n",
            "mkl-service-2.3.0-py37he904b0f_0.conda       218 KB\n",
            "docutils-0.15.2-py37_0.conda                 660 KB\n",
            "pyopenssl-19.0.0-py37_0.conda                 84 KB\n",
            "cryptography-2.7-py37h1ba5d50_0.conda        544 KB\n",
            "get_terminal_size-1.0.0-haa9412d_0.conda       3 KB\n",
            "astroid-2.3.1-py37_0.tar.bz2                 288 KB\n",
            "pyrsistent-0.15.4-py37h7b6447c_0.tar.bz2      92 KB\n",
            "lzo-2.10-h49e0be7_2.conda                    182 KB\n",
            "numba-0.45.1-py37h962f231_0.conda            2.8 MB\n",
            "requests-2.22.0-py37_0.conda                  90 KB\n",
            "singledispatch-3.4.0.3-py37_0.conda           16 KB\n",
            "sphinxcontrib-applehelp-1.0.1-py_0.tar.bz2      29 KB\n",
            "send2trash-1.5.0-py37_0.conda                 16 KB\n",
            "_tflow_select-2.1.0-gpu.conda                  2 KB\n",
            "_ipyw_jlab_nb_ext_conf-0.1.0-py37_0.conda       4 KB\n",
            "ncurses-6.1-he6710b0_1.conda                 777 KB\n",
            "patsy-0.5.1-py37_0.conda                     274 KB\n",
            "pandocfilters-1.4.2-py37_1.conda              13 KB\n",
            "bottleneck-1.2.1-py37h035aef0_1.conda        120 KB\n",
            "libuuid-1.0.3-h1bed415_2.conda                15 KB\n",
            "mkl_fft-1.0.14-py37ha843d7b_0.conda          155 KB\n",
            "fontconfig-2.13.0-h9420a91_0.conda           227 KB\n",
            "pytz-2019.3-py_0.tar.bz2                     231 KB\n",
            "bokeh-1.3.4-py37_0.conda                     3.6 MB\n",
            "libcurl-7.65.3-h20c2e04_0.conda              431 KB\n",
            "pysocks-1.7.1-py37_0.tar.bz2                  30 KB\n",
            "webencodings-0.5.1-py37_1.conda               19 KB\n",
            "expat-2.2.6-he6710b0_0.conda                 146 KB\n",
            "jupyterlab-1.1.4-pyhf63ae98_0.conda          4.4 MB\n",
            "kiwisolver-1.1.0-py37he6710b0_0.conda         82 KB\n",
            "nbconvert-5.6.0-py37_1.tar.bz2               491 KB\n",
            "gevent-1.4.0-py37h7b6447c_0.conda            2.0 MB\n",
            "conda-4.10.0-py37h89c1867_1.tar.bz2          3.1 MB\n",
            "icu-58.2-h9c2bf20_1.conda                   10.3 MB\n",
            "pip-19.2.3-py37_0.tar.bz2                    1.9 MB\n",
            "ripgrep-0.10.0-hc07d326_0.conda              1.2 MB\n",
            "html5lib-1.0.1-py37_0.conda                  185 KB\n",
            "liblief-0.9.0-h7725739_2.conda               2.9 MB\n",
            "simplegeneric-0.8.1-py37_2.conda              10 KB\n",
            "libgcc-ng-9.1.0-hdf63c60_0.conda             5.1 MB\n",
            "termcolor-1.1.0-py_2.tar.bz2                   6 KB\n",
            "sphinxcontrib-serializinghtml-1.1.3-py_0.tar.bz2      24 KB\n",
            "python-dateutil-2.8.0-py37_0.conda           266 KB\n",
            "distributed-2.5.2-py_0.tar.bz2               396 KB\n",
            "unicodecsv-0.14.1-py37_0.conda                25 KB\n",
            "terminado-0.8.2-py37_0.conda                  23 KB\n",
            "pillow-6.2.0-py37h34e0f95_0.tar.bz2          643 KB\n",
            "backports.os-0.1.1-py37_0.conda               15 KB\n",
            "pytest-5.2.1-py37_0.tar.bz2                  364 KB\n",
            "wrapt-1.11.2-py37h7b6447c_0.conda             49 KB\n",
            "statsmodels-0.10.1-py37hdd07704_0.conda      7.4 MB\n",
            "qtpy-1.9.0-py_0.tar.bz2                       39 KB\n",
            "pkginfo-1.5.0.1-py37_0.conda                  44 KB\n",
            "cffi-1.12.3-py37h2e261b9_0.conda             222 KB\n",
            "xz-5.2.4-h14c3975_4.conda                    283 KB\n",
            "mkl_random-1.1.0-py37hd6b4f25_0.conda        321 KB\n",
            "spyder-3.3.6-py37_0.conda                    2.2 MB\n",
            "mkl-2019.4-243.conda                       131.2 MB\n",
            "imageio-2.6.0-py37_0.tar.bz2                 3.4 MB\n",
            "six-1.12.0-py37_0.conda                       23 KB\n",
            "flask-1.1.1-py_0.tar.bz2                      73 KB\n",
            "greenlet-0.4.15-py37h7b6447c_0.conda          20 KB\n",
            "ipywidgets-7.5.1-py_0.tar.bz2                107 KB\n",
            "keras-preprocessing-1.1.2-pyhd8ed1ab_0.tar.bz2      34 KB\n",
            "click-7.0-py37_0.conda                       120 KB\n",
            "astunparse-1.6.3-pyhd8ed1ab_0.tar.bz2         15 KB\n",
            "mpmath-1.1.0-py37_0.conda                    766 KB\n",
            "numexpr-2.7.0-py37h9e4a6bb_0.conda           183 KB\n",
            "typing_extensions-3.7.4.3-py_0.tar.bz2        25 KB\n",
            "pycurl-7.43.0.3-py37h1ba5d50_0.conda          67 KB\n",
            "pygments-2.4.2-py_0.tar.bz2                  664 KB\n",
            "sphinxcontrib-htmlhelp-1.0.2-py_0.tar.bz2      28 KB\n",
            "mdtraj-1.9.5-py37h113d463_0.tar.bz2          1.7 MB\n",
            "rdkit-2020.03.3.0-py37hc20afe1_1.tar.bz2    24.8 MB\n",
            "zeromq-4.3.1-he6710b0_3.conda                496 KB\n",
            "nltk-3.4.5-py37_0.conda                      1.7 MB\n",
            "atomicwrites-1.3.0-py37_1.conda               13 KB\n",
            "zstd-1.3.7-h0b5b093_0.conda                  401 KB\n",
            "ipykernel-5.1.2-py37h39e3cac_0.conda         170 KB\n",
            "jinja2-2.10.3-py_0.tar.bz2                    95 KB\n",
            "pexpect-4.7.0-py37_0.conda                    80 KB\n",
            "llvmlite-0.29.0-py37hd408876_0.conda        14.9 MB\n",
            "libprotobuf-3.13.0.1-h8b12597_0.tar.bz2      2.3 MB\n",
            "xlwt-1.3.0-py37_0.conda                      158 KB\n",
            "more-itertools-7.2.0-py37_0.conda            100 KB\n",
            "gmpy2-2.0.8-py37h10f8cd9_2.conda             150 KB\n",
            "jpeg-9b-h024ee3a_2.conda                     214 KB\n",
            "cython-0.29.13-py37he6710b0_0.conda          2.0 MB\n",
            "sqlite-3.30.0-h7b6447c_0.tar.bz2             1.9 MB\n",
            "importlib_metadata-0.23-py37_0.tar.bz2        43 KB\n",
            "gast-0.4.0-pyh9f0ad1d_0.tar.bz2               12 KB\n",
            "idna-2.8-py37_0.conda                         85 KB\n",
            "libssh2-1.8.2-h1ba5d50_0.conda               226 KB\n",
            "openmm-7.4.2-py37_cuda101_rc_1.tar.bz2      11.9 MB\n",
            "matplotlib-3.1.1-py37h5429711_0.conda        5.0 MB\n",
            "defusedxml-0.6.0-py_0.tar.bz2                 23 KB\n",
            "anaconda-client-1.7.2-py37_0.conda           147 KB\n",
            "jupyterlab_server-1.0.6-py_0.tar.bz2          26 KB\n",
            "itsdangerous-1.1.0-py37_0.conda               28 KB\n",
            "ipython-7.8.0-py37h39e3cac_0.conda           985 KB\n",
            "nbformat-4.4.0-py37_0.conda                  128 KB\n",
            "pango-1.42.4-h049681c_0.conda                464 KB\n",
            "pcre-8.43-he6710b0_0.conda                   209 KB\n",
            "cudatoolkit-10.1.243-h6bb024c_0.conda      347.4 MB\n",
            "pytest-astropy-0.5.0-py37_0.conda              7 KB\n",
            "jupyter_console-6.0.0-py37_0.conda            37 KB\n",
            "lxml-4.4.1-py37hefd8a0e_0.conda              1.4 MB\n",
            "curl-7.65.3-hbc83047_0.conda                 130 KB\n",
            "libgfortran-ng-7.3.0-hdf63c60_0.conda       1006 KB\n",
            "imagesize-1.1.0-py37_0.conda                   9 KB\n",
            "xgboost-1.2.0-py37h3340039_0.tar.bz2          11 KB\n",
            "cytoolz-0.10.0-py37h7b6447c_0.conda          374 KB\n",
            "pyqt-5.9.2-py37h05f1152_2.conda              4.5 MB\n",
            "pathlib2-2.3.5-py37_0.tar.bz2                 37 KB\n",
            "patchelf-0.9-he6710b0_3.conda                 68 KB\n",
            "fsspec-0.5.2-py_0.tar.bz2                     46 KB\n",
            "wheel-0.33.6-py37_0.tar.bz2                   40 KB\n",
            "anaconda-2019.10-py37_0.tar.bz2               11 KB\n",
            "conda-package-handling-1.6.0-py37h7b6447c_0.conda     797 KB\n",
            "pyodbc-4.0.27-py37he6710b0_0.conda            68 KB\n",
            "seaborn-0.9.0-py37_0.conda                   355 KB\n",
            "psutil-5.6.3-py37h7b6447c_0.conda            313 KB\n",
            "pywavelets-1.0.3-py37hdd07704_1.conda        3.5 MB\n",
            "notebook-6.0.1-py37_0.tar.bz2                6.0 MB\n",
            "widgetsnbextension-3.5.1-py37_0.conda        862 KB\n",
            "snowballstemmer-2.0.0-py_0.tar.bz2            58 KB\n",
            "xlsxwriter-1.2.1-py_0.tar.bz2                106 KB\n",
            "pixman-0.38.0-h7b6447c_0.conda               364 KB\n",
            "readline-7.0-h7b6447c_5.conda                324 KB\n",
            "tensorboard-1.14.0-py37_0.tar.bz2            3.2 MB\n",
            "attrs-19.2.0-py_0.tar.bz2                     39 KB\n",
            "parso-0.5.1-py_0.tar.bz2                      68 KB\n",
            "harfbuzz-1.8.8-hffaf4a1_0.conda              507 KB\n",
            "py-xgboost-1.2.0-py37hc8dfbb8_0.tar.bz2      1.7 MB\n",
            "py-lief-0.9.0-py37h7725739_2.conda           1.3 MB\n",
            "importlib-metadata-3.10.1-py37h89c1867_0.tar.bz2      27 KB\n",
            "rope-0.14.0-py_0.tar.bz2                     113 KB\n",
            "path.py-12.0.1-py_0.tar.bz2                   23 KB\n",
            "tqdm-4.36.1-py_0.conda                        50 KB\n",
            "dask-core-2.5.2-py_0.tar.bz2                 579 KB\n",
            "chardet-3.0.4-py37_1003.conda                174 KB\n",
            "py-1.8.0-py37_0.conda                        148 KB\n",
            "pytest-openfiles-0.4.0-py_0.tar.bz2           10 KB\n",
            "ca-certificates-2019.8.28-0.tar.bz2          132 KB\n",
            "xlrd-1.2.0-py37_0.conda                      175 KB\n",
            "conda-verify-3.4.2-py_1.tar.bz2               25 KB\n",
            "sphinxcontrib-qthelp-1.0.2-py_0.tar.bz2       26 KB\n",
            "backports.weakref-1.0.post1-py_1.tar.bz2       7 KB\n",
            "soupsieve-1.9.3-py37_0.tar.bz2                60 KB\n",
            "spyder-kernels-0.5.2-py37_0.tar.bz2           69 KB\n",
            "pyparsing-2.4.2-py_0.tar.bz2                  61 KB\n",
            "jdcal-1.4.1-py_0.tar.bz2                      11 KB\n",
            "nose-1.3.7-py37_2.conda                      214 KB\n",
            "markdown-3.3.4-pyhd8ed1ab_0.tar.bz2           67 KB\n",
            "fribidi-1.0.5-h7b6447c_0.conda               101 KB\n",
            "gstreamer-1.14.0-hb453b48_1.conda            3.1 MB\n",
            "olefile-0.46-py37_0.conda                     50 KB\n",
            "backports.functools_lru_cache-1.5-py_2.tar.bz2       9 KB\n",
            "glob2-0.7-py_0.tar.bz2                        14 KB\n",
            "sortedcontainers-2.1.0-py37_0.conda           43 KB\n",
            "tornado-6.0.3-py37h7b6447c_0.conda           584 KB\n",
            "beautifulsoup4-4.8.0-py37_0.conda            152 KB\n",
            "traitlets-4.3.3-py37_0.tar.bz2               138 KB\n",
            "pandoc-2.2.3.2-0.conda                      14.0 MB\n",
            "wcwidth-0.1.7-py37_0.conda                    22 KB\n",
            "pandas-0.25.1-py37he6710b0_0.conda           8.8 MB\n",
            "openpyxl-3.0.0-py_0.tar.bz2                  157 KB\n",
            "alabaster-0.7.12-py37_0.conda                 18 KB\n",
            "_libgcc_mutex-0.1-main.conda                   3 KB\n",
            "scikit-learn-0.21.3-py37hd81dba3_0.conda     4.9 MB\n",
            "google-pasta-0.2.0-pyh8c360ce_0.tar.bz2       42 KB\n",
            "openssl-1.1.1d-h7b6447c_2.conda              2.5 MB\n",
            "pylint-2.4.2-py37_0.tar.bz2                  429 KB\n",
            "backports-1.0-py_2.tar.bz2                   139 KB\n",
            "cloudpickle-1.2.2-py_0.tar.bz2                29 KB\n",
            "libboost-1.67.0-h46d08c1_4.conda            13.0 MB\n",
            "python-3.7.4-h265db76_1.conda               32.1 MB\n",
            "partd-1.0.0-py_0.tar.bz2                      19 KB\n",
            "ruamel_yaml-0.15.46-py37h14c3975_0.conda     237 KB\n",
            "tensorflow-1.14.0-gpu_py37h74c33d7_0.conda       4 KB\n",
            "python_abi-3.7-1_cp37m.tar.bz2                 4 KB\n",
            "blosc-1.16.3-hd408876_0.conda                 71 KB\n",
            "entrypoints-0.3-py37_0.conda                  12 KB\n",
            "lz4-c-1.8.1.2-h14c3975_0.conda               130 KB\n",
            "glib-2.56.2-hd408876_0.conda                 3.9 MB\n",
            "et_xmlfile-1.0.1-py37_0.conda                 21 KB\n",
            "pytest-arraydiff-0.3-py37h39e3cac_0.conda      15 KB\n",
            "jupyter_client-5.3.3-py37_1.tar.bz2          137 KB\n",
            "\n",
            "---------------------------------------------------\n",
            "Total:                                      1.28 GB\n",
            "\n",
            "Removed json5-0.8.5-py_0.tar.bz2\n",
            "Removed grpcio-1.23.0-py37hb0870dc_1.tar.bz2\n",
            "Removed bleach-3.1.0-py37_0.conda\n",
            "Removed freetype-2.9.1-h8a8886c_1.conda\n",
            "Removed prompt_toolkit-2.0.10-py_0.tar.bz2\n",
            "Removed mistune-0.8.4-py37h7b6447c_0.conda\n",
            "Removed mpfr-4.0.1-hdf1c602_3.conda\n",
            "Removed zict-1.0.0-py_0.tar.bz2\n",
            "Removed future-0.17.1-py37_0.conda\n",
            "Removed cudnn-7.6.5.32-hc0a50b0_1.tar.bz2\n",
            "Removed numpy-1.17.2-py37haad9e8e_0.conda\n",
            "Removed tk-8.6.8-hbc83047_0.conda\n",
            "Removed setuptools-41.4.0-py37_0.tar.bz2\n",
            "Removed libxcb-1.13-h1bed415_1.conda\n",
            "Removed sphinxcontrib-1.0-py37_1.conda\n",
            "Removed gst-plugins-base-1.14.0-hbbd80ab_1.conda\n",
            "Removed pyyaml-5.1.2-py37h7b6447c_0.conda\n",
            "Removed qtconsole-4.5.5-py_0.tar.bz2\n",
            "Removed keras-applications-1.0.8-py_1.tar.bz2\n",
            "Removed protobuf-3.13.0.1-py37h745909e_1.tar.bz2\n",
            "Removed joblib-0.13.2-py37_0.conda\n",
            "Removed pyflakes-2.1.1-py37_0.conda\n",
            "Removed jsonschema-3.0.2-py37_0.conda\n",
            "Removed jupyter-1.0.0-py37_7.conda\n",
            "Removed fastcache-1.1.0-py37h7b6447c_0.conda\n",
            "Removed ipython_genutils-0.2.0-py37_0.conda\n",
            "Removed anaconda-navigator-1.9.7-py37_0.tar.bz2\n",
            "Removed clyent-1.2.2-py37_1.conda\n",
            "Removed keyring-18.0.0-py37_0.conda\n",
            "Removed bzip2-1.0.8-h7b6447c_0.conda\n",
            "Removed babel-2.7.0-py_0.tar.bz2\n",
            "Removed numpy-base-1.17.2-py37hde5b4d6_0.conda\n",
            "Removed simdna-0.4.2-py_0.tar.bz2\n",
            "Removed tbb-2019.4-hfd86e86_0.conda\n",
            "Removed blas-1.0-mkl.conda\n",
            "Removed dbus-1.13.6-h746ee38_0.conda\n",
            "Removed pytables-3.5.2-py37h71ec239_1.conda\n",
            "Removed tensorflow-gpu-1.14.0-h0d30ee6_0.conda\n",
            "Removed anaconda-project-0.8.3-py_0.tar.bz2\n",
            "Removed backports.tempfile-1.0-py_1.tar.bz2\n",
            "Removed prometheus_client-0.7.1-py_0.tar.bz2\n",
            "Removed libxgboost-1.2.0-he1b5a44_0.tar.bz2\n",
            "Removed intel-openmp-2019.4-243.conda\n",
            "Removed navigator-updater-0.2.1-py37_0.conda\n",
            "Removed zipp-0.6.0-py_0.tar.bz2\n",
            "Removed libstdcxx-ng-9.1.0-hdf63c60_0.conda\n",
            "Removed sphinx-2.2.0-py_0.tar.bz2\n",
            "Removed gmp-6.1.2-h6c8ec71_1.conda\n",
            "Removed tensorflow-estimator-1.14.0-py37h5ca1d4c_0.tar.bz2\n",
            "Removed fftw3f-3.3.4-2.tar.bz2\n",
            "Removed sphinxcontrib-devhelp-1.0.1-py_0.tar.bz2\n",
            "Removed hdf5-1.10.4-hb1b8bf9_0.conda\n",
            "Removed cycler-0.10.0-py37_0.conda\n",
            "Removed sphinxcontrib-jsmath-1.0.1-py_0.tar.bz2\n",
            "Removed certifi-2019.9.11-py37_0.tar.bz2\n",
            "Removed ptyprocess-0.6.0-py37_0.conda\n",
            "Removed jbig-2.1-hdba287a_0.conda\n",
            "Removed krb5-1.16.1-h173b8e3_7.conda\n",
            "Removed astor-0.8.1-pyh9f0ad1d_0.tar.bz2\n",
            "Removed deepchem-gpu-2.3.0-py37_0.tar.bz2\n",
            "Removed conda-env-2.6.0-1.conda\n",
            "Removed backports.shutil_get_terminal_size-1.0.0-py37_2.conda\n",
            "Removed h5py-2.9.0-py37h7918eee_0.conda\n",
            "Removed sortedcollections-1.1.2-py37_0.conda\n",
            "Removed msgpack-python-0.6.1-py37hfd86e86_1.conda\n",
            "Removed tensorflow-base-1.14.0-gpu_py37he45bfe2_0.conda\n",
            "Removed pep8-1.7.1-py37_0.conda\n",
            "Removed scikit-image-0.15.0-py37he6710b0_0.conda\n",
            "Removed unixodbc-2.3.7-h14c3975_0.conda\n",
            "Removed py-boost-1.67.0-py37h04863e7_4.conda\n",
            "Removed pycrypto-2.6.1-py37h14c3975_9.conda\n",
            "Removed numpydoc-0.9.1-py_0.tar.bz2\n",
            "Removed scipy-1.3.1-py37h7c811a0_0.conda\n",
            "Removed ply-3.11-py37_0.conda\n",
            "Removed python-libarchive-c-2.8-py37_13.conda\n",
            "Removed pytest-remotedata-0.3.2-py37_0.conda\n",
            "Removed asn1crypto-1.0.1-py37_0.tar.bz2\n",
            "Removed pycosat-0.6.3-py37h14c3975_0.conda\n",
            "Removed mpc-1.1.0-h10f8cd9_1.conda\n",
            "Removed snappy-1.1.7-hbae5bb6_3.conda\n",
            "Removed markupsafe-1.1.1-py37h7b6447c_0.conda\n",
            "Removed yaml-0.1.7-had09818_2.conda\n",
            "Removed libsodium-1.0.16-h1bed415_0.conda\n",
            "Removed jeepney-0.4.1-py_0.tar.bz2\n",
            "Removed decorator-4.4.0-py37_1.conda\n",
            "Removed pycodestyle-2.5.0-py37_0.conda\n",
            "Removed mock-3.0.5-py37_0.conda\n",
            "Removed tblib-1.4.0-py_0.tar.bz2\n",
            "Removed filelock-3.0.12-py_0.tar.bz2\n",
            "Removed colorama-0.4.1-py37_0.conda\n",
            "Removed qt-5.9.7-h5867ecd_1.conda\n",
            "Removed cupti-10.1.168-0.conda\n",
            "Removed libedit-3.1.20181209-hc058e9b_0.conda\n",
            "Removed dask-2.5.2-py_0.tar.bz2\n",
            "Removed boto-2.49.0-py37_0.conda\n",
            "Removed absl-py-0.12.0-pyhd8ed1ab_0.tar.bz2\n",
            "Removed pickleshare-0.7.5-py37_0.conda\n",
            "Removed pyzmq-18.1.0-py37he6710b0_0.conda\n",
            "Removed pluggy-0.13.0-py37_0.tar.bz2\n",
            "Removed pycparser-2.19-py37_0.conda\n",
            "Removed libxslt-1.1.33-h7d1a2b0_0.conda\n",
            "Removed pytest-doctestplus-0.4.0-py_0.tar.bz2\n",
            "Removed libarchive-3.3.3-h5d8350f_5.conda\n",
            "Removed packaging-19.2-py_0.tar.bz2\n",
            "Removed cairo-1.14.12-h8948797_3.conda\n",
            "Removed jupyter_core-4.5.0-py_0.tar.bz2\n",
            "Removed contextlib2-0.6.0-py_0.tar.bz2\n",
            "Removed astropy-3.2.2-py37h7b6447c_0.tar.bz2\n",
            "Removed libtiff-4.0.10-h2733197_2.conda\n",
            "Removed libxml2-2.9.9-hea5a465_1.conda\n",
            "Removed jedi-0.15.1-py37_0.conda\n",
            "Removed werkzeug-0.16.0-py_0.tar.bz2\n",
            "Removed lazy-object-proxy-1.4.2-py37h7b6447c_0.conda\n",
            "Removed c-ares-1.17.1-h36c2ea0_0.tar.bz2\n",
            "Removed qtawesome-0.6.0-py_0.tar.bz2\n",
            "Removed wurlitzer-1.0.3-py37_0.conda\n",
            "Removed libpng-1.6.37-hbc83047_0.conda\n",
            "Removed testpath-0.4.2-py37_0.conda\n",
            "Removed sip-4.19.8-py37hf484d3e_0.conda\n",
            "Removed libtool-2.4.6-h7b6447c_5.conda\n",
            "Removed secretstorage-3.1.1-py37_0.conda\n",
            "Removed conda-4.7.12-py37_0.tar.bz2\n",
            "Removed bkcharts-0.2-py37_0.conda\n",
            "Removed _py-xgboost-mutex-2.0-cpu_0.tar.bz2\n",
            "Removed libffi-3.2.1-hd88cf55_4.conda\n",
            "Removed isort-4.3.21-py37_0.conda\n",
            "Removed pdbfixer-1.6-py_1.tar.bz2\n",
            "Removed urllib3-1.24.2-py37_0.conda\n",
            "Removed bitarray-1.0.1-py37h7b6447c_0.conda\n",
            "Removed sympy-1.4-py37_0.conda\n",
            "Removed backcall-0.1.0-py37_0.conda\n",
            "Removed graphite2-1.3.13-h23475e2_0.conda\n",
            "Removed sqlalchemy-1.3.9-py37h7b6447c_0.tar.bz2\n",
            "Removed mccabe-0.6.1-py37_1.conda\n",
            "Removed locket-0.2.0-py37_1.conda\n",
            "Removed multipledispatch-0.6.0-py37_0.conda\n",
            "Removed networkx-2.3-py_0.tar.bz2\n",
            "Removed conda-build-3.18.9-py37_3.conda\n",
            "Removed sphinxcontrib-websupport-1.1.2-py_0.tar.bz2\n",
            "Removed heapdict-1.0.1-py_0.conda\n",
            "Removed zlib-1.2.11-h7b6447c_3.conda\n",
            "Removed toolz-0.10.0-py_0.tar.bz2\n",
            "Removed mkl-service-2.3.0-py37he904b0f_0.conda\n",
            "Removed docutils-0.15.2-py37_0.conda\n",
            "Removed pyopenssl-19.0.0-py37_0.conda\n",
            "Removed cryptography-2.7-py37h1ba5d50_0.conda\n",
            "Removed get_terminal_size-1.0.0-haa9412d_0.conda\n",
            "Removed astroid-2.3.1-py37_0.tar.bz2\n",
            "Removed pyrsistent-0.15.4-py37h7b6447c_0.tar.bz2\n",
            "Removed lzo-2.10-h49e0be7_2.conda\n",
            "Removed numba-0.45.1-py37h962f231_0.conda\n",
            "Removed requests-2.22.0-py37_0.conda\n",
            "Removed singledispatch-3.4.0.3-py37_0.conda\n",
            "Removed sphinxcontrib-applehelp-1.0.1-py_0.tar.bz2\n",
            "Removed send2trash-1.5.0-py37_0.conda\n",
            "Removed _tflow_select-2.1.0-gpu.conda\n",
            "Removed _ipyw_jlab_nb_ext_conf-0.1.0-py37_0.conda\n",
            "Removed ncurses-6.1-he6710b0_1.conda\n",
            "Removed patsy-0.5.1-py37_0.conda\n",
            "Removed pandocfilters-1.4.2-py37_1.conda\n",
            "Removed bottleneck-1.2.1-py37h035aef0_1.conda\n",
            "Removed libuuid-1.0.3-h1bed415_2.conda\n",
            "Removed mkl_fft-1.0.14-py37ha843d7b_0.conda\n",
            "Removed fontconfig-2.13.0-h9420a91_0.conda\n",
            "Removed pytz-2019.3-py_0.tar.bz2\n",
            "Removed bokeh-1.3.4-py37_0.conda\n",
            "Removed libcurl-7.65.3-h20c2e04_0.conda\n",
            "Removed pysocks-1.7.1-py37_0.tar.bz2\n",
            "Removed webencodings-0.5.1-py37_1.conda\n",
            "Removed expat-2.2.6-he6710b0_0.conda\n",
            "Removed jupyterlab-1.1.4-pyhf63ae98_0.conda\n",
            "Removed kiwisolver-1.1.0-py37he6710b0_0.conda\n",
            "Removed nbconvert-5.6.0-py37_1.tar.bz2\n",
            "Removed gevent-1.4.0-py37h7b6447c_0.conda\n",
            "Removed conda-4.10.0-py37h89c1867_1.tar.bz2\n",
            "Removed icu-58.2-h9c2bf20_1.conda\n",
            "Removed pip-19.2.3-py37_0.tar.bz2\n",
            "Removed ripgrep-0.10.0-hc07d326_0.conda\n",
            "Removed html5lib-1.0.1-py37_0.conda\n",
            "Removed liblief-0.9.0-h7725739_2.conda\n",
            "Removed simplegeneric-0.8.1-py37_2.conda\n",
            "Removed libgcc-ng-9.1.0-hdf63c60_0.conda\n",
            "Removed termcolor-1.1.0-py_2.tar.bz2\n",
            "Removed sphinxcontrib-serializinghtml-1.1.3-py_0.tar.bz2\n",
            "Removed python-dateutil-2.8.0-py37_0.conda\n",
            "Removed distributed-2.5.2-py_0.tar.bz2\n",
            "Removed unicodecsv-0.14.1-py37_0.conda\n",
            "Removed terminado-0.8.2-py37_0.conda\n",
            "Removed pillow-6.2.0-py37h34e0f95_0.tar.bz2\n",
            "Removed backports.os-0.1.1-py37_0.conda\n",
            "Removed pytest-5.2.1-py37_0.tar.bz2\n",
            "Removed wrapt-1.11.2-py37h7b6447c_0.conda\n",
            "Removed statsmodels-0.10.1-py37hdd07704_0.conda\n",
            "Removed qtpy-1.9.0-py_0.tar.bz2\n",
            "Removed pkginfo-1.5.0.1-py37_0.conda\n",
            "Removed cffi-1.12.3-py37h2e261b9_0.conda\n",
            "Removed xz-5.2.4-h14c3975_4.conda\n",
            "Removed mkl_random-1.1.0-py37hd6b4f25_0.conda\n",
            "Removed spyder-3.3.6-py37_0.conda\n",
            "Removed mkl-2019.4-243.conda\n",
            "Removed imageio-2.6.0-py37_0.tar.bz2\n",
            "Removed six-1.12.0-py37_0.conda\n",
            "Removed flask-1.1.1-py_0.tar.bz2\n",
            "Removed greenlet-0.4.15-py37h7b6447c_0.conda\n",
            "Removed ipywidgets-7.5.1-py_0.tar.bz2\n",
            "Removed keras-preprocessing-1.1.2-pyhd8ed1ab_0.tar.bz2\n",
            "Removed click-7.0-py37_0.conda\n",
            "Removed astunparse-1.6.3-pyhd8ed1ab_0.tar.bz2\n",
            "Removed mpmath-1.1.0-py37_0.conda\n",
            "Removed numexpr-2.7.0-py37h9e4a6bb_0.conda\n",
            "Removed typing_extensions-3.7.4.3-py_0.tar.bz2\n",
            "Removed pycurl-7.43.0.3-py37h1ba5d50_0.conda\n",
            "Removed pygments-2.4.2-py_0.tar.bz2\n",
            "Removed sphinxcontrib-htmlhelp-1.0.2-py_0.tar.bz2\n",
            "Removed mdtraj-1.9.5-py37h113d463_0.tar.bz2\n",
            "Removed rdkit-2020.03.3.0-py37hc20afe1_1.tar.bz2\n",
            "Removed zeromq-4.3.1-he6710b0_3.conda\n",
            "Removed nltk-3.4.5-py37_0.conda\n",
            "Removed atomicwrites-1.3.0-py37_1.conda\n",
            "Removed zstd-1.3.7-h0b5b093_0.conda\n",
            "Removed ipykernel-5.1.2-py37h39e3cac_0.conda\n",
            "Removed jinja2-2.10.3-py_0.tar.bz2\n",
            "Removed pexpect-4.7.0-py37_0.conda\n",
            "Removed llvmlite-0.29.0-py37hd408876_0.conda\n",
            "Removed libprotobuf-3.13.0.1-h8b12597_0.tar.bz2\n",
            "Removed xlwt-1.3.0-py37_0.conda\n",
            "Removed more-itertools-7.2.0-py37_0.conda\n",
            "Removed gmpy2-2.0.8-py37h10f8cd9_2.conda\n",
            "Removed jpeg-9b-h024ee3a_2.conda\n",
            "Removed cython-0.29.13-py37he6710b0_0.conda\n",
            "Removed sqlite-3.30.0-h7b6447c_0.tar.bz2\n",
            "Removed importlib_metadata-0.23-py37_0.tar.bz2\n",
            "Removed gast-0.4.0-pyh9f0ad1d_0.tar.bz2\n",
            "Removed idna-2.8-py37_0.conda\n",
            "Removed libssh2-1.8.2-h1ba5d50_0.conda\n",
            "Removed openmm-7.4.2-py37_cuda101_rc_1.tar.bz2\n",
            "Removed matplotlib-3.1.1-py37h5429711_0.conda\n",
            "Removed defusedxml-0.6.0-py_0.tar.bz2\n",
            "Removed anaconda-client-1.7.2-py37_0.conda\n",
            "Removed jupyterlab_server-1.0.6-py_0.tar.bz2\n",
            "Removed itsdangerous-1.1.0-py37_0.conda\n",
            "Removed ipython-7.8.0-py37h39e3cac_0.conda\n",
            "Removed nbformat-4.4.0-py37_0.conda\n",
            "Removed pango-1.42.4-h049681c_0.conda\n",
            "Removed pcre-8.43-he6710b0_0.conda\n",
            "Removed cudatoolkit-10.1.243-h6bb024c_0.conda\n",
            "Removed pytest-astropy-0.5.0-py37_0.conda\n",
            "Removed jupyter_console-6.0.0-py37_0.conda\n",
            "Removed lxml-4.4.1-py37hefd8a0e_0.conda\n",
            "Removed curl-7.65.3-hbc83047_0.conda\n",
            "Removed libgfortran-ng-7.3.0-hdf63c60_0.conda\n",
            "Removed imagesize-1.1.0-py37_0.conda\n",
            "Removed xgboost-1.2.0-py37h3340039_0.tar.bz2\n",
            "Removed cytoolz-0.10.0-py37h7b6447c_0.conda\n",
            "Removed pyqt-5.9.2-py37h05f1152_2.conda\n",
            "Removed pathlib2-2.3.5-py37_0.tar.bz2\n",
            "Removed patchelf-0.9-he6710b0_3.conda\n",
            "Removed fsspec-0.5.2-py_0.tar.bz2\n",
            "Removed wheel-0.33.6-py37_0.tar.bz2\n",
            "Removed anaconda-2019.10-py37_0.tar.bz2\n",
            "Removed conda-package-handling-1.6.0-py37h7b6447c_0.conda\n",
            "Removed pyodbc-4.0.27-py37he6710b0_0.conda\n",
            "Removed seaborn-0.9.0-py37_0.conda\n",
            "Removed psutil-5.6.3-py37h7b6447c_0.conda\n",
            "Removed pywavelets-1.0.3-py37hdd07704_1.conda\n",
            "Removed notebook-6.0.1-py37_0.tar.bz2\n",
            "Removed widgetsnbextension-3.5.1-py37_0.conda\n",
            "Removed snowballstemmer-2.0.0-py_0.tar.bz2\n",
            "Removed xlsxwriter-1.2.1-py_0.tar.bz2\n",
            "Removed pixman-0.38.0-h7b6447c_0.conda\n",
            "Removed readline-7.0-h7b6447c_5.conda\n",
            "Removed tensorboard-1.14.0-py37_0.tar.bz2\n",
            "Removed attrs-19.2.0-py_0.tar.bz2\n",
            "Removed parso-0.5.1-py_0.tar.bz2\n",
            "Removed harfbuzz-1.8.8-hffaf4a1_0.conda\n",
            "Removed py-xgboost-1.2.0-py37hc8dfbb8_0.tar.bz2\n",
            "Removed py-lief-0.9.0-py37h7725739_2.conda\n",
            "Removed importlib-metadata-3.10.1-py37h89c1867_0.tar.bz2\n",
            "Removed rope-0.14.0-py_0.tar.bz2\n",
            "Removed path.py-12.0.1-py_0.tar.bz2\n",
            "Removed tqdm-4.36.1-py_0.conda\n",
            "Removed dask-core-2.5.2-py_0.tar.bz2\n",
            "Removed chardet-3.0.4-py37_1003.conda\n",
            "Removed py-1.8.0-py37_0.conda\n",
            "Removed pytest-openfiles-0.4.0-py_0.tar.bz2\n",
            "Removed ca-certificates-2019.8.28-0.tar.bz2\n",
            "Removed xlrd-1.2.0-py37_0.conda\n",
            "Removed conda-verify-3.4.2-py_1.tar.bz2\n",
            "Removed sphinxcontrib-qthelp-1.0.2-py_0.tar.bz2\n",
            "Removed backports.weakref-1.0.post1-py_1.tar.bz2\n",
            "Removed soupsieve-1.9.3-py37_0.tar.bz2\n",
            "Removed spyder-kernels-0.5.2-py37_0.tar.bz2\n",
            "Removed pyparsing-2.4.2-py_0.tar.bz2\n",
            "Removed jdcal-1.4.1-py_0.tar.bz2\n",
            "Removed nose-1.3.7-py37_2.conda\n",
            "Removed markdown-3.3.4-pyhd8ed1ab_0.tar.bz2\n",
            "Removed fribidi-1.0.5-h7b6447c_0.conda\n",
            "Removed gstreamer-1.14.0-hb453b48_1.conda\n",
            "Removed olefile-0.46-py37_0.conda\n",
            "Removed backports.functools_lru_cache-1.5-py_2.tar.bz2\n",
            "Removed glob2-0.7-py_0.tar.bz2\n",
            "Removed sortedcontainers-2.1.0-py37_0.conda\n",
            "Removed tornado-6.0.3-py37h7b6447c_0.conda\n",
            "Removed beautifulsoup4-4.8.0-py37_0.conda\n",
            "Removed traitlets-4.3.3-py37_0.tar.bz2\n",
            "Removed pandoc-2.2.3.2-0.conda\n",
            "Removed wcwidth-0.1.7-py37_0.conda\n",
            "Removed pandas-0.25.1-py37he6710b0_0.conda\n",
            "Removed openpyxl-3.0.0-py_0.tar.bz2\n",
            "Removed alabaster-0.7.12-py37_0.conda\n",
            "Removed _libgcc_mutex-0.1-main.conda\n",
            "Removed scikit-learn-0.21.3-py37hd81dba3_0.conda\n",
            "Removed google-pasta-0.2.0-pyh8c360ce_0.tar.bz2\n",
            "Removed openssl-1.1.1d-h7b6447c_2.conda\n",
            "Removed pylint-2.4.2-py37_0.tar.bz2\n",
            "Removed backports-1.0-py_2.tar.bz2\n",
            "Removed cloudpickle-1.2.2-py_0.tar.bz2\n",
            "Removed libboost-1.67.0-h46d08c1_4.conda\n",
            "Removed python-3.7.4-h265db76_1.conda\n",
            "Removed partd-1.0.0-py_0.tar.bz2\n",
            "Removed ruamel_yaml-0.15.46-py37h14c3975_0.conda\n",
            "Removed tensorflow-1.14.0-gpu_py37h74c33d7_0.conda\n",
            "Removed python_abi-3.7-1_cp37m.tar.bz2\n",
            "Removed blosc-1.16.3-hd408876_0.conda\n",
            "Removed entrypoints-0.3-py37_0.conda\n",
            "Removed lz4-c-1.8.1.2-h14c3975_0.conda\n",
            "Removed glib-2.56.2-hd408876_0.conda\n",
            "Removed et_xmlfile-1.0.1-py37_0.conda\n",
            "Removed pytest-arraydiff-0.3-py37h39e3cac_0.conda\n",
            "Removed jupyter_client-5.3.3-py37_1.tar.bz2\n",
            "WARNING: /root/.conda/pkgs does not exist\n",
            "Cache location: /usr/local/pkgs\n",
            "Will remove the following packages:\n",
            "/usr/local/pkgs\n",
            "---------------\n",
            "\n",
            "anaconda-2019.10-py37_0                       60 KB\n",
            "conda-env-2.6.0-1                              6 KB\n",
            "python_abi-3.7-1_cp37m                        10 KB\n",
            "xgboost-1.2.0-py37h3340039_0                  32 KB\n",
            "tensorflow-gpu-1.14.0-h0d30ee6_0              18 KB\n",
            "dask-2.5.2-py_0                               40 KB\n",
            "numpy-1.17.2-py37haad9e8e_0                   11 KB\n",
            "blas-1.0-mkl                                  15 KB\n",
            "conda-4.7.12-py37_0                         11.4 MB\n",
            "_py-xgboost-mutex-2.0-cpu_0                   22 KB\n",
            "get_terminal_size-1.0.0-haa9412d_0             7 KB\n",
            "tensorflow-1.14.0-gpu_py37h74c33d7_0          12 KB\n",
            "_tflow_select-2.1.0-gpu                        5 KB\n",
            "_libgcc_mutex-0.1-main                         7 KB\n",
            "\n",
            "---------------------------------------------------\n",
            "Total:                                      11.6 MB\n",
            "\n",
            "removing anaconda-2019.10-py37_0\n",
            "removing conda-env-2.6.0-1\n",
            "removing python_abi-3.7-1_cp37m\n",
            "removing xgboost-1.2.0-py37h3340039_0\n",
            "removing tensorflow-gpu-1.14.0-h0d30ee6_0\n",
            "removing dask-2.5.2-py_0\n",
            "removing numpy-1.17.2-py37haad9e8e_0\n",
            "removing blas-1.0-mkl\n",
            "removing conda-4.7.12-py37_0\n",
            "removing _py-xgboost-mutex-2.0-cpu_0\n",
            "removing get_terminal_size-1.0.0-haa9412d_0\n",
            "removing tensorflow-1.14.0-gpu_py37h74c33d7_0\n",
            "removing _tflow_select-2.1.0-gpu\n",
            "removing _libgcc_mutex-0.1-main\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coNNIQafgoSC",
        "outputId": "af3b264c-3655-4d41-8e9c-e67abbdaa329"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE8nok-6FHLX"
      },
      "source": [
        "h1 = pd.read_csv(\"/content/drive/MyDrive/Columbia_E4511/merge.csv\", index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdjzM5I-kbgC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_fQuS473N1M"
      },
      "source": [
        "h1=h1[~h1.VALUE_NUM_mean.isna()]\n",
        "h1=h1[h1.VALUE_NUM_mean>2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "LOZHYt6EGzbY",
        "outputId": "97b75d5e-0613-4134-b146-c5fefb9602be"
      },
      "source": [
        "h1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>compound_id</th>\n",
              "      <th>base_rdkit_smiles</th>\n",
              "      <th>PXC50</th>\n",
              "      <th>active</th>\n",
              "      <th>VALUE_NUM_mean</th>\n",
              "      <th>VALUE_NUM_std</th>\n",
              "      <th>Perc_Var</th>\n",
              "      <th>Remove_BadDuplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CHEMBL512967</td>\n",
              "      <td>CCC(=O)N(Cc1ccc(Cl)cc1Cl)[C@H]1CCNC1</td>\n",
              "      <td>7.22000</td>\n",
              "      <td>1</td>\n",
              "      <td>7.220925</td>\n",
              "      <td>0.001308</td>\n",
              "      <td>0.012810</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CHEMBL4248596</td>\n",
              "      <td>COc1ccccc1N1CCN(CCCNC(=O)c2ccc(-c3ccccc3)cc2)CC1</td>\n",
              "      <td>5.30000</td>\n",
              "      <td>0</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CHEMBL67203</td>\n",
              "      <td>c1ccc(CCCN2CCCC(CNCCOC(c3ccccc3)c3ccccc3)C2)cc1</td>\n",
              "      <td>7.01000</td>\n",
              "      <td>1</td>\n",
              "      <td>7.325000</td>\n",
              "      <td>0.445477</td>\n",
              "      <td>4.300341</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CHEMBL497479</td>\n",
              "      <td>CNC[C@@H]1COc2ccccc2[C@@H]1Oc1ccccc1Cl</td>\n",
              "      <td>7.51000</td>\n",
              "      <td>1</td>\n",
              "      <td>7.550000</td>\n",
              "      <td>0.056569</td>\n",
              "      <td>0.529801</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CHEMBL4226362</td>\n",
              "      <td>CN(C)C[C@]1(c2ccc(Cl)c(Cl)c2)CC[C@@](C)(O)CC1</td>\n",
              "      <td>8.20500</td>\n",
              "      <td>1</td>\n",
              "      <td>8.205000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4615</th>\n",
              "      <td>CHEMBL594388</td>\n",
              "      <td>CN1C2CCC1[C@@H](C(=O)N[C@H]1CC[C@H](NC(=O)[C@H...</td>\n",
              "      <td>5.30000</td>\n",
              "      <td>1</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4616</th>\n",
              "      <td>CHEMBL607547</td>\n",
              "      <td>CN1C2CCC1[C@@H](C(=O)NCc1ccc(CCNC(=O)[C@H]3C4C...</td>\n",
              "      <td>5.89000</td>\n",
              "      <td>1</td>\n",
              "      <td>5.890000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4617</th>\n",
              "      <td>46226549</td>\n",
              "      <td>CN1C2CCC1[C@@H](C(=O)NCCCCCCCCCCNC(=O)[C@H]1C3...</td>\n",
              "      <td>5.82391</td>\n",
              "      <td>1</td>\n",
              "      <td>5.823910</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4618</th>\n",
              "      <td>CHEMBL595767</td>\n",
              "      <td>CN1C2CCC1[C@@H](C(=O)NCc1ccc(CNC(=O)[C@H]3C4CC...</td>\n",
              "      <td>6.21000</td>\n",
              "      <td>1</td>\n",
              "      <td>6.210000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4619</th>\n",
              "      <td>CHEMBL611963</td>\n",
              "      <td>CN1C2CCC1[C@@H](C(=O)Nc1ccc(CNC(=O)[C@H]3C4CCC...</td>\n",
              "      <td>5.57000</td>\n",
              "      <td>1</td>\n",
              "      <td>5.570000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3119 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        compound_id  ... Remove_BadDuplicate\n",
              "0      CHEMBL512967  ...                   0\n",
              "1     CHEMBL4248596  ...                   0\n",
              "2       CHEMBL67203  ...                   0\n",
              "3      CHEMBL497479  ...                   0\n",
              "4     CHEMBL4226362  ...                   0\n",
              "...             ...  ...                 ...\n",
              "4615   CHEMBL594388  ...                   0\n",
              "4616   CHEMBL607547  ...                   0\n",
              "4617       46226549  ...                   0\n",
              "4618   CHEMBL595767  ...                   0\n",
              "4619   CHEMBL611963  ...                   0\n",
              "\n",
              "[3119 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA8ARleo3h53"
      },
      "source": [
        "### Split (and featurize) the dataset\n",
        "- if you want to calculate molecular descriptors, do it here\n",
        "- change `featurizer` to 'computed_descriptors' and `descriptor_type` to 'rdkit_raw' or 'mordred_filtered'\n",
        "- each time you featurize, a new split table will be generated. moving forward, only pick one to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eQC31_fA2wD"
      },
      "source": [
        "train_file = \"/content/drive/MyDrive/Columbia_E4511/merge.csv\"\n",
        "response_col = \"VALUE_NUM_mean\"\n",
        "compound_id = \"compound_id\"\n",
        "smiles_col = \"base_rdkit_smiles\"\n",
        "result_dir = \"/content/drive/MyDrive/Columbia_E4511/models\"\n",
        "params = {\n",
        "        \"system\": \"LC\",\n",
        "        \"lc_account\": 'None',\n",
        "        \"datastore\": \"False\",\n",
        "        \"save_results\": \"False\",\n",
        "        \"data_owner\": \"username\",\n",
        "        \"prediction_type\": \"regression\",\n",
        "        \"dataset_key\": train_file,\n",
        "        \"id_col\": compound_id,\n",
        "        \"smiles_col\": smiles_col,\n",
        "        \"response_cols\": response_col,\n",
        "        \"previously_split\": \"False\",\n",
        "        \"split_only\": \"True\",\n",
        "        \"featurizer\": \"computed_descriptors\",\n",
        "        \"model_type\": \"RF\",\n",
        "        \"verbose\": \"True\",\n",
        "        \"transformers\": \"True\",\n",
        "        'max_epochs': '70',\n",
        "        \"rerun\": \"False\",\n",
        "        \"result_dir\": result_dir,\n",
        "        \"descriptor_type\": \"rdkit_raw\",\n",
        "        \"split_valid_frac\": \"0.10\",\n",
        "        \"split_test_frac\": \"0.10\"\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcrEY3Bc471H"
      },
      "source": [
        "# # # dataset csv file needs to not have an unnamed first column in order to \n",
        "# # # compute moe descriptors for some reason /shrug\n",
        "# # # naming it index works, naming it idx messes up the id columns\n",
        "# # name it manually before running this\n",
        "# pparams = parse.wrapper(params)\n",
        "# MP = mp.ModelPipeline(pparams)\n",
        "\n",
        "# # # comment out this line after splitting once so you don't re-split\n",
        "# split_uuid = MP.split_dataset()\n",
        "# # pparams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSrHN7pU5Cvs"
      },
      "source": [
        "# split_uuid\n",
        "# copy/paste this into the next cell to use the same split_uuid each time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PivCHbJZgtX9"
      },
      "source": [
        "split_uuid = 'c80c74b3-5c7e-4945-9979-94ccd26cdbf6' # 15/15/70 split\n",
        "split_uuid = 'ead9410d-7abc-41cc-8713-f78dac0106a8' # 10/10/80 split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKP_mFuB5giz"
      },
      "source": [
        "### Grid search\n",
        "#### Tunable parameters for Random Forest models\n",
        "- rf_estimators: number of estimators to use in random forest models\n",
        "- rf_max_depth: the maximum depth of a decision tree in the random forest\n",
        "- rf_max_features: max number of features to split random forest nodes (can't be greater than total number of features)\n",
        "\n",
        "#### NN models\n",
        "- learning_rate: >0.05 is probably too high\n",
        "- layer_sizes: ordered list of layer sizes. due to architecture of NNs you usually want this to be a power of 2 and reduce in size for each layer\n",
        "- dropouts: list of dropouts associated with each layer.\n",
        "- since dropouts and layer sizes must be the same length, either only do a grid search with 2 layers or 3 layers, or create a tuple of layers and dropouts\n",
        "\n",
        "#### XGBoost models\n",
        "- xgb_gamma\n",
        "- xgb_learning_rate: higher values can do better than NN learning rates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBQ-bRaW9oq5"
      },
      "source": [
        "###### RF(Classification) Models\n",
        "add 'active' column to featurized data or the features will be recalculated for each model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0YQ1dfZZn8K"
      },
      "source": [
        "#mf = pd.read_csv(\"/content/drive/MyDrive/Columbia_E4511/scaled_descriptors/HTR3A_curated_with_mordred_filtered_descriptors.csv\")\n",
        "#mf=mf.merge(h1[['base_rdkit_smiles','active']])\n",
        "#mf.to_csv(\"/content/drive/MyDrive/Columbia_E4511/scaled_descriptors/HTR3A_curated_with_mordred_filtered_descriptors.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25hhGGh3IvqR"
      },
      "source": [
        "params={'data_owner': 'username',\n",
        " 'dataset_key': '/content/drive/MyDrive/Columbia_E4511/merge.csv',\n",
        " 'datastore': 'False',\n",
        " 'featurizer': 'ecfp',\n",
        "#  'descriptor_type':'mordred_filtered',\n",
        " 'id_col': 'compound_id',\n",
        " 'lc_account': 'None',\n",
        " 'max_epochs': '70',\n",
        " 'model_type': 'RF',\n",
        " 'prediction_type': 'classification',\n",
        " 'previously_split': 'True',\n",
        " 'rerun': 'False',\n",
        " 'response_cols': 'active',\n",
        " 'result_dir': '/content/drive/MyDrive/Columbia_E4511/models',\n",
        " 'save_results': 'False',\n",
        " 'smiles_col': 'base_rdkit_smiles',\n",
        " 'split_uuid': 'ead9410d-7abc-41cc-8713-f78dac0106a8',\n",
        " 'system': 'LC',\n",
        " 'transformers': 'True',\n",
        " 'uncertainty': 'True',\n",
        " 'verbose': 'True'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6FBeUGh5mGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac3f7f5-e172-4da3-e867-9594c1cfaea9"
      },
      "source": [
        "# 210 models per feature set\n",
        "estimator_choice = [16,24,32,64,128,256,512]\n",
        "depth_choice = [16,24,32,64,128,256]\n",
        "features_choice = [256,512] #16,24,32,64,128, # can only be < total number of features\n",
        "\n",
        "for rf_estimator in estimator_choice:\n",
        "    for rf_depth in depth_choice:\n",
        "        for rf_feature in features_choice:\n",
        "            params[\"rf_estimators\"] = rf_estimator\n",
        "            params[\"rf_max_depth\"] = rf_depth\n",
        "            params[\"rf_max_features\"] = rf_feature\n",
        "            tp = parse.wrapper(params)\n",
        "            pl = mp.ModelPipeline(tp)\n",
        "            pl.train_model()\n",
        "            pred_data = pl.model_wrapper.get_perf_data(subset=\"valid\", epoch_label=\"best\")\n",
        "            pred_results = pred_data.get_prediction_results()\n",
        "            print(f\"rf_estimators: {rf_estimator}, rf_max_depth: {rf_depth}, rf_max_features: {rf_feature}, valid_roc_auc: {pred_results['roc_auc_score']}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:41:16,351 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:41:16,353 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:41:18,262 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_cb0c83f2-c20e-4608-b179-0743c66c31a9.csv\n",
            "2021-04-13 16:41:19,816 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/d3d6fd26-a5df-4e59-b8a9-2ba332e4a1b2/model_metadata.json\n",
            "2021-04-13 16:41:19,832 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/d3d6fd26-a5df-4e59-b8a9-2ba332e4a1b2/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_d3d6fd26-a5df-4e59-b8a9-2ba332e4a1b2.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 16, rf_max_features: 256, valid_roc_auc: 0.8047553037608486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:41:31,684 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:41:31,685 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:41:33,604 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_5d8611e5-8239-44ea-a76a-01b0f6ae3395.csv\n",
            "2021-04-13 16:41:35,501 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/263ac23c-9d92-4b17-90a3-7a56312ec6e4/model_metadata.json\n",
            "2021-04-13 16:41:35,515 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/263ac23c-9d92-4b17-90a3-7a56312ec6e4/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_263ac23c-9d92-4b17-90a3-7a56312ec6e4.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 16, rf_max_features: 512, valid_roc_auc: 0.8017116682738669\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:41:47,466 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:41:47,467 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:41:49,407 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_54a03eed-80e9-4f1a-8ded-a42adbb65ff4.csv\n",
            "2021-04-13 16:41:51,124 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/c4ba385e-040a-4cda-b91d-c529bbc66e7c/model_metadata.json\n",
            "2021-04-13 16:41:51,139 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/c4ba385e-040a-4cda-b91d-c529bbc66e7c/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_c4ba385e-040a-4cda-b91d-c529bbc66e7c.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 24, rf_max_features: 256, valid_roc_auc: 0.8079194792671166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:42:02,862 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:42:02,863 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:42:04,782 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ebc7b07a-c95b-4bfa-a539-a36bea33b8aa.csv\n",
            "2021-04-13 16:42:06,657 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/15e7de7a-863b-4ac1-8644-ce26e7129684/model_metadata.json\n",
            "2021-04-13 16:42:06,673 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/15e7de7a-863b-4ac1-8644-ce26e7129684/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_15e7de7a-863b-4ac1-8644-ce26e7129684.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 24, rf_max_features: 512, valid_roc_auc: 0.8016815332690452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:42:18,506 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:42:18,507 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:42:20,457 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_8edda447-ce6c-4be2-8586-68aeb836ac60.csv\n",
            "2021-04-13 16:42:22,132 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/a203b858-8f41-4d2d-bd47-23d7762fe637/model_metadata.json\n",
            "2021-04-13 16:42:22,150 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/a203b858-8f41-4d2d-bd47-23d7762fe637/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_a203b858-8f41-4d2d-bd47-23d7762fe637.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 32, rf_max_features: 256, valid_roc_auc: 0.8127712150433943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:42:33,942 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:42:33,943 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:42:35,909 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_73c8a034-5d47-49a1-ae7e-83205f55c99c.csv\n",
            "2021-04-13 16:42:37,879 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/29fc1423-81d5-4b71-b8ed-1debc51ff54f/model_metadata.json\n",
            "2021-04-13 16:42:37,895 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/29fc1423-81d5-4b71-b8ed-1debc51ff54f/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_29fc1423-81d5-4b71-b8ed-1debc51ff54f.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 32, rf_max_features: 512, valid_roc_auc: 0.78200337512054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:42:49,711 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:42:49,712 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:42:51,672 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_8ca6d1bd-142b-4a04-92d9-0326d2f37279.csv\n",
            "2021-04-13 16:42:53,351 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/23dd72e1-33ba-4f15-807f-aa7c6ddd7690/model_metadata.json\n",
            "2021-04-13 16:42:53,367 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/23dd72e1-33ba-4f15-807f-aa7c6ddd7690/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_23dd72e1-33ba-4f15-807f-aa7c6ddd7690.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 64, rf_max_features: 256, valid_roc_auc: 0.8096070395371263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:43:05,221 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:43:05,222 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:43:07,166 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_d4105809-0155-49bf-9223-5bfb2f9e55c2.csv\n",
            "2021-04-13 16:43:09,339 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/d94574dd-0e2a-46e8-8910-fb4929e3ef0e/model_metadata.json\n",
            "2021-04-13 16:43:09,358 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/d94574dd-0e2a-46e8-8910-fb4929e3ef0e/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_d94574dd-0e2a-46e8-8910-fb4929e3ef0e.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 64, rf_max_features: 512, valid_roc_auc: 0.7772119093539055\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:43:21,183 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:43:21,184 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:43:23,109 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_d16dd0d9-4343-4b1b-b106-772d31bffc74.csv\n",
            "2021-04-13 16:43:24,897 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/5caed64a-c4ec-4bf4-ab31-993e9082444e/model_metadata.json\n",
            "2021-04-13 16:43:24,914 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/5caed64a-c4ec-4bf4-ab31-993e9082444e/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_5caed64a-c4ec-4bf4-ab31-993e9082444e.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 128, rf_max_features: 256, valid_roc_auc: 0.8096070395371263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:43:36,710 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:43:36,711 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:43:38,634 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_5af63685-666b-407a-81be-6e0c1c7937ef.csv\n",
            "2021-04-13 16:43:40,703 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/be84a4d6-776f-42e6-b006-e9475a74bae6/model_metadata.json\n",
            "2021-04-13 16:43:40,720 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/be84a4d6-776f-42e6-b006-e9475a74bae6/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_be84a4d6-776f-42e6-b006-e9475a74bae6.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 128, rf_max_features: 512, valid_roc_auc: 0.7772119093539054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:43:52,517 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:43:52,518 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:43:54,442 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_8b7a45dd-b1b8-4659-a8c7-72b491c46f59.csv\n",
            "2021-04-13 16:43:56,113 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/6801f126-508f-4d76-95c1-b7e159fed352/model_metadata.json\n",
            "2021-04-13 16:43:56,130 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/6801f126-508f-4d76-95c1-b7e159fed352/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_6801f126-508f-4d76-95c1-b7e159fed352.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 256, rf_max_features: 256, valid_roc_auc: 0.8095467695274832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:44:08,038 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:44:08,039 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:44:10,008 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_09087995-b14f-4c98-823b-df90d8cfaf16.csv\n",
            "2021-04-13 16:44:12,079 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/f8bd052c-6a0f-4ad0-a9b1-360c24a68bfd/model_metadata.json\n",
            "2021-04-13 16:44:12,096 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/f8bd052c-6a0f-4ad0-a9b1-360c24a68bfd/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_f8bd052c-6a0f-4ad0-a9b1-360c24a68bfd.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 256, rf_max_features: 512, valid_roc_auc: 0.7772119093539055\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:44:23,895 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:44:23,896 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:44:25,855 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_318b46cb-0918-4b21-8e12-a34767957e68.csv\n",
            "2021-04-13 16:44:27,533 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/57c6c57f-aae3-4636-8992-eb223e84d1ed/model_metadata.json\n",
            "2021-04-13 16:44:27,550 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/57c6c57f-aae3-4636-8992-eb223e84d1ed/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_57c6c57f-aae3-4636-8992-eb223e84d1ed.tar.gz\n",
            "rf_estimators: 24, rf_max_depth: 16, rf_max_features: 256, valid_roc_auc: 0.8155436354869817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:44:39,490 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:44:39,491 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:44:41,431 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_1f8297a8-5ef0-4c43-a39a-6e23ada97270.csv\n",
            "2021-04-13 16:44:43,307 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/6e1a42fe-f8c5-4dc1-bd0c-f744c2965977/model_metadata.json\n",
            "2021-04-13 16:44:43,345 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/6e1a42fe-f8c5-4dc1-bd0c-f744c2965977/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_6e1a42fe-f8c5-4dc1-bd0c-f744c2965977.tar.gz\n",
            "rf_estimators: 24, rf_max_depth: 16, rf_max_features: 512, valid_roc_auc: 0.7917068466730954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:44:55,164 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:44:55,165 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:44:57,071 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_33c4514c-418a-4275-ad2b-e3c6263230e8.csv\n",
            "2021-04-13 16:44:58,757 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/7ad13be1-e946-4a17-8378-3219c23176b3/model_metadata.json\n",
            "2021-04-13 16:44:58,774 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/7ad13be1-e946-4a17-8378-3219c23176b3/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_7ad13be1-e946-4a17-8378-3219c23176b3.tar.gz\n",
            "rf_estimators: 24, rf_max_depth: 24, rf_max_features: 256, valid_roc_auc: 0.8212692864030859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:45:10,589 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:45:10,590 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:45:12,503 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_734a07c8-d1d7-4a33-b5c7-52859ec57261.csv\n",
            "2021-04-13 16:45:14,481 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/bc0f6713-0eff-44ac-8784-21b45ac70b60/model_metadata.json\n",
            "2021-04-13 16:45:14,498 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/bc0f6713-0eff-44ac-8784-21b45ac70b60/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_bc0f6713-0eff-44ac-8784-21b45ac70b60.tar.gz\n",
            "rf_estimators: 24, rf_max_depth: 24, rf_max_features: 512, valid_roc_auc: 0.798306412729026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:45:26,216 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:45:26,217 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:45:28,135 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_d6492248-0cf7-4f52-a4be-883b830ceaca.csv\n",
            "2021-04-13 16:45:29,833 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/e18cd5b0-eb87-4e00-a68e-e3d0070cb8f5/model_metadata.json\n",
            "2021-04-13 16:45:29,853 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/e18cd5b0-eb87-4e00-a68e-e3d0070cb8f5/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_e18cd5b0-eb87-4e00-a68e-e3d0070cb8f5.tar.gz\n",
            "rf_estimators: 24, rf_max_depth: 32, rf_max_features: 256, valid_roc_auc: 0.822324011571842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:45:41,809 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:45:41,810 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:45:43,743 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_3bd38386-216a-4e7a-b1a1-7d649d7fe100.csv\n",
            "2021-04-13 16:45:45,823 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/2f8a155e-7a2b-4c3c-9dc5-212306708a88/model_metadata.json\n",
            "2021-04-13 16:45:45,840 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/2f8a155e-7a2b-4c3c-9dc5-212306708a88/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_2f8a155e-7a2b-4c3c-9dc5-212306708a88.tar.gz\n",
            "rf_estimators: 24, rf_max_depth: 32, rf_max_features: 512, valid_roc_auc: 0.7852278206364514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:45:57,677 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:45:57,678 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:45:59,596 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_09b69d2e-ed60-42ce-9880-578c62078837.csv\n",
            "2021-04-13 16:46:01,367 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/a47d7244-c81c-4db3-a214-05cdac290315/model_metadata.json\n",
            "2021-04-13 16:46:01,386 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/a47d7244-c81c-4db3-a214-05cdac290315/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_a47d7244-c81c-4db3-a214-05cdac290315.tar.gz\n",
            "rf_estimators: 24, rf_max_depth: 64, rf_max_features: 256, valid_roc_auc: 0.8147902603664416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:46:13,226 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:46:13,227 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:46:15,156 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_9a7d01c8-01fc-4f88-a697-9c8ae1f9e3b0.csv\n",
            "2021-04-13 16:46:17,431 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/d731a5c9-2d0b-4f2c-9c82-df4db27af4bb/model_metadata.json\n",
            "2021-04-13 16:46:17,449 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/d731a5c9-2d0b-4f2c-9c82-df4db27af4bb/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_d731a5c9-2d0b-4f2c-9c82-df4db27af4bb.tar.gz\n",
            "rf_estimators: 24, rf_max_depth: 64, rf_max_features: 512, valid_roc_auc: 0.785107280617165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:46:29,213 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:46:29,214 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:46:31,118 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_38361c3a-d222-4d6a-a575-d37e4b7d071f.csv\n",
            "2021-04-13 16:46:32,890 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/209ac9de-ff20-4c93-8f22-3518fc5768a1/model_metadata.json\n",
            "2021-04-13 16:46:32,912 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/209ac9de-ff20-4c93-8f22-3518fc5768a1/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_209ac9de-ff20-4c93-8f22-3518fc5768a1.tar.gz\n",
            "rf_estimators: 24, rf_max_depth: 128, rf_max_features: 256, valid_roc_auc: 0.8170805207328834\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:46:44,753 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:46:44,754 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:46:46,677 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_3c64abcb-a083-47e2-b978-921847ccdc0a.csv\n",
            "2021-04-13 16:46:49,053 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/fbe0cbb1-fb85-4c71-af22-b0ad947b4b89/model_metadata.json\n",
            "2021-04-13 16:46:49,072 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/fbe0cbb1-fb85-4c71-af22-b0ad947b4b89/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_fbe0cbb1-fb85-4c71-af22-b0ad947b4b89.tar.gz\n",
            "rf_estimators: 24, rf_max_depth: 128, rf_max_features: 512, valid_roc_auc: 0.7851675506268081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:47:00,940 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:47:00,941 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:47:02,901 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_e92a95e1-48c5-4349-a790-c8b1fad18696.csv\n",
            "2021-04-13 16:47:04,687 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/bd6c622c-4caa-4cbd-a583-146c9bfdeec3/model_metadata.json\n",
            "2021-04-13 16:47:04,708 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/bd6c622c-4caa-4cbd-a583-146c9bfdeec3/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_bd6c622c-4caa-4cbd-a583-146c9bfdeec3.tar.gz\n",
            "rf_estimators: 24, rf_max_depth: 256, rf_max_features: 256, valid_roc_auc: 0.8170805207328833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:47:16,636 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:47:16,637 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:47:18,569 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_d87be71b-2e0f-45ff-9a8e-ea145d3c14fd.csv\n",
            "2021-04-13 16:47:20,841 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/9d432aa7-b37e-438d-9ffe-e59e9a22483a/model_metadata.json\n",
            "2021-04-13 16:47:20,860 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/9d432aa7-b37e-438d-9ffe-e59e9a22483a/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_9d432aa7-b37e-438d-9ffe-e59e9a22483a.tar.gz\n",
            "rf_estimators: 24, rf_max_depth: 256, rf_max_features: 512, valid_roc_auc: 0.785107280617165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:47:32,634 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:47:32,635 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:47:34,594 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_3fb35b58-5572-45b2-bcab-36f5b6c60cac.csv\n",
            "2021-04-13 16:47:36,275 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/0dae558d-0e7e-4b64-a671-bb342e80810b/model_metadata.json\n",
            "2021-04-13 16:47:36,292 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/0dae558d-0e7e-4b64-a671-bb342e80810b/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_0dae558d-0e7e-4b64-a671-bb342e80810b.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 16, rf_max_features: 256, valid_roc_auc: 0.8163572806171648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:47:48,108 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:47:48,110 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:47:50,063 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_d78e0020-1233-4b24-bd1f-ecef8bf0322e.csv\n",
            "2021-04-13 16:47:52,140 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/2d7ac91e-bfe4-4f72-9bf2-720f6840bdc9/model_metadata.json\n",
            "2021-04-13 16:47:52,156 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/2d7ac91e-bfe4-4f72-9bf2-720f6840bdc9/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_2d7ac91e-bfe4-4f72-9bf2-720f6840bdc9.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 16, rf_max_features: 512, valid_roc_auc: 0.7898384763741563\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:48:03,957 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:48:03,959 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:48:05,893 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_5948a47c-7bcc-418a-b7ea-31eb26a66bb3.csv\n",
            "2021-04-13 16:48:07,674 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/ca3cdca5-79d8-4a5a-83ae-de7e7e2eb172/model_metadata.json\n",
            "2021-04-13 16:48:07,695 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/ca3cdca5-79d8-4a5a-83ae-de7e7e2eb172/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_ca3cdca5-79d8-4a5a-83ae-de7e7e2eb172.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 24, rf_max_features: 256, valid_roc_auc: 0.8247950819672131\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:48:19,537 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:48:19,539 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:48:21,466 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_b5393e49-0f2e-4356-86cf-7c5cc42dde3a.csv\n",
            "2021-04-13 16:48:23,762 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/12d312fa-330a-427e-9b54-849a27163b61/model_metadata.json\n",
            "2021-04-13 16:48:23,780 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/12d312fa-330a-427e-9b54-849a27163b61/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_12d312fa-330a-427e-9b54-849a27163b61.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 24, rf_max_features: 512, valid_roc_auc: 0.7994214079074252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:48:35,743 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:48:35,744 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:48:37,678 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_bea85a22-ed30-4021-8934-be8e826d20d8.csv\n",
            "2021-04-13 16:48:39,565 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/3b9be545-3ea3-47af-bcaa-493ec5f1d2e0/model_metadata.json\n",
            "2021-04-13 16:48:39,587 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/3b9be545-3ea3-47af-bcaa-493ec5f1d2e0/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_3b9be545-3ea3-47af-bcaa-493ec5f1d2e0.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 32, rf_max_features: 256, valid_roc_auc: 0.8217514464802316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:48:51,395 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:48:51,396 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:48:53,323 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_00193e00-5bcb-4b4d-97c2-b14f0f820598.csv\n",
            "2021-04-13 16:48:55,712 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/e03926f8-d2a2-4742-9a09-c6522f3c0ae8/model_metadata.json\n",
            "2021-04-13 16:48:55,729 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/e03926f8-d2a2-4742-9a09-c6522f3c0ae8/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_e03926f8-d2a2-4742-9a09-c6522f3c0ae8.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 32, rf_max_features: 512, valid_roc_auc: 0.7909534715525555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:49:07,498 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:49:07,499 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:49:09,496 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_353de755-6596-4de4-a646-0cd47afddb38.csv\n",
            "2021-04-13 16:49:11,478 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/b4179d34-b81e-40bb-a175-815eb5066614/model_metadata.json\n",
            "2021-04-13 16:49:11,519 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/b4179d34-b81e-40bb-a175-815eb5066614/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_b4179d34-b81e-40bb-a175-815eb5066614.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 64, rf_max_features: 256, valid_roc_auc: 0.8200940212150434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:49:23,378 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:49:23,379 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:49:25,309 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_929a68c9-678f-4868-9fca-bce89c384f7c.csv\n",
            "2021-04-13 16:49:27,885 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/0bf12625-866d-4ae9-bd1f-79e1956a11ae/model_metadata.json\n",
            "2021-04-13 16:49:27,907 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/0bf12625-866d-4ae9-bd1f-79e1956a11ae/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_0bf12625-866d-4ae9-bd1f-79e1956a11ae.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 64, rf_max_features: 512, valid_roc_auc: 0.7810089199614272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:49:39,760 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:49:39,762 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:49:41,681 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_fa686754-0738-4d9b-b4c1-1512e422c096.csv\n",
            "2021-04-13 16:49:43,659 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/ef637aae-5e86-4bc1-8cdf-b24063971e2f/model_metadata.json\n",
            "2021-04-13 16:49:43,683 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/ef637aae-5e86-4bc1-8cdf-b24063971e2f/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_ef637aae-5e86-4bc1-8cdf-b24063971e2f.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 128, rf_max_features: 256, valid_roc_auc: 0.8215706364513019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:49:55,619 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:49:55,621 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:49:57,614 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_38799746-07b5-4712-a464-739b982c9b2b.csv\n",
            "2021-04-13 16:50:00,210 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/d2135198-315c-454f-ae65-7a5a02cda93a/model_metadata.json\n",
            "2021-04-13 16:50:00,255 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/d2135198-315c-454f-ae65-7a5a02cda93a/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_d2135198-315c-454f-ae65-7a5a02cda93a.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 128, rf_max_features: 512, valid_roc_auc: 0.7810089199614272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:50:12,064 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:50:12,065 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:50:13,983 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_4227dab4-752c-4802-9b64-655af9635c22.csv\n",
            "2021-04-13 16:50:15,968 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/aa8364c3-7cc8-438e-8956-c348a3bbbf21/model_metadata.json\n",
            "2021-04-13 16:50:15,991 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/aa8364c3-7cc8-438e-8956-c348a3bbbf21/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_aa8364c3-7cc8-438e-8956-c348a3bbbf21.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 256, rf_max_features: 256, valid_roc_auc: 0.8215706364513019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:50:27,791 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:50:27,792 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:50:29,719 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_bb28d73d-89cb-4e66-b787-47f1497a09ef.csv\n",
            "2021-04-13 16:50:32,313 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/637f708f-d685-4fff-8c1a-6b0778e1d943/model_metadata.json\n",
            "2021-04-13 16:50:32,334 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/637f708f-d685-4fff-8c1a-6b0778e1d943/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_637f708f-d685-4fff-8c1a-6b0778e1d943.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 256, rf_max_features: 512, valid_roc_auc: 0.7810089199614272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:50:44,200 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:50:44,201 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:50:46,108 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ad86ed16-015e-490e-89dd-d7304dd4cc1d.csv\n",
            "2021-04-13 16:50:48,237 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/20048a06-f673-4ea9-b0b0-7e8c1a69e887/model_metadata.json\n",
            "2021-04-13 16:50:48,258 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/20048a06-f673-4ea9-b0b0-7e8c1a69e887/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_20048a06-f673-4ea9-b0b0-7e8c1a69e887.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 16, rf_max_features: 256, valid_roc_auc: 0.8250662970106075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:51:00,140 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:51:00,141 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:51:02,070 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_e31befec-731f-4160-aaf2-7bed4ed49d08.csv\n",
            "2021-04-13 16:51:04,781 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/67b5a5fb-0a25-4011-af1f-4e5b8f1f57d3/model_metadata.json\n",
            "2021-04-13 16:51:04,803 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/67b5a5fb-0a25-4011-af1f-4e5b8f1f57d3/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_67b5a5fb-0a25-4011-af1f-4e5b8f1f57d3.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 16, rf_max_features: 512, valid_roc_auc: 0.8193707810993252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:51:16,838 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:51:16,839 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:51:18,757 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_6debf72e-19b4-4572-9ddd-2a5835ee884f.csv\n",
            "2021-04-13 16:51:21,058 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/01dd585a-851e-41a7-a4ea-92612e456333/model_metadata.json\n",
            "2021-04-13 16:51:21,083 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/01dd585a-851e-41a7-a4ea-92612e456333/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_01dd585a-851e-41a7-a4ea-92612e456333.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 24, rf_max_features: 256, valid_roc_auc: 0.8355834136933462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:51:32,831 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:51:32,832 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:51:34,799 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_5d997c46-4e21-40ee-b28f-493620c2bbff.csv\n",
            "2021-04-13 16:51:37,939 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/041c3049-84cf-432f-9662-8c47abf956a9/model_metadata.json\n",
            "2021-04-13 16:51:37,962 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/041c3049-84cf-432f-9662-8c47abf956a9/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_041c3049-84cf-432f-9662-8c47abf956a9.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 24, rf_max_features: 512, valid_roc_auc: 0.8074975891996143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:51:49,789 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:51:49,790 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:51:51,764 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_1e20d959-7758-4662-8d76-0bb26136a3b6.csv\n",
            "2021-04-13 16:51:54,307 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/7ccc7262-1859-4774-afa8-cf07c1e622ed/model_metadata.json\n",
            "2021-04-13 16:51:54,334 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/7ccc7262-1859-4774-afa8-cf07c1e622ed/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_7ccc7262-1859-4774-afa8-cf07c1e622ed.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 32, rf_max_features: 256, valid_roc_auc: 0.8284112825458052\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:52:06,088 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:52:06,089 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:52:08,011 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_20bdd901-5069-4dfd-bd44-e417d15b6b71.csv\n",
            "2021-04-13 16:52:11,531 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/ed13d32c-a9bc-4b75-9aaa-8424ea7d81f4/model_metadata.json\n",
            "2021-04-13 16:52:11,558 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/ed13d32c-a9bc-4b75-9aaa-8424ea7d81f4/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_ed13d32c-a9bc-4b75-9aaa-8424ea7d81f4.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 32, rf_max_features: 512, valid_roc_auc: 0.8037608486017358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:52:23,433 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:52:23,434 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:52:25,389 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_64714f3e-8e0f-4eeb-9c4b-fd1e85108860.csv\n",
            "2021-04-13 16:52:28,172 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/dd5f718b-23ec-4d26-b862-1780c54b3f10/model_metadata.json\n",
            "2021-04-13 16:52:28,204 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/dd5f718b-23ec-4d26-b862-1780c54b3f10/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_dd5f718b-23ec-4d26-b862-1780c54b3f10.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 64, rf_max_features: 256, valid_roc_auc: 0.8276880424300869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:52:40,116 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:52:40,117 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:52:42,037 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_65405a49-49c9-4380-8c70-c43bce90f31f.csv\n",
            "2021-04-13 16:52:46,076 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/752c6728-423f-43ee-8dea-87caffd8352c/model_metadata.json\n",
            "2021-04-13 16:52:46,105 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/752c6728-423f-43ee-8dea-87caffd8352c/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_752c6728-423f-43ee-8dea-87caffd8352c.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 64, rf_max_features: 512, valid_roc_auc: 0.8015609932497589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:52:57,965 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:52:57,966 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:52:59,892 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_8cc99854-c480-4941-a96e-9d9890ed1e10.csv\n",
            "2021-04-13 16:53:02,633 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/16c79680-ad7c-49b0-bb39-972dc736cfcf/model_metadata.json\n",
            "2021-04-13 16:53:02,663 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/16c79680-ad7c-49b0-bb39-972dc736cfcf/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_16c79680-ad7c-49b0-bb39-972dc736cfcf.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 128, rf_max_features: 256, valid_roc_auc: 0.8279893924783028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:53:14,420 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:53:14,421 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:53:16,369 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_189ec872-79cb-4cbd-a605-76be4f31edac.csv\n",
            "2021-04-13 16:53:20,404 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/410491ca-cee9-4b58-835b-a2eddaf01ab5/model_metadata.json\n",
            "2021-04-13 16:53:20,433 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/410491ca-cee9-4b58-835b-a2eddaf01ab5/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_410491ca-cee9-4b58-835b-a2eddaf01ab5.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 128, rf_max_features: 512, valid_roc_auc: 0.8015308582449373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:53:32,271 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:53:32,272 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:53:34,240 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_86be7ba8-4aa2-45af-a99a-06136ec41e50.csv\n",
            "2021-04-13 16:53:36,911 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/713a8397-a9df-4b84-a184-fa54cd285f03/model_metadata.json\n",
            "2021-04-13 16:53:36,941 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/713a8397-a9df-4b84-a184-fa54cd285f03/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_713a8397-a9df-4b84-a184-fa54cd285f03.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 256, rf_max_features: 256, valid_roc_auc: 0.8279893924783028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:53:48,821 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:53:48,822 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:53:50,765 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_540ecbdf-36af-4b9f-ab69-d2792f111228.csv\n",
            "2021-04-13 16:53:54,702 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/37e8c9b4-fd84-40ba-a5dc-174f94d6af2c/model_metadata.json\n",
            "2021-04-13 16:53:54,749 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/37e8c9b4-fd84-40ba-a5dc-174f94d6af2c/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_37e8c9b4-fd84-40ba-a5dc-174f94d6af2c.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 256, rf_max_features: 512, valid_roc_auc: 0.8015609932497589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:54:06,591 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:54:06,592 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:54:08,539 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_70aa6911-4f9d-4014-99a0-2914c3539571.csv\n",
            "2021-04-13 16:54:11,545 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/5a2c83ad-01db-4ef5-81da-963f258dbbd6/model_metadata.json\n",
            "2021-04-13 16:54:11,575 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/5a2c83ad-01db-4ef5-81da-963f258dbbd6/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_5a2c83ad-01db-4ef5-81da-963f258dbbd6.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 16, rf_max_features: 256, valid_roc_auc: 0.8206364513018323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:54:23,450 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:54:23,451 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:54:25,397 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_c527d76e-f209-4784-935f-fc827fe064b6.csv\n",
            "2021-04-13 16:54:29,661 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/5c01fc89-2f89-4362-8e38-8d31a80a1b83/model_metadata.json\n",
            "2021-04-13 16:54:29,691 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/5c01fc89-2f89-4362-8e38-8d31a80a1b83/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_5c01fc89-2f89-4362-8e38-8d31a80a1b83.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 16, rf_max_features: 512, valid_roc_auc: 0.8093659594985535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:54:41,488 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:54:41,490 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:54:43,417 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_f00bbf5b-a54c-41b5-9db9-f22d00e22c99.csv\n",
            "2021-04-13 16:54:46,722 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/6ce81e78-cb74-400e-8124-dc0307774f95/model_metadata.json\n",
            "2021-04-13 16:54:46,759 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/6ce81e78-cb74-400e-8124-dc0307774f95/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_6ce81e78-cb74-400e-8124-dc0307774f95.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 24, rf_max_features: 256, valid_roc_auc: 0.8287126325940212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:54:58,643 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:54:58,644 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:55:00,620 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_da3b9ac5-b605-4ecb-9eac-11ee01747d59.csv\n",
            "2021-04-13 16:55:05,525 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/0b9523b7-360f-4c6d-9a56-a58ee331dfa7/model_metadata.json\n",
            "2021-04-13 16:55:05,562 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/0b9523b7-360f-4c6d-9a56-a58ee331dfa7/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_0b9523b7-360f-4c6d-9a56-a58ee331dfa7.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 24, rf_max_features: 512, valid_roc_auc: 0.8158751205400192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:55:17,505 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:55:17,506 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:55:19,460 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_2c4793a6-d4cf-45cc-a868-3dc3da6277af.csv\n",
            "2021-04-13 16:55:22,964 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/c1370f84-9638-4e91-afb7-51080a8eb77e/model_metadata.json\n",
            "2021-04-13 16:55:23,004 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/c1370f84-9638-4e91-afb7-51080a8eb77e/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_c1370f84-9638-4e91-afb7-51080a8eb77e.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 32, rf_max_features: 256, valid_roc_auc: 0.8284715525554485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:55:34,865 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:55:34,866 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:55:36,795 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_d1ee63ec-9612-4e1c-afd7-dcca8d8a4977.csv\n",
            "2021-04-13 16:55:42,280 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/5861d0fd-0350-4290-86dd-d030aee5c951/model_metadata.json\n",
            "2021-04-13 16:55:42,320 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/5861d0fd-0350-4290-86dd-d030aee5c951/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_5861d0fd-0350-4290-86dd-d030aee5c951.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 32, rf_max_features: 512, valid_roc_auc: 0.806834619093539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:55:54,090 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:55:54,091 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:55:56,011 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_0da093a6-08ee-4f06-b24d-dba964f95b6d.csv\n",
            "2021-04-13 16:55:59,915 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/0bd08ca7-0a73-4dd2-9276-a078232f497b/model_metadata.json\n",
            "2021-04-13 16:55:59,965 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/0bd08ca7-0a73-4dd2-9276-a078232f497b/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_0bd08ca7-0a73-4dd2-9276-a078232f497b.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 64, rf_max_features: 256, valid_roc_auc: 0.8265730472516876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:56:11,786 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:56:11,787 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:56:13,703 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_c1f8da62-dc77-4d4c-a1ad-247badbbfedf.csv\n",
            "2021-04-13 16:56:20,129 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/c4c80a50-f56b-4229-9a22-ee12c80f5551/model_metadata.json\n",
            "2021-04-13 16:56:20,175 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/c4c80a50-f56b-4229-9a22-ee12c80f5551/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_c4c80a50-f56b-4229-9a22-ee12c80f5551.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 64, rf_max_features: 512, valid_roc_auc: 0.8008678881388621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:56:31,983 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:56:31,984 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:56:33,963 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_654a654a-f485-47ab-b567-db9909478f8a.csv\n",
            "2021-04-13 16:56:38,014 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/b29c7fd2-ea19-4683-b0b2-bedd4b11bd93/model_metadata.json\n",
            "2021-04-13 16:56:38,067 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/b29c7fd2-ea19-4683-b0b2-bedd4b11bd93/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_b29c7fd2-ea19-4683-b0b2-bedd4b11bd93.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 128, rf_max_features: 256, valid_roc_auc: 0.8269648023143684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:56:50,043 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:56:50,045 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:56:52,021 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_a6ed951d-b99a-4a17-b381-692d18300e7c.csv\n",
            "2021-04-13 16:56:58,644 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/2730da27-3c0d-49e1-9a80-8986b3307350/model_metadata.json\n",
            "2021-04-13 16:56:58,688 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/2730da27-3c0d-49e1-9a80-8986b3307350/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_2730da27-3c0d-49e1-9a80-8986b3307350.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 128, rf_max_features: 512, valid_roc_auc: 0.8008678881388621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:57:10,764 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:57:10,765 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:57:12,750 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_fac44151-90cc-495c-b12c-05fcc6f93ac7.csv\n",
            "2021-04-13 16:57:16,825 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/2bf92a8f-5b96-4e07-b4f6-2b7940b7fe6a/model_metadata.json\n",
            "2021-04-13 16:57:16,898 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/2bf92a8f-5b96-4e07-b4f6-2b7940b7fe6a/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_2bf92a8f-5b96-4e07-b4f6-2b7940b7fe6a.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 256, rf_max_features: 256, valid_roc_auc: 0.8269648023143684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:57:28,869 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:57:28,870 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:57:30,887 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_068fcc44-3532-4743-87e4-be9a53609ed2.csv\n",
            "2021-04-13 16:57:37,535 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/381abee3-f085-47a5-a98c-6af071bb875c/model_metadata.json\n",
            "2021-04-13 16:57:37,580 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/381abee3-f085-47a5-a98c-6af071bb875c/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_381abee3-f085-47a5-a98c-6af071bb875c.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 256, rf_max_features: 512, valid_roc_auc: 0.8008678881388621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:57:49,504 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:57:49,505 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:57:51,485 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_a66d9285-e059-4cd9-a27d-dbe09ce81222.csv\n",
            "2021-04-13 16:57:56,153 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/02775cf3-90e7-4b3f-a060-b83de78d1183/model_metadata.json\n",
            "2021-04-13 16:57:56,204 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/02775cf3-90e7-4b3f-a060-b83de78d1183/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_02775cf3-90e7-4b3f-a060-b83de78d1183.tar.gz\n",
            "rf_estimators: 256, rf_max_depth: 16, rf_max_features: 256, valid_roc_auc: 0.8253977820636451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:58:08,114 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:58:08,115 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:58:10,110 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_86403d70-5ec0-4b2c-9492-7c521bdce12d.csv\n",
            "2021-04-13 16:58:17,899 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/9c7cfaad-291f-45f3-aa4a-d40de682168c/model_metadata.json\n",
            "2021-04-13 16:58:17,946 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/9c7cfaad-291f-45f3-aa4a-d40de682168c/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_9c7cfaad-291f-45f3-aa4a-d40de682168c.tar.gz\n",
            "rf_estimators: 256, rf_max_depth: 16, rf_max_features: 512, valid_roc_auc: 0.8115959498553521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:58:29,831 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:58:29,832 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:58:31,819 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ebff6e89-8978-44ee-b2b4-9bab88f5a0b9.csv\n",
            "2021-04-13 16:58:37,624 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/22fb423e-dc6f-4693-b5ae-897153bc236d/model_metadata.json\n",
            "2021-04-13 16:58:37,687 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/22fb423e-dc6f-4693-b5ae-897153bc236d/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_22fb423e-dc6f-4693-b5ae-897153bc236d.tar.gz\n",
            "rf_estimators: 256, rf_max_depth: 24, rf_max_features: 256, valid_roc_auc: 0.8278085824493732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:58:49,540 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:58:49,541 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:58:51,505 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_7fa6e81a-e5a8-4f5f-a231-d05c915b405b.csv\n",
            "2021-04-13 16:59:01,779 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/68aa4a45-eb2b-453c-a117-1f3b6e104973/model_metadata.json\n",
            "2021-04-13 16:59:01,838 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/68aa4a45-eb2b-453c-a117-1f3b6e104973/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_68aa4a45-eb2b-453c-a117-1f3b6e104973.tar.gz\n",
            "rf_estimators: 256, rf_max_depth: 24, rf_max_features: 512, valid_roc_auc: 0.8134643201542912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:59:13,687 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:59:13,688 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:59:15,719 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_1dc02e1f-797b-47b1-92ed-b06c354233ae.csv\n",
            "2021-04-13 16:59:22,582 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/c8f19142-85a9-428d-8266-4cc299569a26/model_metadata.json\n",
            "2021-04-13 16:59:22,650 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/c8f19142-85a9-428d-8266-4cc299569a26/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_c8f19142-85a9-428d-8266-4cc299569a26.tar.gz\n",
            "rf_estimators: 256, rf_max_depth: 32, rf_max_features: 256, valid_roc_auc: 0.8270250723240117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:59:34,546 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:59:34,547 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:59:36,523 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_7742b8be-10f2-4774-ae9b-c9b5f6f3b3d1.csv\n",
            "2021-04-13 16:59:47,923 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/2f6265bc-1f6d-4585-95c4-3e6a47674e88/model_metadata.json\n",
            "2021-04-13 16:59:47,987 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/2f6265bc-1f6d-4585-95c4-3e6a47674e88/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_2f6265bc-1f6d-4585-95c4-3e6a47674e88.tar.gz\n",
            "rf_estimators: 256, rf_max_depth: 32, rf_max_features: 512, valid_roc_auc: 0.8117767598842816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 16:59:59,802 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 16:59:59,803 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:00:01,776 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_c7d7fbb6-fa22-41c2-a09a-2b6f5e8db8c6.csv\n",
            "2021-04-13 17:00:09,359 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/8188eb7c-a9d1-4560-8ab0-9a6382750b20/model_metadata.json\n",
            "2021-04-13 17:00:09,446 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/8188eb7c-a9d1-4560-8ab0-9a6382750b20/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_8188eb7c-a9d1-4560-8ab0-9a6382750b20.tar.gz\n",
            "rf_estimators: 256, rf_max_depth: 64, rf_max_features: 256, valid_roc_auc: 0.8233787367405978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:00:21,436 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:00:21,437 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:00:23,443 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_d7a5819a-9e9f-4cac-9ca8-f60c2fbbf5f8.csv\n",
            "2021-04-13 17:00:37,009 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/e533f733-334d-4283-9211-c5bab36dd767/model_metadata.json\n",
            "2021-04-13 17:00:37,087 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/e533f733-334d-4283-9211-c5bab36dd767/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_e533f733-334d-4283-9211-c5bab36dd767.tar.gz\n",
            "rf_estimators: 256, rf_max_depth: 64, rf_max_features: 512, valid_roc_auc: 0.8075578592092575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:00:48,964 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:00:48,965 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:00:50,945 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_a0daf255-ca58-4b90-8611-9712ae96e294.csv\n",
            "2021-04-13 17:00:58,478 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/b3005ef8-9b8f-4f60-a6ea-59bca2963604/model_metadata.json\n",
            "2021-04-13 17:00:58,563 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/b3005ef8-9b8f-4f60-a6ea-59bca2963604/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_b3005ef8-9b8f-4f60-a6ea-59bca2963604.tar.gz\n",
            "rf_estimators: 256, rf_max_depth: 128, rf_max_features: 256, valid_roc_auc: 0.8235595467695276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:01:10,412 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:01:10,413 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:01:12,375 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_4a07ae22-ca51-4669-b519-fea740caf51e.csv\n",
            "2021-04-13 17:01:25,789 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/c6b8102a-2134-40ce-8f80-0502280dd14f/model_metadata.json\n",
            "2021-04-13 17:01:25,881 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/c6b8102a-2134-40ce-8f80-0502280dd14f/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_c6b8102a-2134-40ce-8f80-0502280dd14f.tar.gz\n",
            "rf_estimators: 256, rf_max_depth: 128, rf_max_features: 512, valid_roc_auc: 0.8068044840887175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:01:37,747 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:01:37,748 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:01:39,700 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_b8d180ad-f761-4375-b233-2478f5e5e743.csv\n",
            "2021-04-13 17:01:46,710 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/59626aa5-06a4-4615-8ffb-52abc2e8a94f/model_metadata.json\n",
            "2021-04-13 17:01:46,791 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/59626aa5-06a4-4615-8ffb-52abc2e8a94f/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_59626aa5-06a4-4615-8ffb-52abc2e8a94f.tar.gz\n",
            "rf_estimators: 256, rf_max_depth: 256, rf_max_features: 256, valid_roc_auc: 0.8235595467695276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:01:58,667 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:01:58,668 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:02:00,637 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_3f30f56a-5a66-4bde-bc68-c916c7ddc02e.csv\n",
            "2021-04-13 17:02:12,940 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/c5f62ae1-7df4-47df-93bc-c1dde5e8ce61/model_metadata.json\n",
            "2021-04-13 17:02:13,018 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/c5f62ae1-7df4-47df-93bc-c1dde5e8ce61/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_c5f62ae1-7df4-47df-93bc-c1dde5e8ce61.tar.gz\n",
            "rf_estimators: 256, rf_max_depth: 256, rf_max_features: 512, valid_roc_auc: 0.8068044840887175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:02:24,784 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:02:24,785 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:02:26,727 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_25242ca5-66a6-4d84-90f6-f125b848d761.csv\n",
            "2021-04-13 17:02:35,259 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/89370c4d-afd4-4244-ba0a-055756a4a345/model_metadata.json\n",
            "2021-04-13 17:02:35,344 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/89370c4d-afd4-4244-ba0a-055756a4a345/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_89370c4d-afd4-4244-ba0a-055756a4a345.tar.gz\n",
            "rf_estimators: 512, rf_max_depth: 16, rf_max_features: 256, valid_roc_auc: 0.8264826422372227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:02:47,123 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:02:47,124 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:02:49,088 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_e9b7539c-4db0-47ef-9500-9061809dd8f1.csv\n",
            "2021-04-13 17:03:03,078 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/88289178-7301-4ce5-b76c-6335ec66848d/model_metadata.json\n",
            "2021-04-13 17:03:03,157 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/88289178-7301-4ce5-b76c-6335ec66848d/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_88289178-7301-4ce5-b76c-6335ec66848d.tar.gz\n",
            "rf_estimators: 512, rf_max_depth: 16, rf_max_features: 512, valid_roc_auc: 0.8135848601735776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:03:15,008 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:03:15,010 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:03:16,974 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_58bbd29d-58f6-4cbf-bbd5-f43c0e936082.csv\n",
            "2021-04-13 17:03:27,077 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/809c3abb-aa15-41be-bb4e-490ff83f3e4b/model_metadata.json\n",
            "2021-04-13 17:03:27,189 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/809c3abb-aa15-41be-bb4e-490ff83f3e4b/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_809c3abb-aa15-41be-bb4e-490ff83f3e4b.tar.gz\n",
            "rf_estimators: 512, rf_max_depth: 24, rf_max_features: 256, valid_roc_auc: 0.8281702025072324\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:03:38,948 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:03:38,949 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:03:40,895 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_e7c2918b-ced0-4b65-9938-31c4a4439553.csv\n",
            "2021-04-13 17:03:57,981 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/2e5597f8-fa0e-4930-8485-c519a88c6fe6/model_metadata.json\n",
            "2021-04-13 17:03:58,078 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/2e5597f8-fa0e-4930-8485-c519a88c6fe6/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_2e5597f8-fa0e-4930-8485-c519a88c6fe6.tar.gz\n",
            "rf_estimators: 512, rf_max_depth: 24, rf_max_features: 512, valid_roc_auc: 0.8168394406943105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:04:09,851 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:04:09,852 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:04:11,787 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_1ef48473-ea68-479a-9be7-654a24c190c9.csv\n",
            "2021-04-13 17:04:22,812 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/1e5abb99-1344-4644-b378-0428c589a8ca/model_metadata.json\n",
            "2021-04-13 17:04:22,936 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/1e5abb99-1344-4644-b378-0428c589a8ca/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_1e5abb99-1344-4644-b378-0428c589a8ca.tar.gz\n",
            "rf_estimators: 512, rf_max_depth: 32, rf_max_features: 256, valid_roc_auc: 0.8270853423336548\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:04:34,883 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:04:34,884 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:04:36,843 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_4dbec76d-ddb4-424b-91e6-af4af62ddd4d.csv\n",
            "2021-04-13 17:04:55,271 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/ca98e30d-b4a0-4ee0-8bb5-8c93e4c12fd7/model_metadata.json\n",
            "2021-04-13 17:04:55,397 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/ca98e30d-b4a0-4ee0-8bb5-8c93e4c12fd7/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_ca98e30d-b4a0-4ee0-8bb5-8c93e4c12fd7.tar.gz\n",
            "rf_estimators: 512, rf_max_depth: 32, rf_max_features: 512, valid_roc_auc: 0.8144889103182257\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:05:07,236 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:05:07,237 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:05:09,162 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_4788c7f0-76a7-47d5-a367-1f9466281cfa.csv\n",
            "2021-04-13 17:05:21,729 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/1d6d8251-c749-49d1-a5c9-9d7174bdcb17/model_metadata.json\n",
            "2021-04-13 17:05:21,887 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/1d6d8251-c749-49d1-a5c9-9d7174bdcb17/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_1d6d8251-c749-49d1-a5c9-9d7174bdcb17.tar.gz\n",
            "rf_estimators: 512, rf_max_depth: 64, rf_max_features: 256, valid_roc_auc: 0.823830761812922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:05:33,876 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:05:33,878 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:05:35,833 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_5503c68e-0da4-429d-a1e5-2761ca4b814d.csv\n",
            "2021-04-13 17:05:58,102 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/125cc5d8-3c80-4bbb-a1bb-7ba017ba107b/model_metadata.json\n",
            "2021-04-13 17:05:58,245 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/125cc5d8-3c80-4bbb-a1bb-7ba017ba107b/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_125cc5d8-3c80-4bbb-a1bb-7ba017ba107b.tar.gz\n",
            "rf_estimators: 512, rf_max_depth: 64, rf_max_features: 512, valid_roc_auc: 0.8100891996142718\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:06:10,115 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:06:10,116 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:06:12,060 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_4b33fb45-57ed-4ffe-8ac0-366f4977e8c9.csv\n",
            "2021-04-13 17:06:24,488 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/eedc6f71-6441-41e3-8805-c84b1a8a36f0/model_metadata.json\n",
            "2021-04-13 17:06:24,644 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/eedc6f71-6441-41e3-8805-c84b1a8a36f0/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_eedc6f71-6441-41e3-8805-c84b1a8a36f0.tar.gz\n",
            "rf_estimators: 512, rf_max_depth: 128, rf_max_features: 256, valid_roc_auc: 0.8241622468659595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:06:36,522 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:06:36,523 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:06:38,510 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_73c5234b-9825-4517-80b0-86ac43b108de.csv\n",
            "2021-04-13 17:07:00,889 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/e9fe9e5b-5eb1-4b3c-a6e3-33b4607714f8/model_metadata.json\n",
            "2021-04-13 17:07:01,029 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/e9fe9e5b-5eb1-4b3c-a6e3-33b4607714f8/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_e9fe9e5b-5eb1-4b3c-a6e3-33b4607714f8.tar.gz\n",
            "rf_estimators: 512, rf_max_depth: 128, rf_max_features: 512, valid_roc_auc: 0.8100289296046287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:07:12,895 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:07:12,896 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:07:14,801 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_20d34719-df96-4297-bfbb-6ad6198abec7.csv\n",
            "2021-04-13 17:07:27,103 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/166ce8ef-3a5e-426a-9f88-b37eb53b1098/model_metadata.json\n",
            "2021-04-13 17:07:27,257 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/166ce8ef-3a5e-426a-9f88-b37eb53b1098/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_166ce8ef-3a5e-426a-9f88-b37eb53b1098.tar.gz\n",
            "rf_estimators: 512, rf_max_depth: 256, rf_max_features: 256, valid_roc_auc: 0.8241622468659595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:07:39,199 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:07:39,201 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:07:41,120 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_2fe574e3-6008-48e5-b872-ddd05f7250f0.csv\n",
            "2021-04-13 17:08:03,190 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/56406b93-78eb-4d98-a76a-85af6769aa1b/model_metadata.json\n",
            "2021-04-13 17:08:03,332 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_classification/56406b93-78eb-4d98-a76a-85af6769aa1b/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_56406b93-78eb-4d98-a76a-85af6769aa1b.tar.gz\n",
            "rf_estimators: 512, rf_max_depth: 256, rf_max_features: 512, valid_roc_auc: 0.8100289296046287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp86dseMwT8D",
        "outputId": "98519144-05ed-47fb-db02-5177ff8c5856"
      },
      "source": [
        "pred_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy_score': 0.8173076923076923,\n",
              " 'confusion_matrix': [[[33, 35], [22, 222]]],\n",
              " 'cross_entropy': 0.43499775247781014,\n",
              " 'kappa': 0.4243915069911962,\n",
              " 'matthews_cc': 0.4280964919045971,\n",
              " 'model_choice_score': 0.8100289296046287,\n",
              " 'npv': 0.6,\n",
              " 'num_compounds': 312,\n",
              " 'prc_auc_score': 0.9345298338450231,\n",
              " 'precision': 0.8638132295719845,\n",
              " 'recall_score': 0.9098360655737705,\n",
              " 'roc_auc_score': 0.8100289296046287}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DxKCK8FKYsr"
      },
      "source": [
        "###### RF (Regression) Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MCAlIYXKnIm"
      },
      "source": [
        "params={'data_owner': 'username',\n",
        " 'dataset_key': '/content/drive/MyDrive/Columbia_E4511/merge.csv',\n",
        " 'datastore': 'False',\n",
        " 'featurizer': 'ecfp',\n",
        "#  'descriptor_type':'mordred_filtered',\n",
        " 'id_col': 'compound_id',\n",
        " 'lc_account': 'None',\n",
        " 'max_epochs': '70',\n",
        " 'model_type': 'RF',\n",
        " 'prediction_type': 'regression',\n",
        " 'previously_split': 'True',\n",
        " 'rerun': 'False',\n",
        " 'response_cols': 'active',\n",
        " 'result_dir': '/content/drive/MyDrive/Columbia_E4511/models',\n",
        " 'save_results': 'False',\n",
        " 'smiles_col': 'base_rdkit_smiles',\n",
        " 'split_uuid': 'ead9410d-7abc-41cc-8713-f78dac0106a8',\n",
        " 'system': 'LC',\n",
        " 'transformers': 'True',\n",
        " 'uncertainty': 'True',\n",
        " 'verbose': 'True'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlRAz1zIQWuy",
        "outputId": "0d52fe99-e1ce-481d-fa1e-aae6b12ef169"
      },
      "source": [
        "ampl_param = parse.wrapper(params)\n",
        "pl = mp.ModelPipeline(ampl_param)\n",
        "pl.train_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:25:38,442 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:25:38,444 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:25:40,310 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_2f6b61b6-0191-4ce5-beb7-e80783195c7a.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.113 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:25:44,310 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/8970b20b-9b37-443c-950f-5713d26a5dab/model_metadata.json\n",
            "2021-04-13 17:25:44,572 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/8970b20b-9b37-443c-950f-5713d26a5dab/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_8970b20b-9b37-443c-950f-5713d26a5dab.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU48FAsrQbvF",
        "outputId": "fb68db3b-bde8-47df-fb38-69363a6c0423"
      },
      "source": [
        "pred_data = pl.model_wrapper.get_perf_data(subset=\"valid\", epoch_label=\"best\")\n",
        "pred_results = pred_data.get_prediction_results()\n",
        "print(f\"R2 score of validation set: {pred_results['r2_score']:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 score of validation set: 0.299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfy6tq4UKpy9",
        "outputId": "8f3115e4-c1c3-4fff-c198-73533a0b1cd0"
      },
      "source": [
        "param_choice = [16,32,64,128]\n",
        "\n",
        "rfe_list = []\n",
        "rfd_list = []\n",
        "rff_list = []\n",
        "valid_r2_list = []\n",
        "for rf_estimator in param_choice:\n",
        "    for rf_depth in param_choice:\n",
        "        for rf_feature in param_choice:\n",
        "            params[\"rf_estimators\"] = rf_estimator\n",
        "            params[\"rf_max_depth\"] = rf_depth\n",
        "            params[\"rf_max_features\"] = rf_feature\n",
        "            rfe_list.append(rf_estimator)\n",
        "            rfd_list.append(rf_depth)\n",
        "            rff_list.append(rf_feature)\n",
        "            tp = parse.wrapper(params)\n",
        "            pl = mp.ModelPipeline(tp)\n",
        "            pl.train_model()\n",
        "            pred_data = pl.model_wrapper.get_perf_data(subset=\"valid\", epoch_label=\"best\")\n",
        "            pred_results = pred_data.get_prediction_results()\n",
        "            valid_r2 = pred_results['r2_score']\n",
        "            valid_r2_list.append(valid_r2)\n",
        "            print(f\"rf_estimators: {rf_estimator}, rf_max_depth: {rf_depth}, rf_max_features: {rf_feature}, valid_r2: {valid_r2}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:26:31,811 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:26:31,813 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:26:33,645 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_a1ab0925-3022-43f2-87c0-09c92795a21e.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.124 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.020 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.020 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:26:34,940 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/ea1dc053-f6ef-4943-806b-84ca399731d4/model_metadata.json\n",
            "2021-04-13 17:26:34,958 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/ea1dc053-f6ef-4943-806b-84ca399731d4/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_ea1dc053-f6ef-4943-806b-84ca399731d4.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 16, rf_max_features: 16, valid_r2: 0.23793333666593686\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:26:47,180 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:26:47,182 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:26:49,131 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_d5711f7c-7ace-42ea-b2e4-80c7ba70a79c.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.128 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.020 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.020 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:26:50,507 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/4d9505c5-6307-4d30-8131-759b2e567fa3/model_metadata.json\n",
            "2021-04-13 17:26:50,524 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/4d9505c5-6307-4d30-8131-759b2e567fa3/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_4d9505c5-6307-4d30-8131-759b2e567fa3.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 16, rf_max_features: 32, valid_r2: 0.20482604393920167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:27:02,660 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:27:02,662 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:27:04,547 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_e197487a-c7d8-4bc4-9a85-84b58a85e8c5.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.116 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:27:05,832 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/11066c39-0f4f-4071-8b01-9782d4472306/model_metadata.json\n",
            "2021-04-13 17:27:05,849 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/11066c39-0f4f-4071-8b01-9782d4472306/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_11066c39-0f4f-4071-8b01-9782d4472306.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 16, rf_max_features: 64, valid_r2: 0.2529888235228388\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:27:18,065 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:27:18,066 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:27:19,957 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_9365330a-e94e-4729-a965-70a5f4c846fc.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.121 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:27:21,347 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/77b32c1f-5a1e-427c-bf05-4d57b61f2567/model_metadata.json\n",
            "2021-04-13 17:27:21,364 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/77b32c1f-5a1e-427c-bf05-4d57b61f2567/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_77b32c1f-5a1e-427c-bf05-4d57b61f2567.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 16, rf_max_features: 128, valid_r2: 0.23634591239045333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:27:33,333 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:27:33,334 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:27:35,201 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_fb62c78f-59b2-4e03-8f66-fe7ef0f22dd5.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.115 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:27:36,473 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/8950acc0-1bf2-4b8c-813b-a64dd5f8de02/model_metadata.json\n",
            "2021-04-13 17:27:36,494 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/8950acc0-1bf2-4b8c-813b-a64dd5f8de02/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_8950acc0-1bf2-4b8c-813b-a64dd5f8de02.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 32, rf_max_features: 16, valid_r2: 0.25379636088510993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:27:48,408 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:27:48,409 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:27:50,265 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_11a50bca-9cc8-4714-816b-3a6b82d5e056.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.116 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:27:51,568 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/e8e757c6-3055-460c-8ab8-0fc2ee20fc1d/model_metadata.json\n",
            "2021-04-13 17:27:51,588 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/e8e757c6-3055-460c-8ab8-0fc2ee20fc1d/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_e8e757c6-3055-460c-8ab8-0fc2ee20fc1d.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 32, rf_max_features: 32, valid_r2: 0.25953002061454356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:28:03,483 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:28:03,484 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:28:05,301 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_628a0497-acf3-4e67-add3-c0231d383255.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.111 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:28:06,665 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/b4844656-fc89-4f02-8900-1041f7b3543d/model_metadata.json\n",
            "2021-04-13 17:28:06,683 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/b4844656-fc89-4f02-8900-1041f7b3543d/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_b4844656-fc89-4f02-8900-1041f7b3543d.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 32, rf_max_features: 64, valid_r2: 0.22429128318663794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:28:18,525 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:28:18,526 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:28:20,362 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_2e877e70-a45f-47ae-8f2f-be8c1fe86dee.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.112 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:28:21,737 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/153ca15c-f810-4acf-a19a-de0a32c4d286/model_metadata.json\n",
            "2021-04-13 17:28:21,754 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/153ca15c-f810-4acf-a19a-de0a32c4d286/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_153ca15c-f810-4acf-a19a-de0a32c4d286.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 32, rf_max_features: 128, valid_r2: 0.2501756738178478\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:28:33,588 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:28:33,589 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:28:35,449 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_319ebecc-435d-4801-a06b-7fc2b8b2f7fb.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.113 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:28:36,718 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/2d5cef80-f5dd-4e3a-869b-a4fd928a3548/model_metadata.json\n",
            "2021-04-13 17:28:36,741 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/2d5cef80-f5dd-4e3a-869b-a4fd928a3548/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_2d5cef80-f5dd-4e3a-869b-a4fd928a3548.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 64, rf_max_features: 16, valid_r2: 0.26175985045838435\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:28:48,571 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:28:48,573 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:28:50,386 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_1e8bb0f0-5d27-44f6-b954-c8b8b1d48bce.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.112 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:28:51,643 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/6b8fa997-c333-4450-8a98-5223b5dc235d/model_metadata.json\n",
            "2021-04-13 17:28:51,694 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/6b8fa997-c333-4450-8a98-5223b5dc235d/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_6b8fa997-c333-4450-8a98-5223b5dc235d.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 64, rf_max_features: 32, valid_r2: 0.23080555694998295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:29:03,612 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:29:03,613 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:29:05,445 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_a54fbbfc-3299-4681-aaa6-0c9acc1c9525.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.113 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:29:06,819 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/c9d53798-db52-4f0e-9f69-872f27f8988c/model_metadata.json\n",
            "2021-04-13 17:29:06,839 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/c9d53798-db52-4f0e-9f69-872f27f8988c/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_c9d53798-db52-4f0e-9f69-872f27f8988c.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 64, rf_max_features: 64, valid_r2: 0.2320812046882662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:29:18,733 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:29:18,734 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:29:20,551 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_e0242f11-cfdc-420a-bb70-31525fa9262c.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.113 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.020 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:29:21,911 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/b4e3690d-497a-4325-a5e2-0dc8c12cf1b0/model_metadata.json\n",
            "2021-04-13 17:29:21,930 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/b4e3690d-497a-4325-a5e2-0dc8c12cf1b0/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_b4e3690d-497a-4325-a5e2-0dc8c12cf1b0.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 64, rf_max_features: 128, valid_r2: 0.24700787457497098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:29:33,781 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:29:33,783 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:29:35,638 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_f140122d-9b8d-4c1c-8449-f00c192ee837.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.113 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:29:36,904 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/e054026b-24be-4067-8ee9-2a98b340d526/model_metadata.json\n",
            "2021-04-13 17:29:36,929 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/e054026b-24be-4067-8ee9-2a98b340d526/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_e054026b-24be-4067-8ee9-2a98b340d526.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 128, rf_max_features: 16, valid_r2: 0.3034485217707088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:29:48,773 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:29:48,774 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:29:50,590 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_6c15fe9d-79ac-442d-a4d8-1f6d9a8448b9.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.112 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.020 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:29:51,853 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/7e71ad4a-2ee0-4af4-927e-4b45e8f42ac2/model_metadata.json\n",
            "2021-04-13 17:29:51,876 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/7e71ad4a-2ee0-4af4-927e-4b45e8f42ac2/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_7e71ad4a-2ee0-4af4-927e-4b45e8f42ac2.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 128, rf_max_features: 32, valid_r2: 0.23080555694998295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:30:03,782 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:30:03,783 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:30:05,604 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_68875209-16eb-450e-939f-622cff642879.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.112 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:30:06,971 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/7bd2402d-a8b7-4513-a7b2-59f759108013/model_metadata.json\n",
            "2021-04-13 17:30:06,992 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/7bd2402d-a8b7-4513-a7b2-59f759108013/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_7bd2402d-a8b7-4513-a7b2-59f759108013.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 128, rf_max_features: 64, valid_r2: 0.2320812046882662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:30:19,001 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:30:19,003 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:30:20,841 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_79255408-309a-4dbd-abee-8b3dccb5ce45.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.114 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:30:22,234 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/92a7e5b1-8431-459a-b5f8-05c2c696d35c/model_metadata.json\n",
            "2021-04-13 17:30:22,253 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/92a7e5b1-8431-459a-b5f8-05c2c696d35c/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_92a7e5b1-8431-459a-b5f8-05c2c696d35c.tar.gz\n",
            "rf_estimators: 16, rf_max_depth: 128, rf_max_features: 128, valid_r2: 0.24700787457497098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:30:34,233 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:30:34,234 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:30:36,068 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_407d8e14-a33c-445c-9dcf-2e302040bf27.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.114 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:30:37,365 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/795adbdf-fa85-499f-868c-5ab46bb383e9/model_metadata.json\n",
            "2021-04-13 17:30:37,394 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/795adbdf-fa85-499f-868c-5ab46bb383e9/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_795adbdf-fa85-499f-868c-5ab46bb383e9.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 16, rf_max_features: 16, valid_r2: 0.2509599064775555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:30:49,302 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:30:49,303 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:30:51,150 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_17dcfe68-5ab7-41b4-aaf9-6db8cb9f0c64.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.118 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:30:52,449 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/2aecff4b-a2d1-413d-813e-796738473b04/model_metadata.json\n",
            "2021-04-13 17:30:52,470 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/2aecff4b-a2d1-413d-813e-796738473b04/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_2aecff4b-a2d1-413d-813e-796738473b04.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 16, rf_max_features: 32, valid_r2: 0.24460610601800137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:31:04,260 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:31:04,261 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:31:06,109 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_397919c3-5e19-465d-baf4-11ce7c5d95b3.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.113 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:31:07,493 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/988cd1a1-bd3b-435e-a20d-ead3bcaa39be/model_metadata.json\n",
            "2021-04-13 17:31:07,513 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/988cd1a1-bd3b-435e-a20d-ead3bcaa39be/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_988cd1a1-bd3b-435e-a20d-ead3bcaa39be.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 16, rf_max_features: 64, valid_r2: 0.26965389292159025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:31:19,547 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:31:19,548 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:31:21,415 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_e0ddd9f3-5aff-4eaf-acb1-a62d2882be59.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.116 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:31:22,921 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/5f4d9b23-1b0b-470b-806d-0cea512264ca/model_metadata.json\n",
            "2021-04-13 17:31:22,943 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/5f4d9b23-1b0b-470b-806d-0cea512264ca/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_5f4d9b23-1b0b-470b-806d-0cea512264ca.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 16, rf_max_features: 128, valid_r2: 0.2567262269806585\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:31:34,962 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:31:34,963 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:31:36,789 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_c27bfe20-7b8c-447f-8a06-48e39e5d7be3.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.116 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:31:38,212 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/23865794-329a-4f64-8580-6d3fa16e8a5e/model_metadata.json\n",
            "2021-04-13 17:31:38,242 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/23865794-329a-4f64-8580-6d3fa16e8a5e/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_23865794-329a-4f64-8580-6d3fa16e8a5e.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 32, rf_max_features: 16, valid_r2: 0.27237896310739185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:31:50,142 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:31:50,143 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:31:52,111 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_fe59cd09-e493-4ffd-a47a-7b85f67c9125.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.116 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:31:53,496 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/6d3bae0f-b16e-4260-8b61-56cead7a497a/model_metadata.json\n",
            "2021-04-13 17:31:53,522 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/6d3bae0f-b16e-4260-8b61-56cead7a497a/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_6d3bae0f-b16e-4260-8b61-56cead7a497a.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 32, rf_max_features: 32, valid_r2: 0.2856984909762136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:32:05,361 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:32:05,362 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:32:07,193 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_4e6defdb-bef1-4e73-828b-348c0c9a6c7c.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.113 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:32:08,603 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/135f0328-3a4c-4595-ab5c-1e25010150a7/model_metadata.json\n",
            "2021-04-13 17:32:08,630 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/135f0328-3a4c-4595-ab5c-1e25010150a7/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_135f0328-3a4c-4595-ab5c-1e25010150a7.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 32, rf_max_features: 64, valid_r2: 0.2559974110316733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:32:20,449 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:32:20,450 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:32:22,266 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_36e958a3-2809-499c-8e77-dc144b24fe1a.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.113 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:32:23,841 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/0d2132a5-779e-4666-aa37-1983f33aeda0/model_metadata.json\n",
            "2021-04-13 17:32:23,864 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/0d2132a5-779e-4666-aa37-1983f33aeda0/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_0d2132a5-779e-4666-aa37-1983f33aeda0.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 32, rf_max_features: 128, valid_r2: 0.25403319005635605\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:32:35,739 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:32:35,740 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:32:37,581 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_116fe8c5-0bab-4a1e-83e3-313f905e2d85.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.117 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.020 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:32:38,990 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/41a00017-a696-4fd7-91bf-dfde573dc760/model_metadata.json\n",
            "2021-04-13 17:32:39,045 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/41a00017-a696-4fd7-91bf-dfde573dc760/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_41a00017-a696-4fd7-91bf-dfde573dc760.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 64, rf_max_features: 16, valid_r2: 0.25486207626954327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:32:50,822 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:32:50,823 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:32:52,659 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_370535b6-c14a-4b66-bca8-47f83fe31d6b.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.113 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:32:54,050 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/55d05deb-5b40-45ca-a5a6-740dc9ef7edf/model_metadata.json\n",
            "2021-04-13 17:32:54,079 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/55d05deb-5b40-45ca-a5a6-740dc9ef7edf/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_55d05deb-5b40-45ca-a5a6-740dc9ef7edf.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 64, rf_max_features: 32, valid_r2: 0.24632888285148846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:33:06,065 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:33:06,067 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:33:07,917 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_4923ee3e-317b-4ee9-b76e-2bedcb66e2f8.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.114 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:33:09,312 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/31a90a0e-75e1-4c2f-8493-9834d0cdfc40/model_metadata.json\n",
            "2021-04-13 17:33:09,339 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/31a90a0e-75e1-4c2f-8493-9834d0cdfc40/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_31a90a0e-75e1-4c2f-8493-9834d0cdfc40.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 64, rf_max_features: 64, valid_r2: 0.27036692995709755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:33:21,283 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:33:21,284 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:33:23,105 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_1bcd5676-d992-4e58-b0e4-725002b2784b.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.111 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:33:24,672 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/d1f2e7f6-5c10-4ffe-98e9-754171d05b5d/model_metadata.json\n",
            "2021-04-13 17:33:24,697 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/d1f2e7f6-5c10-4ffe-98e9-754171d05b5d/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_d1f2e7f6-5c10-4ffe-98e9-754171d05b5d.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 64, rf_max_features: 128, valid_r2: 0.2292897405964659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:33:36,532 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:33:36,534 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:33:38,409 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_0b7a75ed-a491-48f6-9e5d-929cf4988b33.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.110 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:33:39,784 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/46de28e9-5ad1-4a31-9e77-589f8d716c56/model_metadata.json\n",
            "2021-04-13 17:33:39,815 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/46de28e9-5ad1-4a31-9e77-589f8d716c56/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_46de28e9-5ad1-4a31-9e77-589f8d716c56.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 128, rf_max_features: 16, valid_r2: 0.29033969533838444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:33:51,631 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:33:51,632 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:33:53,457 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_1e5a1514-7391-4d87-ae8a-840803bcc2f7.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.111 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:33:54,846 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/d593a11a-2841-4fda-9a9b-1b60a85ad706/model_metadata.json\n",
            "2021-04-13 17:33:54,876 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/d593a11a-2841-4fda-9a9b-1b60a85ad706/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_d593a11a-2841-4fda-9a9b-1b60a85ad706.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 128, rf_max_features: 32, valid_r2: 0.2501276645071452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:34:06,716 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:34:06,717 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:34:08,552 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_215367ca-93ae-4f06-921d-232ac8f8f250.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.113 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:34:10,045 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/7085e6ac-d707-4085-96d9-9af685a21961/model_metadata.json\n",
            "2021-04-13 17:34:10,071 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/7085e6ac-d707-4085-96d9-9af685a21961/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_7085e6ac-d707-4085-96d9-9af685a21961.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 128, rf_max_features: 64, valid_r2: 0.27036692995709755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:34:21,954 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:34:21,955 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:34:23,810 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_79a4191e-fbfc-4512-9e8d-454885e04c8b.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.120 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:34:25,417 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/bce4d9f3-967d-440b-bec3-2b3ec42226ce/model_metadata.json\n",
            "2021-04-13 17:34:25,441 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/bce4d9f3-967d-440b-bec3-2b3ec42226ce/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_bce4d9f3-967d-440b-bec3-2b3ec42226ce.tar.gz\n",
            "rf_estimators: 32, rf_max_depth: 128, rf_max_features: 128, valid_r2: 0.2292897405964659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:34:37,337 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:34:37,338 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:34:39,209 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_91e3eebb-81b2-48d9-94fb-e70e7fa42a23.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.112 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.016 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:34:40,603 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/8be5d111-52a6-4efe-bd1c-ba8924a478eb/model_metadata.json\n",
            "2021-04-13 17:34:40,634 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/8be5d111-52a6-4efe-bd1c-ba8924a478eb/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_8be5d111-52a6-4efe-bd1c-ba8924a478eb.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 16, rf_max_features: 16, valid_r2: 0.2440182914992265\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:34:52,472 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:34:52,473 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:34:54,282 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_2dd4a1fd-6c53-4a06-842f-6aca3c8ce329.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.111 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.016 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:34:55,680 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/181982a6-b37f-4d01-9131-420145ed5fdb/model_metadata.json\n",
            "2021-04-13 17:34:55,708 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/181982a6-b37f-4d01-9131-420145ed5fdb/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_181982a6-b37f-4d01-9131-420145ed5fdb.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 16, rf_max_features: 32, valid_r2: 0.25582951391202724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:35:07,577 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:35:07,578 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:35:09,412 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_4ce05104-172f-4764-9171-7560461e930b.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.118 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:35:10,926 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/7d872d5c-adfc-4c3f-b3cd-eb7638b69364/model_metadata.json\n",
            "2021-04-13 17:35:10,952 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/7d872d5c-adfc-4c3f-b3cd-eb7638b69364/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_7d872d5c-adfc-4c3f-b3cd-eb7638b69364.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 16, rf_max_features: 64, valid_r2: 0.2875619678697432\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:35:22,717 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:35:22,719 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:35:24,529 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_0e8863a0-ec48-4c6b-b150-bc3e38a9977e.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.112 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:35:26,218 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/0cc4126e-7f79-46fe-8f5c-7ba3547dadad/model_metadata.json\n",
            "2021-04-13 17:35:26,274 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/0cc4126e-7f79-46fe-8f5c-7ba3547dadad/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_0cc4126e-7f79-46fe-8f5c-7ba3547dadad.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 16, rf_max_features: 128, valid_r2: 0.2660890439397784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:35:38,065 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:35:38,066 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:35:39,917 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ea1bb69a-5bb0-4df5-8d60-400d5a6d440f.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.114 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:35:41,331 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/be0251ab-6735-4154-a2fc-a61f61905c58/model_metadata.json\n",
            "2021-04-13 17:35:41,373 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/be0251ab-6735-4154-a2fc-a61f61905c58/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_be0251ab-6735-4154-a2fc-a61f61905c58.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 32, rf_max_features: 16, valid_r2: 0.27584970579931556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:35:53,281 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:35:53,283 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:35:55,114 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_dbbaab82-cb8f-4258-9fd6-a8e5c104c8d4.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.113 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:35:56,627 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/53ea6cdf-7082-4dca-8e30-affad271b10c/model_metadata.json\n",
            "2021-04-13 17:35:56,687 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/53ea6cdf-7082-4dca-8e30-affad271b10c/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_53ea6cdf-7082-4dca-8e30-affad271b10c.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 32, rf_max_features: 32, valid_r2: 0.28909986986768443\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:36:08,525 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:36:08,527 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:36:10,347 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_fd6c109f-fb98-460e-b5e7-e522f28cf049.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.111 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:36:11,954 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/4f782e16-f994-4895-85da-f70287c6b700/model_metadata.json\n",
            "2021-04-13 17:36:11,988 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/4f782e16-f994-4895-85da-f70287c6b700/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_4f782e16-f994-4895-85da-f70287c6b700.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 32, rf_max_features: 64, valid_r2: 0.2920889720933212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:36:23,828 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:36:23,829 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:36:25,626 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_5a7809d1-4191-49ff-a57b-7d7ba8e1631a.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.109 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.016 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:36:27,411 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/38753b45-4fad-4cf4-959e-5e8cee2cc6ac/model_metadata.json\n",
            "2021-04-13 17:36:27,442 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/38753b45-4fad-4cf4-959e-5e8cee2cc6ac/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_38753b45-4fad-4cf4-959e-5e8cee2cc6ac.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 32, rf_max_features: 128, valid_r2: 0.275773933251642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:36:39,449 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:36:39,451 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:36:41,252 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_40aeca8a-85af-4643-9d1a-62d9a4c0f6c3.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.118 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:36:42,669 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/22ce6d2f-ec16-4ce0-96b9-80a677a04b1f/model_metadata.json\n",
            "2021-04-13 17:36:42,719 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/22ce6d2f-ec16-4ce0-96b9-80a677a04b1f/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_22ce6d2f-ec16-4ce0-96b9-80a677a04b1f.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 64, rf_max_features: 16, valid_r2: 0.26220802237132523\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:36:54,594 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:36:54,595 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:36:56,396 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_a7b23e44-1e89-4c18-abbf-85ba4336b2c0.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.109 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:36:57,897 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/d4bd1e02-134d-43a5-a73a-4af99ac3ce1c/model_metadata.json\n",
            "2021-04-13 17:36:57,941 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/d4bd1e02-134d-43a5-a73a-4af99ac3ce1c/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_d4bd1e02-134d-43a5-a73a-4af99ac3ce1c.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 64, rf_max_features: 32, valid_r2: 0.2819188818290168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:37:09,767 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:37:09,768 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:37:11,602 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_3b215d9a-c9d8-4c2a-9540-126b4cf927c3.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.110 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:37:13,212 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/a06d36c7-0f41-4ad0-ab09-fde982422066/model_metadata.json\n",
            "2021-04-13 17:37:13,257 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/a06d36c7-0f41-4ad0-ab09-fde982422066/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_a06d36c7-0f41-4ad0-ab09-fde982422066.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 64, rf_max_features: 64, valid_r2: 0.2825811514605414\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:37:25,156 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:37:25,157 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:37:26,950 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_6f0013dd-575a-4c91-828d-594e1df1b0ba.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.110 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:37:28,837 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/60b58f8d-72bb-431e-89ea-b1c280652e9f/model_metadata.json\n",
            "2021-04-13 17:37:28,870 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/60b58f8d-72bb-431e-89ea-b1c280652e9f/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_60b58f8d-72bb-431e-89ea-b1c280652e9f.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 64, rf_max_features: 128, valid_r2: 0.23782318811964243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:37:40,765 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:37:40,767 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:37:42,567 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ea379c11-9c16-4a36-9f4b-a5d9d3b4bd3a.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.111 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:37:43,980 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/7f6e2ae7-03b1-480c-b429-c6ad7ee68965/model_metadata.json\n",
            "2021-04-13 17:37:44,029 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/7f6e2ae7-03b1-480c-b429-c6ad7ee68965/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_7f6e2ae7-03b1-480c-b429-c6ad7ee68965.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 128, rf_max_features: 16, valid_r2: 0.28762704382094284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:37:55,828 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:37:55,829 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:37:57,631 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_dc894ed1-6104-47e1-83a0-328192f80ec7.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.110 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:37:59,130 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/1a1e7a31-65e9-4f82-a6b5-55aa13c6a656/model_metadata.json\n",
            "2021-04-13 17:37:59,179 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/1a1e7a31-65e9-4f82-a6b5-55aa13c6a656/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_1a1e7a31-65e9-4f82-a6b5-55aa13c6a656.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 128, rf_max_features: 32, valid_r2: 0.2839781957644899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:38:11,007 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:38:11,009 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:38:12,807 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_8f7fe0a1-cf15-4f33-8a8c-2e53ed704a5f.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.112 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:38:14,444 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/375d3ada-c0f4-4313-9ed8-c663eb1f3325/model_metadata.json\n",
            "2021-04-13 17:38:14,484 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/375d3ada-c0f4-4313-9ed8-c663eb1f3325/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_375d3ada-c0f4-4313-9ed8-c663eb1f3325.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 128, rf_max_features: 64, valid_r2: 0.2824500086444591\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:38:26,367 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:38:26,368 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:38:28,159 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_70d919ea-d76a-49b8-94a7-aaa43966252e.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.116 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:38:30,056 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/1a854221-6d5d-4912-81b5-5c6a8df1fbd0/model_metadata.json\n",
            "2021-04-13 17:38:30,091 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/1a854221-6d5d-4912-81b5-5c6a8df1fbd0/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_1a854221-6d5d-4912-81b5-5c6a8df1fbd0.tar.gz\n",
            "rf_estimators: 64, rf_max_depth: 128, rf_max_features: 128, valid_r2: 0.23782318811964243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:38:42,047 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:38:42,048 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:38:43,840 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_43099813-993b-473a-910a-a8f49f4a9ca7.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.108 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.016 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:38:45,400 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/9025c591-c963-42cc-8aad-ddb63f2f5c4a/model_metadata.json\n",
            "2021-04-13 17:38:45,441 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/9025c591-c963-42cc-8aad-ddb63f2f5c4a/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_9025c591-c963-42cc-8aad-ddb63f2f5c4a.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 16, rf_max_features: 16, valid_r2: 0.2475707492498942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:38:57,229 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:38:57,230 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:38:59,042 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_472aad50-3ded-4e71-8de6-49b9d4503ff6.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.113 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:39:00,697 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/5781f9c2-4f07-4b9a-9717-6ebabc934e7e/model_metadata.json\n",
            "2021-04-13 17:39:00,739 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/5781f9c2-4f07-4b9a-9717-6ebabc934e7e/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_5781f9c2-4f07-4b9a-9717-6ebabc934e7e.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 16, rf_max_features: 32, valid_r2: 0.26000245286958734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:39:12,541 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:39:12,542 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:39:14,331 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_d4566d4a-fc75-444f-b0b7-6172e6879c7e.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.108 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:39:16,173 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/483a3db9-c88a-4a29-9549-e0c8e37f78a7/model_metadata.json\n",
            "2021-04-13 17:39:16,227 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/483a3db9-c88a-4a29-9549-e0c8e37f78a7/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_483a3db9-c88a-4a29-9549-e0c8e37f78a7.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 16, rf_max_features: 64, valid_r2: 0.27863018830773956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:39:28,032 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:39:28,033 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:39:29,824 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_b5d637b8-d894-4583-9901-e23c88e37a30.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.111 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:39:31,957 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/88ac5719-88aa-49b4-9d88-db6a4aaa4208/model_metadata.json\n",
            "2021-04-13 17:39:31,993 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/88ac5719-88aa-49b4-9d88-db6a4aaa4208/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_88ac5719-88aa-49b4-9d88-db6a4aaa4208.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 16, rf_max_features: 128, valid_r2: 0.2696541813511366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:39:43,851 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:39:43,853 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:39:45,648 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_259ea57f-b33d-4802-9b47-49107d5ea53b.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.110 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.022 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:39:47,340 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/78370620-f875-45cb-beb0-bd68b485e145/model_metadata.json\n",
            "2021-04-13 17:39:47,409 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/78370620-f875-45cb-beb0-bd68b485e145/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_78370620-f875-45cb-beb0-bd68b485e145.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 32, rf_max_features: 16, valid_r2: 0.2911147127017688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:39:59,281 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:39:59,282 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:40:01,120 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_bea13cfe-6460-4720-95ac-11fafb2beddb.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.110 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:40:02,908 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/6a4d48ff-7bdc-42e1-be5a-67d4622ec23d/model_metadata.json\n",
            "2021-04-13 17:40:02,982 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/6a4d48ff-7bdc-42e1-be5a-67d4622ec23d/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_6a4d48ff-7bdc-42e1-be5a-67d4622ec23d.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 32, rf_max_features: 32, valid_r2: 0.29233727948783206\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:40:14,894 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:40:14,895 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:40:16,691 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_f123a7b4-7b49-4f0b-aa91-7cc9031cd4b7.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.109 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:40:18,659 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/834c997a-3608-4fd8-8d77-ef5f3c90e8a1/model_metadata.json\n",
            "2021-04-13 17:40:18,714 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/834c997a-3608-4fd8-8d77-ef5f3c90e8a1/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_834c997a-3608-4fd8-8d77-ef5f3c90e8a1.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 32, rf_max_features: 64, valid_r2: 0.300964862267615\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:40:30,450 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:40:30,451 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:40:32,242 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_9f087c6c-85bd-4428-b82a-9cdac4ad1c9c.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.109 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.016 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:40:34,695 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/4f502b85-441f-44e8-b50f-a621f32eee6c/model_metadata.json\n",
            "2021-04-13 17:40:34,746 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/4f502b85-441f-44e8-b50f-a621f32eee6c/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_4f502b85-441f-44e8-b50f-a621f32eee6c.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 32, rf_max_features: 128, valid_r2: 0.2722613684232762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:40:46,568 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:40:46,569 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:40:48,358 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_9681a810-23dc-4f9d-934b-0b4bd5c905a3.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.110 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:40:50,052 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/3f0fe4a2-79ee-494e-94e5-2455a8e4cad4/model_metadata.json\n",
            "2021-04-13 17:40:50,137 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/3f0fe4a2-79ee-494e-94e5-2455a8e4cad4/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_3f0fe4a2-79ee-494e-94e5-2455a8e4cad4.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 64, rf_max_features: 16, valid_r2: 0.2753480780515253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:41:01,956 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:41:01,957 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:41:03,780 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_96f2ae6f-8e88-4baf-a999-43054d6a3bfd.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.111 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:41:05,669 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/10942a62-80fe-48a3-9bdb-21e880264844/model_metadata.json\n",
            "2021-04-13 17:41:05,741 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/10942a62-80fe-48a3-9bdb-21e880264844/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_10942a62-80fe-48a3-9bdb-21e880264844.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 64, rf_max_features: 32, valid_r2: 0.2958537919096367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:41:17,636 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:41:17,637 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:41:19,455 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_2c5e03ee-c9f1-4cf0-8bd3-6089e1742875.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.110 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.019 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:41:21,541 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/5b5f47db-ba9e-49f2-8a7e-c1c5b4ebf818/model_metadata.json\n",
            "2021-04-13 17:41:21,605 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/5b5f47db-ba9e-49f2-8a7e-c1c5b4ebf818/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_5b5f47db-ba9e-49f2-8a7e-c1c5b4ebf818.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 64, rf_max_features: 64, valid_r2: 0.29545409989613647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:41:33,420 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:41:33,421 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:41:35,231 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_e2c612db-87f8-4ed2-844f-6d42cbe978cc.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.108 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:41:37,914 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/d615b803-b0ba-48f8-ab93-8d8fe8f3a794/model_metadata.json\n",
            "2021-04-13 17:41:37,972 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/d615b803-b0ba-48f8-ab93-8d8fe8f3a794/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_d615b803-b0ba-48f8-ab93-8d8fe8f3a794.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 64, rf_max_features: 128, valid_r2: 0.23573105584602905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:41:50,078 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:41:50,079 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:41:52,056 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_0e9436c4-adac-4f8c-9bde-a2a4bbed8274.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.109 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:41:53,748 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/798d1dc4-73a4-4e10-8c52-8643e0f6cd66/model_metadata.json\n",
            "2021-04-13 17:41:53,835 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/798d1dc4-73a4-4e10-8c52-8643e0f6cd66/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_798d1dc4-73a4-4e10-8c52-8643e0f6cd66.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 128, rf_max_features: 16, valid_r2: 0.27726670684485366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:42:05,611 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:42:05,612 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:42:07,403 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_d7aef2e9-24af-4788-8f21-5591c25b7245.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.110 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.016 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:42:09,292 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/a17d1c42-f4c5-429a-9e7a-697cacdb8edc/model_metadata.json\n",
            "2021-04-13 17:42:09,391 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/a17d1c42-f4c5-429a-9e7a-697cacdb8edc/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_a17d1c42-f4c5-429a-9e7a-697cacdb8edc.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 128, rf_max_features: 32, valid_r2: 0.2981579505755998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:42:21,220 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:42:21,222 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:42:23,022 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_aeb4951f-7bcf-442e-a1d0-d7b05bc76ea2.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.108 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:42:25,213 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/be6d182c-6ea5-49f7-ac5c-ec9d5e8bb46f/model_metadata.json\n",
            "2021-04-13 17:42:25,279 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/be6d182c-6ea5-49f7-ac5c-ec9d5e8bb46f/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_be6d182c-6ea5-49f7-ac5c-ec9d5e8bb46f.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 128, rf_max_features: 64, valid_r2: 0.2946671173401645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:42:37,192 Error when loading dataset split table:\n",
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_ead9410d-7abc-41cc-8713-f78dac0106a8.csv'\n",
            "2021-04-13 17:42:37,193 Splitting data by scaffold\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "number of features: 1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:42:39,030 Dataset split table saved to /content/drive/MyDrive/Columbia_E4511/merge_train_valid_test_scaffold_0329a524-80b2-41fa-bcd8-0da46dc00416.csv\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "n_cnt [3120.]\n",
            "y_means [0.78942308]\n",
            "y_stds [0.40771839]\n",
            "TIMING: dataset construction took 0.109 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.018 s\n",
            "Loading dataset from disk.\n",
            "TIMING: dataset construction took 0.017 s\n",
            "Loading dataset from disk.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-13 17:42:41,703 Wrote model metadata to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/93fd043b-9bf7-4260-bc3b-ad304d6dc292/model_metadata.json\n",
            "2021-04-13 17:42:41,794 Wrote model metrics to file /content/drive/MyDrive/Columbia_E4511/models/merge/RF_ecfp_scaffold_regression/93fd043b-9bf7-4260-bc3b-ad304d6dc292/model_metrics.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wrote model tarball to /content/drive/MyDrive/Columbia_E4511/models/merge_model_93fd043b-9bf7-4260-bc3b-ad304d6dc292.tar.gz\n",
            "rf_estimators: 128, rf_max_depth: 128, rf_max_features: 128, valid_r2: 0.23462936292006342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dabi7uMMAhs"
      },
      "source": [
        "pred_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quStVkT996lA"
      },
      "source": [
        "##### XGBoost models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7aRRhsAALxX"
      },
      "source": [
        "params={'data_owner': 'username',\n",
        " 'dataset_key': '/content/drive/MyDrive/Columbia_E4511/merge.csv',\n",
        " 'datastore': 'False',\n",
        " 'featurizer': 'computed_descriptors',\n",
        " 'descriptor_type':'mordred_filtered',\n",
        " 'id_col': 'compound_id',\n",
        " 'lc_account': 'None',\n",
        " 'max_epochs': '70',\n",
        " 'model_type': 'xgboost',\n",
        " 'prediction_type': 'regression',\n",
        " 'previously_split': 'True',\n",
        " 'rerun': 'False',\n",
        " 'response_cols': 'VALUE_NUM_mean',\n",
        " 'result_dir': '/content/drive/MyDrive/Columbia_E4511/models',\n",
        " 'save_results': 'False',\n",
        " 'smiles_col': 'base_rdkit_smiles',\n",
        " 'split_uuid': 'ead9410d-7abc-41cc-8713-f78dac0106a8',\n",
        " 'system': 'LC',\n",
        " 'transformers': 'True',\n",
        " 'uncertainty': 'True',\n",
        " 'verbose': 'False'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRJpm-FqALmh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7bc8665c-f98d-4415-fc88-fa957c6e88b9"
      },
      "source": [
        " # 96 models per feature set, ~40 seconds per model; ~1:04 hours\n",
        "gamma_choice = [0.0,0.05,0.1,0.2]\n",
        "lr_choice = [0.25,0.2,0.15,0.10,0.05]\n",
        "\n",
        "for gamma in gamma_choice:\n",
        "  for learning_rate in lr_choice:\n",
        "      params[\"xgb_gamma\"] = gamma\n",
        "      params[\"xgb_learning_rate\"] = learning_rate\n",
        "      tp = parse.wrapper(params)\n",
        "      pl = mp.ModelPipeline(tp)\n",
        "      pl.train_model()\n",
        "      pred_data = pl.model_wrapper.get_perf_data(subset=\"valid\", epoch_label=\"best\")\n",
        "      pred_results = pred_data.get_prediction_results()\n",
        "      print(f\"xgb gamma: {gamma}, xgb learning rate: {learning_rate}, valid_r2: {pred_results['r2_score']}\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-6:\n",
            "Process ForkPoolWorker-8:\n",
            "Traceback (most recent call last):\n",
            "Process ForkPoolWorker-9:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mordred/_base/parallel.py\u001b[0m in \u001b[0;36mparallel\u001b[0;34m(calc, mols, nproc, nmols, quiet, ipynb, id)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mMolPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnproc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mordred/_base/parallel.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mordred/_base/parallel.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, mol)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mordred/_base/parallel.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, mol, id)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mcxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_proxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mordred/_base/context.py\u001b[0m in \u001b[0;36mfrom_calculator\u001b[0;34m(cls, calc, mol, id)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mcalc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mordred/_base/context.py\u001b[0m in \u001b[0;36mfrom_query\u001b[0;34m(cls, mol, require_3D, explicit_hydrogens, kekulizes, id, config)\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIs3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                         \u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mke\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconformer_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mordred/_util.py\u001b[0m in \u001b[0;36mconformer_to_numpy\u001b[0;34m(conf)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconformer_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetAtomPosition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNumAtoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mordred/_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconformer_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetAtomPosition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNumAtoms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-234faa24f805>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m      \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m      \u001b[0mpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m      \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m      \u001b[0mpred_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_perf_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"best\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m      \u001b[0mpred_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prediction_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/atomsci/ddm/pipeline/model_pipeline.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, featurization)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_model_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_featurize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;31m## return if split only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/atomsci/ddm/pipeline/model_pipeline.py\u001b[0m in \u001b[0;36mload_featurize_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[1;32m    171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_featurized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreviously_split\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_presplit_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/atomsci/ddm/pipeline/model_datasets.py\u001b[0m in \u001b[0;36mget_featurized_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mdset_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_full_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_task_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"number of features: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/atomsci/ddm/pipeline/featurization.py\u001b[0m in \u001b[0;36mfeaturize_data\u001b[0;34m(self, dset_df, model_dataset)\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_smiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m             \u001b[0mcalc_smiles_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_smiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m             \u001b[0mcalc_desc_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_descriptors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_smiles_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m             \u001b[0mcalc_merged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_smiles_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdescr_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/atomsci/ddm/pipeline/featurization.py\u001b[0m in \u001b[0;36mcompute_descriptors\u001b[0;34m(self, smiles_df, params)\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmordred_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mordred package needs to be installed to use Mordred descriptors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m             \u001b[0mdesc_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mordred_descriptors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmiles_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m             \u001b[0mdesc_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdescr_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m             \u001b[0;31m# Add the ID and SMILES columns to the returned data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/atomsci/ddm/pipeline/featurization.py\u001b[0m in \u001b[0;36mcompute_mordred_descriptors\u001b[0;34m(self, smiles_strs, params)\u001b[0m\n\u001b[1;32m   1617\u001b[0m         \u001b[0mmols3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_3d_mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_strs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m         \u001b[0mquiet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m         \u001b[0mdesc_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_all_mordred_descrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmols3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmordred_cpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1620\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/atomsci/ddm/pipeline/featurization.py\u001b[0m in \u001b[0;36mcompute_all_mordred_descrs\u001b[0;34m(mols, max_cpus, quiet)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0mcalc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mordred_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_3D\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Computing Mordred descriptors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0mres_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_cpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done computing Mordred descriptors\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mordred/_base/calculator.py\u001b[0m in \u001b[0;36mpandas\u001b[0;34m(self, mols, nproc, nmols, quiet, ipynb, id)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         )\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_dataclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mordred/_base/calculator.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         return MordredDataFrame(\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mordred/_base/parallel.py\u001b[0m in \u001b[0;36mparallel\u001b[0;34m(calc, mols, nproc, nmols, quiet, ipynb, id)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/mordred/_base/parallel.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001b[1;32m    223\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_terminate_pool\u001b[0;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'helping task handler/workers to finish'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_help_stuff_finish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mresult_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_help_stuff_finish\u001b[0;34m(inqueue, task_handler, size)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0minqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mtask_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m             \u001b[0minqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/managers.py\u001b[0m in \u001b[0;36mRebuildProxy\u001b[0;34m(func, token, serializer, kwds)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_inheriting'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         )\n\u001b[0;32m--> 943\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, token, serializer, manager, authkey, exposed, incref, manager_owned)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mincref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_incref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_after_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseProxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_fork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/managers.py\u001b[0m in \u001b[0;36m_incref\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m         \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'incref'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'INCREF %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSocketClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mSocketClient\u001b[0;34m(address)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-7:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/parallel.py\", line 17, in worker\n",
            "    r = list(calculator._calculate(cxt))\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/parallel.py\", line 17, in worker\n",
            "    r = list(calculator._calculate(cxt))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/calculator.py\", line 273, in _calculate\n",
            "    _, r = self._calculate_one(cxt, desc, True)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/calculator.py\", line 247, in _calculate_one\n",
            "    r = desc.calculate(**args)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/parallel.py\", line 17, in worker\n",
            "    r = list(calculator._calculate(cxt))\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/calculator.py\", line 273, in _calculate\n",
            "    _, r = self._calculate_one(cxt, desc, True)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/parallel.py\", line 17, in worker\n",
            "    r = list(calculator._calculate(cxt))\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/ExtendedTopochemicalAtom.py\", line 421, in calculate\n",
            "    for i, row in enumerate(D)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/calculator.py\", line 239, in _calculate_one\n",
            "    ok, r = self._calculate_one(cxt, dep, False)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/calculator.py\", line 273, in _calculate\n",
            "    _, r = self._calculate_one(cxt, desc, True)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/ExtendedTopochemicalAtom.py\", line 421, in <genexpr>\n",
            "    for i, row in enumerate(D)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/calculator.py\", line 247, in _calculate_one\n",
            "    r = desc.calculate(**args)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/calculator.py\", line 273, in _calculate\n",
            "    _, r = self._calculate_one(cxt, desc, True)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/ExtendedTopochemicalAtom.py\", line 419, in <genexpr>\n",
            "    if i < j and checker(r)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/calculator.py\", line 239, in _calculate_one\n",
            "    ok, r = self._calculate_one(cxt, dep, False)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/calculator.py\", line 239, in _calculate_one\n",
            "    ok, r = self._calculate_one(cxt, dep, False)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/InformationContent.py\", line 126, in calculate\n",
            "    tree = BFSTree(self.mol)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/calculator.py\", line 247, in _calculate_one\n",
            "    r = desc.calculate(**args)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/_base/calculator.py\", line 247, in _calculate_one\n",
            "    r = desc.calculate(**args)\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/InformationContent.py\", line 36, in __init__\n",
            "    (a.GetAtomicNum(), a.GetDegree(), a.GetNeighbors()) for a in mol.GetAtoms()\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/PathCount.py\", line 74, in calculate\n",
            "    for i in self._bond_ids_to_atom_ids(path):\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/PathCount.py\", line 50, in _bond_ids_to_atom_ids\n",
            "    for i in it:\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/InformationContent.py\", line 36, in <listcomp>\n",
            "    (a.GetAtomicNum(), a.GetDegree(), a.GetNeighbors()) for a in mol.GetAtoms()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/PathCount.py\", line 74, in calculate\n",
            "    for i in self._bond_ids_to_atom_ids(path):\n",
            "  File \"/usr/local/lib/python3.7/site-packages/mordred/PathCount.py\", line 34, in _bond_ids_to_atom_ids\n",
            "    a0f, a0t = self._bonds[next(it)]\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1rIVfBKCPT5"
      },
      "source": [
        "### Edit some AMPL functions to include xgboost parameters\n",
        "Just run this code once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAiqmPOhCO9m"
      },
      "source": [
        "nan = np.float32('nan')\n",
        "def get_summary_perf_tables(collection_names=None, filter_dict={}, result_dir=None, prediction_type='regression', verbose=False):\n",
        "    \"\"\"\n",
        "    Load model parameters and performance metrics from model tracker for all models saved in the model tracker DB under\n",
        "    the given collection names (or result directory if Model tracker is not available) with the given prediction type. Tabulate the parameters and metrics including:\n",
        "        dataset (assay name, target, parameter, key, bucket)\n",
        "        dataset size (train/valid/test/total)\n",
        "        number of training folds\n",
        "        model type (NN or RF)\n",
        "        featurizer\n",
        "        transformation type\n",
        "        metrics: r2_score, mae_score and rms_score for regression, or ROC AUC for classification\n",
        "\n",
        "    result_dir: use result_dir when the model tracker is not available. Use a list format if you have multiple result direcotries.\n",
        "    \"\"\"\n",
        "    collection_list = []\n",
        "    model_uuid_list = []\n",
        "    time_built_list = []\n",
        "    model_type_list = []\n",
        "    dataset_key_list = []\n",
        "    bucket_list = []\n",
        "    param_list = []\n",
        "    featurizer_list = []\n",
        "    desc_type_list = []\n",
        "    transform_list = []\n",
        "    dset_size_list = []\n",
        "    splitter_list = []\n",
        "    split_strategy_list = []\n",
        "    split_uuid_list = []\n",
        "    rf_estimators_list = []\n",
        "    rf_max_features_list = []\n",
        "    rf_max_depth_list = []\n",
        "    best_epoch_list = []\n",
        "    max_epochs_list = []\n",
        "    learning_rate_list = []\n",
        "    layer_sizes_list = []\n",
        "    dropouts_list = []\n",
        "    xgb_gamma_list = []\n",
        "    xgb_learning_rate_list = []\n",
        "    umap_dim_list = []\n",
        "    umap_targ_wt_list = []\n",
        "    umap_neighbors_list = []\n",
        "    umap_min_dist_list = []\n",
        "    split_uuid_list=[]\n",
        "\n",
        "\n",
        "    if prediction_type == 'regression':\n",
        "        score_types = ['r2_score', 'mae_score', 'rms_score']\n",
        "    else:\n",
        "        # TODO: add more classification metrics later\n",
        "        score_types = ['roc_auc_score', 'prc_auc_score', 'accuracy_score', 'precision', 'recall_score', 'npv', 'matthews_cc']\n",
        "\n",
        "    subsets = ['train', 'valid', 'test']\n",
        "    score_dict = {}\n",
        "    ncmpd_dict = {}\n",
        "    for subset in subsets:\n",
        "        score_dict[subset] = {}\n",
        "        for score_type in score_types:\n",
        "            score_dict[subset][score_type] = []\n",
        "        ncmpd_dict[subset] = []\n",
        "\n",
        "    metadata_list_dict = {}\n",
        "    if result_dir:\n",
        "        if isinstance(result_dir, str):\n",
        "            result_dir = [result_dir]\n",
        "        for rd in result_dir:\n",
        "            if rd not in metadata_list_dict:\n",
        "                metadata_list_dict[rd] = []\n",
        "            for dirpath, dirnames, filenames in os.walk(rd):\n",
        "                if \"model_metadata.json\" in filenames:\n",
        "                    with open(os.path.join(dirpath, 'model_metadata.json')) as f:\n",
        "                        metadata_dict = json.load(f)\n",
        "                    metadata_list_dict[rd].append(metadata_dict)\n",
        "\n",
        "    for ss in metadata_list_dict:\n",
        "        for i, metadata_dict in enumerate(metadata_list_dict[ss]):\n",
        "            if (i % 10 == 0) and verbose:\n",
        "                print('Processing collection %s model %d' % (ss, i))\n",
        "            # Check that model has metrics before we go on\n",
        "            if not 'training_metrics' in metadata_dict:\n",
        "                continue\n",
        "            collection_list.append(ss)\n",
        "            model_uuid = metadata_dict['model_uuid']\n",
        "            model_uuid_list.append(model_uuid)\n",
        "            time_built = metadata_dict['time_built']\n",
        "            time_built_list.append(time_built)\n",
        "\n",
        "            model_params = metadata_dict['model_parameters']\n",
        "            model_type = model_params['model_type']\n",
        "            model_type_list.append(model_type)\n",
        "            featurizer = model_params['featurizer']\n",
        "            featurizer_list.append(featurizer)\n",
        "            if 'descriptor_specific' in metadata_dict:\n",
        "                desc_type = metadata_dict['descriptor_specific']['descriptor_type']\n",
        "            elif featurizer in ['graphconv', 'ecfp']:\n",
        "                desc_type = featurizer\n",
        "            else:\n",
        "                desc_type = ''\n",
        "            desc_type_list.append(desc_type)\n",
        "            dataset_key = metadata_dict['training_dataset']['dataset_key']\n",
        "            bucket = metadata_dict['training_dataset']['bucket']\n",
        "            dataset_key_list.append(dataset_key)\n",
        "            bucket_list.append(bucket)\n",
        "            dset_metadata = metadata_dict['training_dataset']['dataset_metadata']\n",
        "            param = metadata_dict['training_dataset']['response_cols'][0]\n",
        "            param_list.append(param)\n",
        "            transform_type = metadata_dict['training_dataset']['feature_transform_type']\n",
        "            transform_list.append(transform_type)\n",
        "            split_params = metadata_dict['splitting_parameters']\n",
        "            splitter_list.append(split_params['splitter'])\n",
        "            split_uuid_list.append(split_params.get('split_uuid', ''))\n",
        "            split_strategy = split_params['split_strategy']\n",
        "            split_strategy_list.append(split_strategy)\n",
        "\n",
        "            if 'umap_specific' in metadata_dict:\n",
        "                umap_params = metadata_dict['umap_specific']\n",
        "                umap_dim_list.append(umap_params['umap_dim'])\n",
        "                umap_targ_wt_list.append(umap_params['umap_targ_wt'])\n",
        "                umap_neighbors_list.append(umap_params['umap_neighbors'])\n",
        "                umap_min_dist_list.append(umap_params['umap_min_dist'])\n",
        "            else:\n",
        "                umap_dim_list.append(nan)\n",
        "                umap_targ_wt_list.append(nan)\n",
        "                umap_neighbors_list.append(nan)\n",
        "                umap_min_dist_list.append(nan)\n",
        "\n",
        "            if model_type == 'NN':\n",
        "                nn_params = metadata_dict['nn_specific']\n",
        "                max_epochs_list.append(nn_params['max_epochs'])\n",
        "                best_epoch_list.append(nn_params['best_epoch'])\n",
        "                learning_rate_list.append(nn_params['learning_rate'])\n",
        "                layer_sizes_list.append(','.join(['%d' % s for s in nn_params['layer_sizes']]))\n",
        "                dropouts_list.append(','.join(['%.2f' % d for d in nn_params['dropouts']]))\n",
        "                rf_estimators_list.append(nan)\n",
        "                rf_max_features_list.append(nan)\n",
        "                rf_max_depth_list.append(nan)\n",
        "                xgb_gamma_list.append(nan)\n",
        "                xgb_learning_rate_list.append(nan)\n",
        "            elif model_type == 'RF':\n",
        "                rf_params = metadata_dict['rf_specific']\n",
        "                rf_estimators_list.append(rf_params['rf_estimators'])\n",
        "                rf_max_features_list.append(rf_params['rf_max_features'])\n",
        "                rf_max_depth_list.append(rf_params['rf_max_depth'])\n",
        "                max_epochs_list.append(nan)\n",
        "                best_epoch_list.append(nan)\n",
        "                learning_rate_list.append(nan)\n",
        "                layer_sizes_list.append(nan)\n",
        "                dropouts_list.append(nan)\n",
        "                xgb_gamma_list.append(nan)\n",
        "                xgb_learning_rate_list.append(nan)\n",
        "            elif model_type == 'xgboost':\n",
        "                # TODO: Add xgboost parameters\n",
        "                xg_params = metadata_dict['xgb_specific']\n",
        "                xgb_gamma_list.append(xg_params['xgb_gamma'])\n",
        "                xgb_learning_rate_list.append(xg_params['xgb_learning_rate'])\n",
        "                max_epochs_list.append(nan)\n",
        "                best_epoch_list.append(nan)\n",
        "                learning_rate_list.append(nan)\n",
        "                layer_sizes_list.append(nan)\n",
        "                dropouts_list.append(nan)\n",
        "                rf_estimators_list.append(nan)\n",
        "                rf_max_features_list.append(nan)\n",
        "                rf_max_depth_list.append(nan)\n",
        "            else:\n",
        "                raise Exception('Unexpected model type %s' % model_type)\n",
        "\n",
        "            # Get model metrics for this model\n",
        "            metrics_dicts = metadata_dict['training_metrics']\n",
        "            #print(\"Got %d metrics dicts for model %s\" % (len(metrics_dicts), model_uuid))\n",
        "            subset_metrics = {}\n",
        "            for metrics_dict in metrics_dicts:\n",
        "                if metrics_dict['label'] == 'best':\n",
        "                    subset = metrics_dict['subset']\n",
        "                    subset_metrics[subset] = metrics_dict['prediction_results']\n",
        "            if split_strategy == 'k_fold_cv':\n",
        "                dset_size = subset_metrics['train']['num_compounds'] + subset_metrics['test']['num_compounds']\n",
        "            else:\n",
        "                dset_size = subset_metrics['train']['num_compounds'] + subset_metrics['valid']['num_compounds'] + subset_metrics['test']['num_compounds']\n",
        "            for subset in subsets:\n",
        "                subset_size = subset_metrics[subset]['num_compounds']\n",
        "                for score_type in score_types:\n",
        "                    try:\n",
        "                        score = subset_metrics[subset][score_type]\n",
        "                    except KeyError:\n",
        "                        score = float('nan')\n",
        "                    score_dict[subset][score_type].append(score)\n",
        "                ncmpd_dict[subset].append(subset_size)\n",
        "            dset_size_list.append(dset_size)\n",
        "\n",
        "    col_dict = dict(\n",
        "                    collection=collection_list,\n",
        "                    model_uuid=model_uuid_list,\n",
        "                    time_built=time_built_list,\n",
        "                    model_type=model_type_list,\n",
        "                    featurizer=featurizer_list,\n",
        "                    features=desc_type_list,\n",
        "                    transformer=transform_list,\n",
        "                    splitter=splitter_list,\n",
        "                    split_strategy=split_strategy_list,\n",
        "                    split_uuid=split_uuid_list,\n",
        "                    umap_dim=umap_dim_list,\n",
        "                    umap_targ_wt=umap_targ_wt_list,\n",
        "                    umap_neighbors=umap_neighbors_list,\n",
        "                    umap_min_dist=umap_min_dist_list,\n",
        "                    layer_sizes=layer_sizes_list,\n",
        "                    dropouts=dropouts_list,\n",
        "                    learning_rate=learning_rate_list,\n",
        "                    best_epoch=best_epoch_list,\n",
        "                    max_epochs=max_epochs_list,\n",
        "                    rf_estimators=rf_estimators_list,\n",
        "                    rf_max_features=rf_max_features_list,\n",
        "                    rf_max_depth=rf_max_depth_list,\n",
        "                    xgb_gamma = xgb_gamma_list,\n",
        "                    xgb_learning_rate = xgb_learning_rate_list,\n",
        "                    dataset_bucket=bucket_list,\n",
        "                    dataset_key=dataset_key_list,\n",
        "                    dataset_size=dset_size_list,\n",
        "                    parameter=param_list\n",
        "                    )\n",
        "\n",
        "    perf_df = pd.DataFrame(col_dict)\n",
        "    for subset in subsets:\n",
        "        ncmpds_col = '%s_size' % subset\n",
        "        perf_df[ncmpds_col] = ncmpd_dict[subset]\n",
        "        for score_type in score_types:\n",
        "            metric_col = '%s_%s' % (subset, score_type)\n",
        "            perf_df[metric_col] = score_dict[subset][score_type]\n",
        "\n",
        "    return perf_df\n",
        "\n",
        "from atomsci.ddm.pipeline import predict_from_model as pfm\n",
        "\n",
        "def predict_from_model_file(model_path, input_df, id_col='compound_id', smiles_col='rdkit_smiles',\n",
        "                     response_col=None, is_featurized=False, dont_standardize=False):\n",
        "    \"\"\"\n",
        "    Loads a pretrained model from a model tarball file and runs predictions on compounds in an input\n",
        "    data frame.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): File path of the model tarball file.\n",
        "\n",
        "        input_df (DataFrame): Input data to run predictions on; must at minimum contain SMILES strings.\n",
        "\n",
        "        id_col (str): Name of the column containing compound IDs. If none is provided, sequential IDs will be\n",
        "        generated.\n",
        "\n",
        "        smiles_col (str): Name of the column containing SMILES strings; required.\n",
        "\n",
        "        response_col (str): Name of an optional column containing actual response values; if it is provided, \n",
        "        the actual values will be included in the returned data frame to make it easier for you to assess performance.\n",
        "\n",
        "        dont_standardize (bool): By default, SMILES strings are salt-stripped and standardized using RDKit; \n",
        "        if you have already done this, or don't want them to be standardized, set dont_standardize to True.\n",
        "\n",
        "    Return: \n",
        "        A data frame with compound IDs, SMILES strings and predicted response values. Actual response values\n",
        "        will be included if response_col is provided. Standard prediction error estimates will be included\n",
        "        if the model was trained with uncertainty=True. Note that the predicted and actual response\n",
        "        columns will be labeled according to the response_col setting in the original training data,\n",
        "        not the response_col passed to this function; e.g. if the original model response_col was 'pIC50',\n",
        "        the returned data frame will contain columns 'pIC50_actual', 'pIC50_pred' and 'pIC50_std'.\n",
        "    \"\"\"\n",
        "\n",
        "    input_df, pred_params = pfm._prepare_input_data(input_df, id_col, smiles_col, response_col, dont_standardize)\n",
        "\n",
        "    has_responses = ('response_cols' in pred_params)\n",
        "    pred_params = parse.wrapper(pred_params)\n",
        "\n",
        "    pipe = mp.create_prediction_pipeline_from_file(pred_params, reload_dir=None, model_path=model_path)\n",
        "    if pipe.params.model_type == 'xgboost':\n",
        "        pipe.params.uncertainty = False\n",
        "    pred_df = pipe.predict_full_dataset(input_df, contains_responses=has_responses, is_featurized=is_featurized,\n",
        "                                        dset_params=pred_params)\n",
        "    pred_df = pred_df.sort_values(by=id_col)\n",
        "    return pred_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHjYDaTNBYjQ"
      },
      "source": [
        "### Monitor HP search with `groupby`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSDa2HTH6wbD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "e8cede24-8db9-46b9-d0ad-8adcf7109b31"
      },
      "source": [
        "perf_df = get_summary_perf_tables(collection_names=None, filter_dict={}, result_dir=result_dir, prediction_type='regression', verbose=False)\n",
        "perf_df = perf_df[perf_df.rf_estimators!=500]\n",
        "perf_df.sort_values(by=\"valid_r2_score\", ascending=False).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>collection</th>\n",
              "      <th>model_uuid</th>\n",
              "      <th>time_built</th>\n",
              "      <th>model_type</th>\n",
              "      <th>featurizer</th>\n",
              "      <th>features</th>\n",
              "      <th>transformer</th>\n",
              "      <th>splitter</th>\n",
              "      <th>split_strategy</th>\n",
              "      <th>split_uuid</th>\n",
              "      <th>umap_dim</th>\n",
              "      <th>umap_targ_wt</th>\n",
              "      <th>umap_neighbors</th>\n",
              "      <th>umap_min_dist</th>\n",
              "      <th>layer_sizes</th>\n",
              "      <th>dropouts</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>best_epoch</th>\n",
              "      <th>max_epochs</th>\n",
              "      <th>rf_estimators</th>\n",
              "      <th>rf_max_features</th>\n",
              "      <th>rf_max_depth</th>\n",
              "      <th>xgb_gamma</th>\n",
              "      <th>xgb_learning_rate</th>\n",
              "      <th>dataset_bucket</th>\n",
              "      <th>dataset_key</th>\n",
              "      <th>dataset_size</th>\n",
              "      <th>parameter</th>\n",
              "      <th>train_size</th>\n",
              "      <th>train_r2_score</th>\n",
              "      <th>train_mae_score</th>\n",
              "      <th>train_rms_score</th>\n",
              "      <th>valid_size</th>\n",
              "      <th>valid_r2_score</th>\n",
              "      <th>valid_mae_score</th>\n",
              "      <th>valid_rms_score</th>\n",
              "      <th>test_size</th>\n",
              "      <th>test_r2_score</th>\n",
              "      <th>test_mae_score</th>\n",
              "      <th>test_rms_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>/content/drive/MyDrive/Columbia_E4511/models</td>\n",
              "      <td>e054026b-24be-4067-8ee9-2a98b340d526</td>\n",
              "      <td>1.618335e+09</td>\n",
              "      <td>RF</td>\n",
              "      <td>ecfp</td>\n",
              "      <td>ecfp</td>\n",
              "      <td>normalization</td>\n",
              "      <td>scaffold</td>\n",
              "      <td>train_valid_test</td>\n",
              "      <td>f140122d-9b8d-4c1c-8449-f00c192ee837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>128.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>public</td>\n",
              "      <td>/content/drive/MyDrive/Columbia_E4511/merge.csv</td>\n",
              "      <td>3120</td>\n",
              "      <td>active</td>\n",
              "      <td>2496</td>\n",
              "      <td>0.854198</td>\n",
              "      <td>0.070688</td>\n",
              "      <td>0.147423</td>\n",
              "      <td>312</td>\n",
              "      <td>0.303449</td>\n",
              "      <td>0.248289</td>\n",
              "      <td>0.344565</td>\n",
              "      <td>312</td>\n",
              "      <td>0.021423</td>\n",
              "      <td>0.386990</td>\n",
              "      <td>0.489672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>/content/drive/MyDrive/Columbia_E4511/models</td>\n",
              "      <td>834c997a-3608-4fd8-8d77-ef5f3c90e8a1</td>\n",
              "      <td>1.618336e+09</td>\n",
              "      <td>RF</td>\n",
              "      <td>ecfp</td>\n",
              "      <td>ecfp</td>\n",
              "      <td>normalization</td>\n",
              "      <td>scaffold</td>\n",
              "      <td>train_valid_test</td>\n",
              "      <td>f123a7b4-7b49-4f0b-aa91-7cc9031cd4b7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>32.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>public</td>\n",
              "      <td>/content/drive/MyDrive/Columbia_E4511/merge.csv</td>\n",
              "      <td>3120</td>\n",
              "      <td>active</td>\n",
              "      <td>2496</td>\n",
              "      <td>0.832904</td>\n",
              "      <td>0.085333</td>\n",
              "      <td>0.157821</td>\n",
              "      <td>312</td>\n",
              "      <td>0.300965</td>\n",
              "      <td>0.255318</td>\n",
              "      <td>0.345179</td>\n",
              "      <td>312</td>\n",
              "      <td>0.107918</td>\n",
              "      <td>0.380801</td>\n",
              "      <td>0.467531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>/content/drive/MyDrive/Columbia_E4511/models</td>\n",
              "      <td>a17d1c42-f4c5-429a-9e7a-697cacdb8edc</td>\n",
              "      <td>1.618336e+09</td>\n",
              "      <td>RF</td>\n",
              "      <td>ecfp</td>\n",
              "      <td>ecfp</td>\n",
              "      <td>normalization</td>\n",
              "      <td>scaffold</td>\n",
              "      <td>train_valid_test</td>\n",
              "      <td>d7aef2e9-24af-4788-8f21-5591c25b7245</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>128.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>public</td>\n",
              "      <td>/content/drive/MyDrive/Columbia_E4511/merge.csv</td>\n",
              "      <td>3120</td>\n",
              "      <td>active</td>\n",
              "      <td>2496</td>\n",
              "      <td>0.873583</td>\n",
              "      <td>0.068623</td>\n",
              "      <td>0.137273</td>\n",
              "      <td>312</td>\n",
              "      <td>0.298158</td>\n",
              "      <td>0.257270</td>\n",
              "      <td>0.345871</td>\n",
              "      <td>312</td>\n",
              "      <td>0.111652</td>\n",
              "      <td>0.382204</td>\n",
              "      <td>0.466551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>/content/drive/MyDrive/Columbia_E4511/models</td>\n",
              "      <td>10942a62-80fe-48a3-9bdb-21e880264844</td>\n",
              "      <td>1.618336e+09</td>\n",
              "      <td>RF</td>\n",
              "      <td>ecfp</td>\n",
              "      <td>ecfp</td>\n",
              "      <td>normalization</td>\n",
              "      <td>scaffold</td>\n",
              "      <td>train_valid_test</td>\n",
              "      <td>96f2ae6f-8e88-4baf-a999-43054d6a3bfd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>64.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>public</td>\n",
              "      <td>/content/drive/MyDrive/Columbia_E4511/merge.csv</td>\n",
              "      <td>3120</td>\n",
              "      <td>active</td>\n",
              "      <td>2496</td>\n",
              "      <td>0.873773</td>\n",
              "      <td>0.068558</td>\n",
              "      <td>0.137170</td>\n",
              "      <td>312</td>\n",
              "      <td>0.295854</td>\n",
              "      <td>0.257683</td>\n",
              "      <td>0.346439</td>\n",
              "      <td>312</td>\n",
              "      <td>0.112110</td>\n",
              "      <td>0.381924</td>\n",
              "      <td>0.466431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>/content/drive/MyDrive/Columbia_E4511/models</td>\n",
              "      <td>5b5f47db-ba9e-49f2-8a7e-c1c5b4ebf818</td>\n",
              "      <td>1.618336e+09</td>\n",
              "      <td>RF</td>\n",
              "      <td>ecfp</td>\n",
              "      <td>ecfp</td>\n",
              "      <td>normalization</td>\n",
              "      <td>scaffold</td>\n",
              "      <td>train_valid_test</td>\n",
              "      <td>2c5e03ee-c9f1-4cf0-8bd3-6089e1742875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>64.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>public</td>\n",
              "      <td>/content/drive/MyDrive/Columbia_E4511/merge.csv</td>\n",
              "      <td>3120</td>\n",
              "      <td>active</td>\n",
              "      <td>2496</td>\n",
              "      <td>0.873702</td>\n",
              "      <td>0.067523</td>\n",
              "      <td>0.137208</td>\n",
              "      <td>312</td>\n",
              "      <td>0.295454</td>\n",
              "      <td>0.253158</td>\n",
              "      <td>0.346537</td>\n",
              "      <td>312</td>\n",
              "      <td>0.091229</td>\n",
              "      <td>0.383665</td>\n",
              "      <td>0.471884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       collection  ... test_rms_score\n",
              "131  /content/drive/MyDrive/Columbia_E4511/models  ...       0.489672\n",
              "173  /content/drive/MyDrive/Columbia_E4511/models  ...       0.467531\n",
              "180  /content/drive/MyDrive/Columbia_E4511/models  ...       0.466551\n",
              "176  /content/drive/MyDrive/Columbia_E4511/models  ...       0.466431\n",
              "177  /content/drive/MyDrive/Columbia_E4511/models  ...       0.471884\n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "IE8VVq4h2sXn",
        "outputId": "be3aa1e2-0436-45da-cfea-c1714f6a5df2"
      },
      "source": [
        "perf_df.groupby(by=['model_type', 'features']).count()[['model_uuid']].T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>model_type</th>\n",
              "      <th>RF</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>features</th>\n",
              "      <th>ecfp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>model_uuid</th>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "model_type   RF\n",
              "features   ecfp\n",
              "model_uuid  182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    }
  ]
}